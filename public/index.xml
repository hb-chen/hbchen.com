<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hobo&#39;s Blog - 技术实践</title>
    <link>http://hbchen.com/</link>
    <description>Recent content on Hobo&#39;s Blog - 技术实践</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>HB Studio</copyright>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="http://hbchen.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://hbchen.com/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>http://hbchen.com/about/</guid>
      
        <description>

&lt;h2 id=&#34;hobo-s-blog&#34;&gt;Hobo&amp;rsquo;s Blog!&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;微信&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/wechat.jpg&#34; alt=&#34;微信&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;github-https-github-com-hb-chen&#34;&gt;&lt;a href=&#34;https://github.com/hb-chen&#34;&gt;GitHub&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/echo-web&#34;&gt;Echo 实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro&#34;&gt;go-micro实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-mesh&#34;&gt;Istio微服务架构实践&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>【go-micro】使用kubernetes注册中心</title>
      <link>http://hbchen.com/post/microservice/2019-06-27-go-micro-use-kubernetes-registry/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-06-27-go-micro-use-kubernetes-registry/</guid>
      
        <description>&lt;p&gt;&lt;code&gt;go-micro&lt;/code&gt;部署到&lt;code&gt;kubernetes&lt;/code&gt;环境，可以选择&lt;code&gt;kubernetes&lt;/code&gt;注册中心插件，减少组件依赖简化运维。&lt;/p&gt;

&lt;h1 id=&#34;主要工作&#34;&gt;主要工作&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;部署示例&lt;a href=&#34;https://github.com/hb-go/micro/tree/master/k8s&#34;&gt;hb-go/micro&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;micro&lt;/code&gt;选择自己编译，而不是直接&lt;code&gt;go get -u github.com/micro/micro&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自定义选择插件的支持&lt;/li&gt;
&lt;li&gt;自己发布镜像，官方&lt;code&gt;microhq/micro&lt;/code&gt;上的镜像没有版本，容易出现兼容问题&lt;/li&gt;
&lt;li&gt;另外非常重要的一点&lt;strong&gt;保证本地与线上&lt;code&gt;micro&lt;/code&gt;的一致&lt;/strong&gt;，只需要替换注册中心&lt;code&gt;--registry=kubernetes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;go build&lt;/code&gt;打包服务时增加&lt;code&gt;kubernetes&lt;/code&gt;插件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
	_ &amp;quot;github.com/micro/go-plugins/registry/kubernetes&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;rbac问题&#34;&gt;RBAC问题&lt;/h1&gt;

&lt;p&gt;如果&lt;code&gt;kubernetes&lt;/code&gt;开启了&lt;code&gt;RBAC&lt;/code&gt;，在部署服务时需要配置&lt;code&gt;RBAC&lt;/code&gt;，包括&lt;code&gt;micro web&lt;/code&gt;、&lt;code&gt;micro api&lt;/code&gt;服务，否则服务注册/发现将失败&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2019/06/27 12:54:13 K8s: request failed with code 403
2019/06/27 12:54:13 K8s: request failed with body:
2019/06/27 12:54:13 {&amp;quot;kind&amp;quot;:&amp;quot;Status&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;metadata&amp;quot;:{},&amp;quot;status&amp;quot;:&amp;quot;Failure&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;pods \&amp;quot;micro-web-79545546b4-p5vbt\&amp;quot; is forbidden: User \&amp;quot;system:serviceaccount:default:default\&amp;quot; cannot patch resource \&amp;quot;pods\&amp;quot; in API group \&amp;quot;\&amp;quot; in the namespace \&amp;quot;default\&amp;quot;&amp;quot;,&amp;quot;reason&amp;quot;:&amp;quot;Forbidden&amp;quot;,&amp;quot;details&amp;quot;:{&amp;quot;name&amp;quot;:&amp;quot;micro-web-79545546b4-p5vbt&amp;quot;,&amp;quot;kind&amp;quot;:&amp;quot;pods&amp;quot;},&amp;quot;code&amp;quot;:403}
2019/06/27 12:54:13 Server register error: K8s: error
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rbac-yaml&#34;&gt;RBAC yaml&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: ServiceAccount
metadata:
  name: micro-services
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: micro-registry
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - pods
  verbs:
  - list
  - patch
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: micro-registry
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: micro-registry
subjects:
- kind: ServiceAccount
  name: micro-services
  namespace: default
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;服务指定service-account&#34;&gt;服务指定Service Account&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  namespace: default
  name: micro-api
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: micro-api
    spec:
+     serviceAccountName: micro-services
      containers:
      - name: api
        command: [
          &amp;quot;/micro&amp;quot;,
          &amp;quot;--registry=kubernetes&amp;quot;,
          &amp;quot;--server=rpc&amp;quot;,
          &amp;quot;--broker=http&amp;quot;,
          &amp;quot;--transport=http&amp;quot;,
          &amp;quot;--register_ttl=60&amp;quot;,
          &amp;quot;--register_interval=30&amp;quot;,
          &amp;quot;--selector=cache&amp;quot;,
          &amp;quot;--enable_stats&amp;quot;,
          &amp;quot;api&amp;quot;
        ]
        image: hbchen/micro:k8s
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          name: api-port
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】服务间通信插件Benchmark</title>
      <link>http://hbchen.com/post/microservice/2019-05-31-go-micro-benchmark/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-05-31-go-micro-benchmark/</guid>
      
        <description>&lt;p&gt;测试影响&lt;code&gt;go-micro&lt;/code&gt;服务间通信效率的三个组件：&lt;code&gt;transport&lt;/code&gt;、&lt;code&gt;server&lt;/code&gt;以及&lt;code&gt;codec&lt;/code&gt;，主要做不同插件间的横向对比。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;源码&lt;a href=&#34;https://github.com/hb-go/micro/tree/master/benchmark&#34;&gt;github.com/hb-go/micro/benchmark&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;测试环境&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MBP&lt;/li&gt;
&lt;li&gt;go &lt;strong&gt;1.12.5&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;go-micro &lt;strong&gt;v1.2.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;go-plugins &lt;strong&gt;v1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;transport-server对比&#34;&gt;Transport + Server对比&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;transport&lt;/code&gt;和&lt;code&gt;server&lt;/code&gt;的对比使用&lt;code&gt;100&lt;/code&gt;并发，完成&lt;code&gt;10W&lt;/code&gt;请求进行测试&lt;/p&gt;

&lt;h3 id=&#34;结果对比&#34;&gt;结果对比&lt;/h3&gt;

&lt;p&gt;从结果看&lt;code&gt;tcp&lt;/code&gt;+&lt;code&gt;rpc&lt;/code&gt;吞吐量最高，分别比较：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transport&lt;/code&gt;比较结果&lt;code&gt;tcp&lt;/code&gt;&amp;gt;&lt;code&gt;grpc&lt;/code&gt;&amp;gt;&lt;code&gt;utp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;server&lt;/code&gt;比较结果大致为&lt;code&gt;rpc&lt;/code&gt;&amp;gt;&lt;code&gt;grpc&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;T+S&lt;/th&gt;
&lt;th&gt;平均&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;中位&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最大&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最小&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P90&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P99&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;TPS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tcp+rpc&lt;/td&gt;
&lt;td&gt;7.236&lt;/td&gt;
&lt;td&gt;5.629&lt;/td&gt;
&lt;td&gt;101.506&lt;/td&gt;
&lt;td&gt;0.177&lt;/td&gt;
&lt;td&gt;13.338&lt;/td&gt;
&lt;td&gt;35.880&lt;/td&gt;
&lt;td&gt;13192&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;grpc+rpc&lt;/td&gt;
&lt;td&gt;8.668&lt;/td&gt;
&lt;td&gt;7.964&lt;/td&gt;
&lt;td&gt;101.280&lt;/td&gt;
&lt;td&gt;0.251&lt;/td&gt;
&lt;td&gt;12.744&lt;/td&gt;
&lt;td&gt;21.672&lt;/td&gt;
&lt;td&gt;11166&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;utp+rpc&lt;/td&gt;
&lt;td&gt;11.824&lt;/td&gt;
&lt;td&gt;11.600&lt;/td&gt;
&lt;td&gt;53.183&lt;/td&gt;
&lt;td&gt;0.204&lt;/td&gt;
&lt;td&gt;15.575&lt;/td&gt;
&lt;td&gt;21.334&lt;/td&gt;
&lt;td&gt;8252&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;grpc+grpc&lt;/td&gt;
&lt;td&gt;8.924&lt;/td&gt;
&lt;td&gt;8.181&lt;/td&gt;
&lt;td&gt;134.434&lt;/td&gt;
&lt;td&gt;0.286&lt;/td&gt;
&lt;td&gt;13.211&lt;/td&gt;
&lt;td&gt;22.973&lt;/td&gt;
&lt;td&gt;10845&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;在开始的测试中有个误区，&lt;code&gt;grpc&lt;/code&gt;服务并不使用&lt;code&gt;transport&lt;/code&gt;，包括&lt;code&gt;http&lt;/code&gt;服务，&lt;code&gt;transport&lt;/code&gt;仅在使用&lt;code&gt;go-micro&lt;/code&gt;的&lt;code&gt;rpc&lt;/code&gt;服务时有效&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;codec对比&#34;&gt;Codec对比&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;transport&lt;/code&gt;和&lt;code&gt;server&lt;/code&gt;分别使用&lt;code&gt;tcp&lt;/code&gt;和&lt;code&gt;rpc&lt;/code&gt;对比不同&lt;code&gt;codec&lt;/code&gt;性能，因为并发&lt;code&gt;100&lt;/code&gt;时不同&lt;code&gt;codec&lt;/code&gt;的失败率差别比较大，所以使用&lt;code&gt;50&lt;/code&gt;并发，完成&lt;code&gt;10W&lt;/code&gt;请求进行测试&lt;/p&gt;

&lt;h3 id=&#34;结果对比-1&#34;&gt;结果对比&lt;/h3&gt;

&lt;p&gt;对比结果：&lt;code&gt;protobuf&lt;/code&gt;&amp;gt;&lt;code&gt;proto-rpc&lt;/code&gt;&amp;gt;&lt;code&gt;grpc&lt;/code&gt;&amp;gt;&lt;code&gt;json&lt;/code&gt;&amp;gt;&lt;code&gt;grpc+json&lt;/code&gt;&amp;gt;&lt;code&gt;json-rpc&lt;/code&gt;&amp;gt;&lt;code&gt;bsonrpc&lt;/code&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CODEC&lt;/th&gt;
&lt;th&gt;平均&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;中位&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最大&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最小&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P90&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P99&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;TPS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;grpc&lt;/td&gt;
&lt;td&gt;3.937&lt;/td&gt;
&lt;td&gt;2.979&lt;/td&gt;
&lt;td&gt;90.004&lt;/td&gt;
&lt;td&gt;0.180&lt;/td&gt;
&lt;td&gt;7.184&lt;/td&gt;
&lt;td&gt;19.355&lt;/td&gt;
&lt;td&gt;12310&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;grpc+json&lt;/td&gt;
&lt;td&gt;6.085&lt;/td&gt;
&lt;td&gt;4.694&lt;/td&gt;
&lt;td&gt;149.861&lt;/td&gt;
&lt;td&gt;0.342&lt;/td&gt;
&lt;td&gt;10.365&lt;/td&gt;
&lt;td&gt;31.837&lt;/td&gt;
&lt;td&gt;8000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;protobuf&lt;/td&gt;
&lt;td&gt;3.661&lt;/td&gt;
&lt;td&gt;2.707&lt;/td&gt;
&lt;td&gt;96.636&lt;/td&gt;
&lt;td&gt;0.156&lt;/td&gt;
&lt;td&gt;6.542&lt;/td&gt;
&lt;td&gt;20.261&lt;/td&gt;
&lt;td&gt;13150&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;json&lt;/td&gt;
&lt;td&gt;5.402&lt;/td&gt;
&lt;td&gt;4.122&lt;/td&gt;
&lt;td&gt;122.360&lt;/td&gt;
&lt;td&gt;0.225&lt;/td&gt;
&lt;td&gt;9.186&lt;/td&gt;
&lt;td&gt;30.474&lt;/td&gt;
&lt;td&gt;8896&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;json-rpc&lt;/td&gt;
&lt;td&gt;6.380&lt;/td&gt;
&lt;td&gt;4.878&lt;/td&gt;
&lt;td&gt;115.141&lt;/td&gt;
&lt;td&gt;0.288&lt;/td&gt;
&lt;td&gt;11.150&lt;/td&gt;
&lt;td&gt;33.395&lt;/td&gt;
&lt;td&gt;7631&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;proto-rpc&lt;/td&gt;
&lt;td&gt;3.692&lt;/td&gt;
&lt;td&gt;2.729&lt;/td&gt;
&lt;td&gt;101.010&lt;/td&gt;
&lt;td&gt;0.180&lt;/td&gt;
&lt;td&gt;6.701&lt;/td&gt;
&lt;td&gt;19.454&lt;/td&gt;
&lt;td&gt;13041&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bsonrpc&lt;/td&gt;
&lt;td&gt;7.912&lt;/td&gt;
&lt;td&gt;5.979&lt;/td&gt;
&lt;td&gt;132.041&lt;/td&gt;
&lt;td&gt;0.354&lt;/td&gt;
&lt;td&gt;14.789&lt;/td&gt;
&lt;td&gt;40.414&lt;/td&gt;
&lt;td&gt;6145&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;默认&lt;code&gt;chdec&lt;/code&gt;如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;DefaultCodecs = map[string]codec.NewCodec{
    &amp;quot;application/grpc&amp;quot;:         grpc.NewCodec,
    &amp;quot;application/grpc+json&amp;quot;:    grpc.NewCodec,
    &amp;quot;application/grpc+proto&amp;quot;:   grpc.NewCodec,
    &amp;quot;application/json&amp;quot;:         json.NewCodec,
    &amp;quot;application/json-rpc&amp;quot;:     jsonrpc.NewCodec,
    &amp;quot;application/protobuf&amp;quot;:     proto.NewCodec,
    &amp;quot;application/proto-rpc&amp;quot;:    protorpc.NewCodec,
    &amp;quot;application/octet-stream&amp;quot;: raw.NewCodec,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外&lt;code&gt;go-plugins&lt;/code&gt;提供三个&lt;code&gt;codec&lt;/code&gt;插件，在&lt;code&gt;server&lt;/code&gt;和&lt;code&gt;client&lt;/code&gt;初始化时自定义添加&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;server.Codec(&amp;quot;application/msgpackrpc&amp;quot;, msgpackrpc.NewCodec),
server.Codec(&amp;quot;application/bsonrpc&amp;quot;, bsonrpc.NewCodec),
server.Codec(&amp;quot;application/jsonrpc2&amp;quot;, jsonrpc2.NewCodec),

client.Codec(&amp;quot;application/msgpackrpc&amp;quot;, msgpackrpc.NewCodec),
client.Codec(&amp;quot;application/bsonrpc&amp;quot;, bsonrpc.NewCodec),
client.Codec(&amp;quot;application/jsonrpc2&amp;quot;, jsonrpc2.NewCodec),
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际测试时由于不同原因&lt;code&gt;raw&lt;/code&gt; 、&lt;code&gt;msgpackrpc&lt;/code&gt;和&lt;code&gt;jsonrpc2&lt;/code&gt;运行失败未测试，&lt;code&gt;grpc+proto&lt;/code&gt;与&lt;code&gt;grpc&lt;/code&gt;实现一致未测试&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;raw.NewCodec&lt;br/&gt;error:{&amp;ldquo;id&amp;rdquo;:&amp;ldquo;go.micro.client.codec&amp;rdquo;,&amp;ldquo;code&amp;rdquo;:500,&amp;ldquo;detail&amp;rdquo;:&amp;ldquo;failed to write: field1:……&lt;br/&gt;
 msgpackrpc.NewCodec，需要实现EncodeMsg(*Writer)&lt;br/&gt;error:{&amp;ldquo;id&amp;rdquo;:&amp;ldquo;go.micro.client.codec&amp;rdquo;,&amp;ldquo;code&amp;rdquo;:500,&amp;ldquo;detail&amp;rdquo;:&amp;ldquo;Not encodable&amp;rdquo;,&amp;ldquo;status&amp;rdquo;:&amp;ldquo;Internal Server Error&amp;rdquo;}&lt;br/&gt;
 jsonrpc2.NewCodec&lt;br/&gt;error:{&amp;ldquo;id&amp;rdquo;:&amp;ldquo;go.micro.client.transport&amp;rdquo;,&amp;ldquo;code&amp;rdquo;:500,&amp;ldquo;detail&amp;rdquo;:&amp;ldquo;EOF&amp;rdquo;,&amp;ldquo;status&amp;rdquo;:&amp;ldquo;Internal Server Error&amp;rdquo;}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;详细数据&#34;&gt;详细数据&lt;/h2&gt;

&lt;h3 id=&#34;transport-server&#34;&gt;Transport + Server&lt;/h3&gt;

&lt;h4 id=&#34;测试命令&#34;&gt;测试命令&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go run server.go
$ go run client.go -c 100 -n 100000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;tcp + rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 7580
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99999
throughput (TPS)       : 13192

concurrency mean      median    max         min       p90        p99        TPS
100         7235584ns 5629000ns 101506000ns 177000ns  13338000ns 35880000ns 13192
100         7.236ms   5.629ms   101.506ms   0.177ms   13.338ms   35.880ms   13192

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc + rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 8955
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99999
throughput (TPS)       : 11166

concurrency mean      median    max         min       p90        p99        TPS
100         8668191ns 7964000ns 101280000ns 251000ns  12744000ns 21672000ns 11166
100         8.668ms   7.964ms   101.280ms   0.251ms   12.744ms   21.672ms   11166
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;utp + rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 12117
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 100000
throughput (TPS)       : 8252

concurrency mean       median     max        min       p90        p99        TPS
100         11823520ns 11600000ns 53183000ns 204000ns  15575000ns 21334000ns 8252
100         11.824ms   11.600ms   53.183ms   0.204ms   15.575ms   21.334ms   8252
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc + gRPC&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 9220
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99995
throughput (TPS)       : 10845

concurrency mean      median    max         min       p90        p99        TPS
100         8924043ns 8181000ns 134434000ns 286000ns  13211000ns 22973000ns 10845
100         8.924ms   8.181ms   134.434ms   0.286ms   13.211ms   22.973ms   10845
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;codec&#34;&gt;Codec&lt;/h3&gt;

&lt;h4 id=&#34;测试命令-1&#34;&gt;测试命令&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd benchmark/tcp_rpc
$ go run server.go
$ go run client.go -c 50 -n 100000 -ct grpc
$ go run client.go -c 50 -n 100000 -ct grpc+json
$ go run client.go -c 50 -n 100000 -ct protobuf
$ go run client.go -c 50 -n 100000 -ct json
$ go run client.go -c 50 -n 100000 -ct json-rpc
$ go run client.go -c 50 -n 100000 -ct proto-rpc
$ go run client.go -c 50 -n 100000 -ct bsonrpc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 8123
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 100000
throughput (TPS)       : 12310

concurrency mean      median    max        min       p90       p99        TPS
50          3936652ns 2979000ns 90004000ns 180000ns  7184000ns 19355000ns 12310
50          3.937ms   2.979ms   90.004ms   0.180ms   7.184ms   19.355ms   12310
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc+json&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 12500
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99961
throughput (TPS)       : 8000

concurrency mean      median    max         min       p90        p99        TPS
50          6084709ns 4694000ns 149861000ns 342000ns  10365000ns 31837000ns 8000
50          6.085ms   4.694ms   149.861ms   0.342ms   10.365ms   31.837ms   8000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;protobuf&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 7604
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 100000
throughput (TPS)       : 13150

concurrency mean      median    max        min       p90       p99        TPS
50          3660854ns 2707000ns 96636000ns 156000ns  6542000ns 20261000ns 13150
50          3.661ms   2.707ms   96.636ms   0.156ms   6.542ms   20.261ms   13150
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;json&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 11241
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99922
throughput (TPS)       : 8896

concurrency mean      median    max         min       p90       p99        TPS
50          5401532ns 4121500ns 122360000ns 225000ns  9186000ns 30474000ns 8896
50          5.402ms   4.122ms   122.360ms   0.225ms   9.186ms   30.474ms   8896
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;json-rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 13103
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99971
throughput (TPS)       : 7631

concurrency mean      median    max         min       p90        p99        TPS
50          6380308ns 4878000ns 115141000ns 288000ns  11150000ns 33395000ns 7631
50          6.380ms   4.878ms   115.141ms   0.288ms   11.150ms   33.395ms   7631
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;proto-rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 7668
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99998
throughput (TPS)       : 13041

concurrency mean      median    max         min       p90       p99        TPS
50          3692281ns 2729000ns 101010000ns 180000ns  6701000ns 19454000ns 13041
50          3.692ms   2.729ms   101.010ms   0.180ms   6.701ms   19.454ms   13041
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;bsonrpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 16272
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99933
throughput (TPS)       : 6145

concurrency mean      median    max         min       p90        p99        TPS
50          7911887ns 5979000ns 132041000ns 354000ns  14789000ns 40414000ns 6145
50          7.912ms   5.979ms   132.041ms   0.354ms   14.789ms   40.414ms   6145
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio安全】网格边缘-Ingress</title>
      <link>http://hbchen.com/post/servicemesh/2019-05-11-istio-security-ingress/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-05-11-istio-security-ingress/</guid>
      
        <description>&lt;p&gt;接&lt;a href=&#34;(/post/servicemesh/2019-04-11-istio-security-egress/)&#34;&gt;【Istio安全】网格边缘-Egress&lt;/a&gt;继续网格边缘的实践&lt;code&gt;ingress-gateway&lt;/code&gt;，
分为&lt;strong&gt;HTTP&lt;/strong&gt;、&lt;strong&gt;HTTPS-不终止TLS&lt;/strong&gt;和&lt;strong&gt;HTTPS-种子TLS&lt;/strong&gt;三种场景。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;有了&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-04-11-istio-security-egress/&#34;&gt;Egress&lt;/a&gt;的实践，这里不使用&lt;code&gt;httpbin&lt;/code&gt;做内部服务，而是用&lt;code&gt;egress-gateway&lt;/code&gt;的成果，
&lt;code&gt;www.aliyun.com&lt;/code&gt;和&lt;code&gt;hbchen.com&lt;/code&gt;的两个外部服务进行测试。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http
    protocol: HTTP
  resolution: NONE
EOF

$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: originate-tls-for-aliyun
spec:
  host: www.aliyun.com
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - name: originate-tls
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
        portLevelSettings:
        - port:
            number: 443
          tls:
            mode: SIMPLE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;环境变量&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;http2&amp;quot;)].nodePort}&#39;)
export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;https&amp;quot;)].nodePort}&#39;)

export INGRESS_HOST=$(minikube ip)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;接下来进入正文&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;都只需要定义两个&lt;code&gt;.yaml&lt;/code&gt;配置:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gateway&lt;/strong&gt;:&lt;code&gt;ingress-example-gateway&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VirtualService&lt;/strong&gt;:&lt;code&gt;ingress-example-svc&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;http-gateway&#34;&gt;Http Gateway&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/ingress-http.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方文档&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/ingress/&#34;&gt;控制 Ingress 流量&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ingress-example-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - &amp;quot;hbchen.com&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ingress-example-svc
spec:
  hosts:
  - &amp;quot;hbchen.com&amp;quot;
  gateways:
  - ingress-example-gateway
  http:
  - match:
    - port: 80
    route:
    - destination:
        host: hbchen.com
        port:
          number: 80
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -I -v -HHost:hbchen.com http://$INGRESS_HOST:$INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;https-gateway-不终止-tls&#34;&gt;Https Gateway-不终止&lt;code&gt;TLS&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/ingress-https-passthrough.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方文档&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/ingress-sni-passthrough/&#34;&gt;没有 TLS 的 Ingress gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不终止&lt;code&gt;TLS&lt;/code&gt;即透传&lt;code&gt;https&lt;/code&gt;请求到网格内服务，这里我们使用一个外部服务来模拟一个支持&lt;code&gt;https&lt;/code&gt;的服务&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ingress-example-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - &amp;quot;www.aliyun.com&amp;quot;
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: PASSTHROUGH
    hosts:
    - &amp;quot;www.aliyun.com&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ingress-example-svc
spec:
  hosts:
  - &amp;quot;www.aliyun.com&amp;quot;
  gateways:
  - ingress-example-gateway
  http:
  - match:
    - port: 80
    route:
    - destination:
        host: www.aliyun.com
        subset: originate-tls
        port:
          number: 443
  tls:
  - match:
    - port: 443
      sni_hosts:
      - www.aliyun.com
    route:
    - destination:
        host: www.aliyun.com
        port:
          number: 443
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -I -v -HHost:www.aliyun.com http://$INGRESS_HOST:$INGRESS_PORT
curl -I -v --resolve www.aliyun.com:$SECURE_INGRESS_PORT:$INGRESS_HOST https://www.aliyun.com:$SECURE_INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;https-gateway-终止-tls&#34;&gt;Https Gateway-终止&lt;code&gt;TLS&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/ingress-https.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方文档&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/secure-ingress/sds/&#34;&gt;使用 SDS 为 Gateway 提供 HTTPS 加密支持&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;终止&lt;code&gt;TLS&lt;/code&gt;即由&lt;code&gt;ingress-gateway&lt;/code&gt;提供&lt;code&gt;https&lt;/code&gt;服务，更符合&lt;code&gt;ingress-gateway&lt;/code&gt;作为网格统一入口的需求&lt;/p&gt;

&lt;h3 id=&#34;启用sds&#34;&gt;启用SDS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;SDS&lt;/code&gt;默认是关闭的，所以首先需要开启&lt;code&gt;ingress-gateway&lt;/code&gt;的&lt;code&gt;SDS&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd istio/path 

# 生成.yaml
$ helm template install/kubernetes/helm/istio/ --name istio \
--namespace istio-system -x charts/gateways/templates/deployment.yaml \
--set gateways.istio-egressgateway.enabled=false \
--set gateways.istio-ingressgateway.sds.enabled=true &amp;gt; \
$HOME/istio-ingressgateway.yaml

# 重新部署
$ kubectl apply -f $HOME/istio-ingressgateway.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;生成证书&#34;&gt;生成证书&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/nicholasjackson/mtls-go-example

$ cd mtls-go-example
$ ./generate.sh hbchen.com 123456

$ mkdir ./../hbchen.com &amp;amp;&amp;amp; mv 1_root 2_intermediate 3_application 4_client ./../hbchen.com
$ cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建-secret&#34;&gt;创建&lt;code&gt;Secret&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl create -n istio-system secret generic hbchen-credential \
--from-file=key=hbchen.com/3_application/private/hbchen.com.key.pem \
--from-file=cert=hbchen.com/3_application/certs/hbchen.com.cert.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ingress-example-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: &amp;quot;hbchen-credential&amp;quot; # NOTE: 和 Secret 名称一致
    hosts:
    - &amp;quot;hbchen.com&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ingress-example-svc
spec:
  hosts:
  - &amp;quot;hbchen.com&amp;quot;
  gateways:
  - ingress-example-gateway
  http:
  - match:
    - port: 443
    route:
    - destination:
        host: hbchen.com
        port:
          number: 80
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -I -v -HHost:hbchen.com \
--resolve hbchen.com:$SECURE_INGRESS_PORT:$INGRESS_HOST \
--cacert hbchen.com/2_intermediate/certs/ca-chain.cert.pem \
https://hbchen.com:$SECURE_INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;todo&#34;&gt;TODO&lt;/h2&gt;

&lt;h3 id=&#34;jwt&#34;&gt;JWT&lt;/h3&gt;

&lt;h3 id=&#34;authn&#34;&gt;Authn&lt;/h3&gt;</description>
      
    </item>
    
    <item>
      <title>分布式系统限流服务-Golang&amp;Redis</title>
      <link>http://hbchen.com/post/distributed/2019-05-05-rate-limit/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/distributed/2019-05-05-rate-limit/</guid>
      
        <description>&lt;p&gt;本文参考两个使用Redis做限流的项目，分析分布式系统限流服务的实现，包括固定窗口以及滚动窗口的限流。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考项目&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Istio项目&lt;code&gt;mixer&lt;/code&gt;模块的&lt;a href=&#34;https://github.com/istio/istio/tree/master/mixer/adapter/redisquota&#34;&gt;adapter/redisquota&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/go-redis/redis_rate&#34;&gt;go-redis/redis_rate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;固定窗口&#34;&gt;固定窗口&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/distributed/rate-window-fixed.png&#34; alt=&#34;fixed-window&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;go-redis-redis-rate&#34;&gt;go-redis/redis_rate&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;redis_rate&lt;/code&gt;使用&lt;strong&gt;窗口标识&lt;/strong&gt;做&lt;code&gt;key&lt;/code&gt;的字符串，用&lt;code&gt;INCRBY&lt;/code&gt;统计窗口已使用流量&lt;code&gt;n&lt;/code&gt;，且&lt;code&gt;key&lt;/code&gt;在此窗口结束后自动过期。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;窗口标识&lt;/strong&gt;的生成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;slot&lt;/code&gt; = &lt;code&gt;utime&lt;/code&gt;(&lt;em&gt;时间戳&lt;code&gt;s&lt;/code&gt;&lt;/em&gt;)➗&lt;code&gt;udur&lt;/code&gt;(&lt;em&gt;窗口大小&lt;code&gt;s&lt;/code&gt;，&lt;code&gt;dur ≥ 1s&lt;/code&gt;&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;key&lt;/code&gt; = &lt;code&gt;name&lt;/code&gt; + &lt;code&gt;slot&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;utime&lt;/code&gt;与系统时钟相关，考虑一种较为极端的情况，窗口大小&lt;code&gt;1s&lt;/code&gt;，&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;两个系统时钟差&lt;code&gt;2s&lt;/code&gt;，而&lt;code&gt;key&lt;/code&gt;的过期时间与窗口大小相同&lt;code&gt;1s&lt;/code&gt;，
假设&lt;code&gt;key&lt;/code&gt;在窗口最后有更新则&lt;code&gt;key&lt;/code&gt;的生存周期是&lt;code&gt;2s&lt;/code&gt;，而恰好时钟相差&lt;code&gt;2s&lt;/code&gt;，这样&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;系统的分布式限流就变成了单机限流。&lt;br/&gt;
虽然比较极端，但在使用时还是需要注意，根据需要可以适当加大&lt;code&gt;key&lt;/code&gt;的过期时间，同时存活多个窗口，使存活窗口范围覆盖系统间的时钟误差。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (l *Limiter) AllowN(
	name string, maxn int64, dur time.Duration, n int64,
) (count int64, delay time.Duration, allow bool) {
	udur := int64(dur / time.Second)
	utime := time.Now().Unix()
	slot := utime / udur
	delay = time.Duration((slot+1)*udur-utime) * time.Second

	if l.Fallback != nil {
		allow = l.Fallback.Allow()
	}

	name = allowName(name, slot)
	count, err := l.incr(name, dur, n)
	if err == nil {
		allow = count &amp;lt;= maxn
	}

	return count, delay, allow
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;adapter-redisquota-fixed-window&#34;&gt;adapter/redisquota/fixed_window&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;redisquota&lt;/strong&gt;使用&lt;code&gt;lua&lt;/code&gt;脚本实现，设计上使用一个带有&lt;code&gt;token&lt;/code&gt;和&lt;code&gt;expire&lt;/code&gt;的哈希表，&lt;code&gt;key&lt;/code&gt;过期时间为&lt;code&gt;windowLength&lt;/code&gt;，窗口在&lt;code&gt;key&lt;/code&gt;过期或&lt;code&gt;timestamp&lt;/code&gt;≥&lt;code&gt;expire&lt;/code&gt;时重置。
另外&lt;code&gt;redisquota&lt;/code&gt;根据场景做了&lt;strong&gt;幂等&lt;/strong&gt;设计，同一&lt;code&gt;deduplicationid&lt;/code&gt;在窗口有效期内不会重新分配&lt;code&gt;token&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;因为&lt;code&gt;timestamp&lt;/code&gt;与系统时钟相关，同样假设&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;两个系统时钟差&lt;code&gt;2s&lt;/code&gt;(&lt;code&gt;A&lt;/code&gt;&amp;gt;&lt;code&gt;B&lt;/code&gt;)，窗口大小&lt;code&gt;10s&lt;/code&gt;，如果窗口①由&lt;code&gt;A&lt;/code&gt;系统时间戳触发，而窗口②由&lt;code&gt;B&lt;/code&gt;系统时间戳触发(&lt;code&gt;A&lt;/code&gt;在后&lt;code&gt;2s&lt;/code&gt;没有流量)，
这样①实际窗口大小就是&lt;code&gt;12s&lt;/code&gt;，这样继续到窗口③由&lt;code&gt;A&lt;/code&gt;系统时间戳触发，②的实际窗口代销就是&lt;code&gt;8s&lt;/code&gt;，所以在分布式环境下限流效果同样受系统时钟误差的影响。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;local key_meta = KEYS[1]
-- local key_data = KEYS[2]

local credit = tonumber(ARGV[1])
local windowLength = tonumber(ARGV[2])
-- local bucketLength = tonumber(ARGV[3])
local bestEffort = tonumber(ARGV[4])
local token = tonumber(ARGV[5])
local timestamp = tonumber(ARGV[6])
local deduplicationid = ARGV[7]

-- lookup previous response for the deduplicationid and returns if it is still valid
--------------------------------------------------------------------------------
if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
    local previous_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;))
    local previous_expire = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;expire&amp;quot;))

    if previous_token and previous_expire then
        if timestamp &amp;lt; previous_expire then
            return {previous_token, previous_expire - timestamp}
        end
    end
end

-- read or initialize meta information
--------------------------------------------------------------------------------
local info_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;token&amp;quot;))
local info_expire = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;expire&amp;quot;))

if (not info_token or not info_expire) or (timestamp &amp;gt;= info_expire) then
    info_token = 0
    info_expire = windowLength + timestamp

    redis.call(&amp;quot;HMSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, info_token, &amp;quot;expire&amp;quot;, windowLength + timestamp)
    -- set the expiration time for automatic cleanup
    redis.call(&amp;quot;PEXPIRE&amp;quot;, key_meta, windowLength / 1000000)
end

if info_token + token &amp;gt; credit then
    if bestEffort == 1 then
        local exceeded = info_token + token - credit

        if exceeded &amp;lt; token then
            -- return maximum available allocated token
            redis.call(&amp;quot;HMSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, credit)

            -- save current request and set expiration time for auto cleanup
            if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
                redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, token - exceeded, &amp;quot;expire&amp;quot;, info_expire)
                redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, math.floor((info_expire - timestamp) / 1000000))
            end

            return {token - exceeded, info_expire - timestamp}
        else
            -- not enough available credit
            return {0, 0}
        end
    else
        -- not enough available credit
        return {0, 0}
    end
else
    -- allocated token
    redis.call(&amp;quot;HMSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, info_token + token)

    -- save current request and set expiration time for auto cleanup
    if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
        redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, token, &amp;quot;expire&amp;quot;, info_expire)
        redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, math.floor((info_expire - timestamp) / 1000000))
    end

    return {token, info_expire - timestamp}
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;lua脚本获取时间戳&#34;&gt;Lua脚本获取时间戳&lt;/h3&gt;

&lt;p&gt;既然在分布式环境系统时钟有可能存在误差，那自然考虑将时间戳转到Redis中获取，消除时钟误差对窗口的影响，这里有一个限制条件是需要Lua脚本支持&lt;strong&gt;随机写入&lt;/strong&gt;，
有关Redis Lua脚本&lt;strong&gt;随机写入&lt;/strong&gt;请参考此文《&lt;a href=&#34;https://yq.aliyun.com/articles/195914&#34;&gt;redis4.0之Lua脚本新姿势&lt;/a&gt;》，结合这个特性可以将两个方案的时间戳由外部传入改为在Lua脚本中获取Redis系统时间，
我在&lt;a href=&#34;https://github.com/hb-go/pkg/tree/master/rate&#34;&gt;hb-go/pkg/rate&lt;/a&gt;包分别使用&lt;code&gt;SET&lt;/code&gt;、&lt;code&gt;HSET&lt;/code&gt;做了实现可以参考。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;-- Redis version ≥ 3.2
redis.replicate_commands()
local now = redis.call(&#39;TIME&#39;)
timestamp = (tonumber(now[1]) * 1e6 + tonumber(now[2])) * 1e3
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;滚动窗口&#34;&gt;滚动窗口&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/distributed/rate-window-rolling.png&#34; alt=&#34;rolling-window&#34; /&gt;&lt;/p&gt;

&lt;p&gt;滚动窗口在固定窗口基础上，将一个&lt;code&gt;window&lt;/code&gt;拆成多个&lt;code&gt;bucket&lt;/code&gt;，这样窗口根据&lt;code&gt;bucket&lt;/code&gt;的大小向前移动。Redis的结构为哈希表：&lt;code&gt;token&lt;/code&gt;、&lt;code&gt;bucket.token&lt;/code&gt;、&lt;code&gt;bucket.timestamp&lt;/code&gt;和&lt;code&gt;key&lt;/code&gt;，
以及一个存储&lt;code&gt;bucket&lt;/code&gt;历史数据的有序集合(&lt;em&gt;以&lt;code&gt;bucket&lt;/code&gt;的时间戳排序&lt;/em&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;token&lt;/code&gt;:窗口内已使用&lt;code&gt;token&lt;/code&gt;数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bucket.token&lt;/code&gt;:当前桶内已使用&lt;code&gt;token&lt;/code&gt;数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bucket.timestamp&lt;/code&gt;:当前桶的时间戳&lt;/li&gt;
&lt;li&gt;&lt;code&gt;key&lt;/code&gt;:累计&lt;code&gt;bucket&lt;/code&gt;数量&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;local key_meta = KEYS[1]
local key_data = KEYS[2]

local credit = tonumber(ARGV[1])
local windowLength = tonumber(ARGV[2])
local bucketLength = tonumber(ARGV[3])
local bestEffort = tonumber(ARGV[4])
local token = tonumber(ARGV[5])
local timestamp = tonumber(ARGV[6])
local deduplicationid = ARGV[7]

-- lookup previous response for the deduplicationid and returns if it is still valid
--------------------------------------------------------------------------------
if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
    local previous_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;))
    local previous_expire = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;expire&amp;quot;))

    if previous_token and previous_expire then
        if timestamp &amp;lt; previous_expire then
            return {previous_token, previous_expire - timestamp}
        end
    end
end

-- read meta information
--------------------------------------------------------------------------------
local info_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;token&amp;quot;))
local info_bucket_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;bucket.token&amp;quot;))
local info_bucket_timestamp = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;bucket.timestamp&amp;quot;))

-- initialize meta
--------------------------------------------------------------------------------
if not info_token or not info_bucket_token or not info_bucket_timestamp then
    info_token = 0
    info_bucket_token = 0
    info_bucket_timestamp = timestamp

    redis.call(&amp;quot;HMSET&amp;quot;, key_meta,
        &amp;quot;token&amp;quot;, info_token,
        &amp;quot;bucket.token&amp;quot;, info_bucket_token,
        &amp;quot;bucket.timestamp&amp;quot;, info_bucket_timestamp,
        &amp;quot;key&amp;quot;, 0)
end


-- move buffer to bucket list if bucket timer is older than bucket window
--------------------------------------------------------------------------------
if (timestamp - info_bucket_timestamp + 1) &amp;gt; bucketLength then
    if tonumber(info_bucket_token) &amp;gt; 0 then
        local nextKey = redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;key&amp;quot;, 1)
        local value = tostring(nextKey) .. &amp;quot;.&amp;quot; .. tostring(info_bucket_token)
        redis.call(&amp;quot;ZADD&amp;quot;, key_data, info_bucket_timestamp, value);
    end
    redis.call(&amp;quot;HMSET&amp;quot;, key_meta,
        &amp;quot;bucket.token&amp;quot;, 0,
        &amp;quot;bucket.timestamp&amp;quot;, timestamp)
end

local time_to_expire = timestamp - windowLength

-- reclaim tokens from expired records
--------------------------------------------------------------------------------
local reclaimed = 0
local expired = redis.call(&amp;quot;ZRANGEBYSCORE&amp;quot;, key_data, 0, time_to_expire)

for idx, value in ipairs(expired) do
    reclaimed = reclaimed + tonumber(string.sub(value, string.find(value, &amp;quot;%.&amp;quot;)+1))
end

-- remove expired records
--------------------------------------------------------------------------------
redis.call(&amp;quot;ZREMRANGEBYSCORE&amp;quot;, key_data, 0, time_to_expire)

-- update consumed token
--------------------------------------------------------------------------------
if reclaimed &amp;gt; 0 then
    info_token = info_token - reclaimed;
    if info_token &amp;lt; 0 then
        info_token = 0
    end
    redis.call(&amp;quot;HSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, info_token)
end

-- update the expiration time for automatic cleanup
--------------------------------------------------------------------------------
redis.call(&amp;quot;PEXPIRE&amp;quot;, key_meta, windowLength / 1000000)
redis.call(&amp;quot;PEXPIRE&amp;quot;, key_meta, windowLength / 1000000)

-- calculate available token
--------------------------------------------------------------------------------
local available_token = credit - info_token

-- check available token and requested token
--------------------------------------------------------------------------------

if available_token &amp;lt;= 0 then
    -- credit exhausted
    return {0, 0}
elseif available_token &amp;gt;= token then
    -- increase token and bucket.token by token
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;token&amp;quot;, token)
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;bucket.token&amp;quot;, token)

    -- save current request and set expiration time for auto cleanup
    if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
        redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, token, &amp;quot;expire&amp;quot;, timestamp + windowLength)
        redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, windowLength / 1000000)
    end

    return {token,  windowLength}
else

    if bestEffort == 0 then
        -- not enough token
        return {0, 0}
    end

    -- allocate available token only
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;token&amp;quot;, available_token)
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;bucket.token&amp;quot;, available_token)

    -- save current request and set expiration time for auto cleanup
    if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
        redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, available_token, &amp;quot;expire&amp;quot;, timestamp + windowLength)
        redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, windowLength / 1000000)
    end

    return {available_token, windowLength}
end
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;限流的窗口与Flink的&lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/stream/operators/windows.html#tumbling-windows&#34;&gt;Window&lt;/a&gt;类似，
对于固定窗口结合使用场景的需求，可以借鉴Flink的&lt;strong&gt;Tumbling Window&lt;/strong&gt;接口设计提供&lt;code&gt;offset&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;</description>
      
    </item>
    
    <item>
      <title>【Flink实践】实时消费阿里云SLS日志&#43;输出到ES</title>
      <link>http://hbchen.com/post/flink/2019-04-29-sls&#43;es/</link>
      <pubDate>Mon, 29 Apr 2019 18:42:22 +0800</pubDate>
      
      <guid>http://hbchen.com/post/flink/2019-04-29-sls&#43;es/</guid>
      
        <description>&lt;p&gt;本文介绍Flink在流计算场景的简单应用，实时消费SLS内的AccessLog，并将计算结果输出到Elasticsearch。&lt;/p&gt;

&lt;h2 id=&#34;环境&#34;&gt;环境&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Flink

&lt;ul&gt;
&lt;li&gt;1.8&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ES

&lt;ul&gt;
&lt;li&gt;6.3.2&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;假设场景&#34;&gt;假设场景&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;日志结构&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;request_time: 1556415329
uri: /analysis/path?id=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;系统AccessLog通过Logtai采集到阿里云SLS，指定&lt;code&gt;request_time&lt;/code&gt;为日志时间字段。示例场景需求统计指定&lt;code&gt;uri.path&lt;/code&gt;+&lt;code&gt;uri.query.id&lt;/code&gt;分组统计访问计数。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实时消费&lt;code&gt;SLS&lt;/code&gt;日志&lt;/li&gt;
&lt;li&gt;筛选&lt;code&gt;uri.path&lt;/code&gt;=&lt;code&gt;/analysis/path&lt;/code&gt;(&lt;em&gt;简化只统计单个&lt;code&gt;path&lt;/code&gt;，实际场景可能是多个&lt;code&gt;path&lt;/code&gt;的访问统计，相应的&lt;code&gt;key&lt;/code&gt;参数规则也会不同&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;解析&lt;code&gt;uri.query&lt;/code&gt;参数&lt;code&gt;id&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;创建ES索引&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PUT sls_analysis

PUT sls_analysis/_mapping/_doc
{
  &amp;quot;properties&amp;quot;: {
    &amp;quot;path&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;
    },
    &amp;quot;key&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;
    },
    &amp;quot;count&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;
    },
    &amp;quot;timestamp&amp;quot;: {
      &amp;quot;type&amp;quot;:&amp;quot;long&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;流程解析&#34;&gt;流程解析&lt;/h2&gt;

&lt;p&gt;接下来结合&lt;a href=&#34;https://github.com/hb-chen/flink-practice/tree/master/sls&#34;&gt;hb-chen/flink-practice&lt;/a&gt;源码对流程进行解析。&lt;/p&gt;

&lt;h3 id=&#34;gradle添加依赖&#34;&gt;Gradle添加依赖&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;    // ES
    flinkShadowJar &amp;quot;org.apache.flink:flink-connector-elasticsearch6_${scalaBinaryVersion}:${flinkVersion}&amp;quot;

    // SLS
    flinkShadowJar &amp;quot;com.aliyun.openservices:flink-log-connector:0.1.7&amp;quot;
    flinkShadowJar &amp;quot;com.aliyun.openservices:aliyun-log:0.6.19&amp;quot;
    flinkShadowJar &amp;quot;com.aliyun.openservices:log-loghub-producer:0.1.8&amp;quot;
    flinkShadowJar &amp;quot;com.google.protobuf:protobuf-java:2.5.0&amp;quot;
    
    // YAML解析
    flinkShadowJar &amp;quot;org.yaml:snakeyaml:1.24&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;参数-配置-可忽略&#34;&gt;参数&amp;amp;配置（可忽略）&lt;/h3&gt;

&lt;p&gt;虽然只是示例还是做了&lt;code&gt;args&lt;/code&gt;参数及&lt;code&gt;config.yml&lt;/code&gt;配置的获取，方便配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) throws Exception {
    final ParameterTool params = ParameterTool.fromArgs(args);
    String analysisPath = params.getRequired(&amp;quot;path&amp;quot;);
    String analysisQueryKey = params.get(&amp;quot;key&amp;quot;, &amp;quot;id&amp;quot;);
    LOG.info(&amp;quot;access log analysis path:&amp;quot; + analysisPath + &amp;quot; key:&amp;quot; + analysisQueryKey);

    Config config = getConfig();
    
    // ……
}

private static Config getConfig() {
    Constructor constructor = new Constructor(Config.class);
    org.yaml.snakeyaml.Yaml yaml = new org.yaml.snakeyaml.Yaml(constructor);

    Config config = yaml.loadAs(SlsAnalysis.class.getClassLoader().getResourceAsStream(&amp;quot;config.yml&amp;quot;), Config.class);
    return config;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;日志消费&#34;&gt;日志消费&lt;/h3&gt;

&lt;p&gt;首先参考&lt;a href=&#34;https://help.aliyun.com/document_detail/63594.html&#34;&gt;官方文档&lt;/a&gt;通过&lt;code&gt;SLS&lt;/code&gt;的各种配置创建一个&lt;code&gt;Consumer&lt;/code&gt;，获得&lt;code&gt;SLS&lt;/code&gt;日志流&lt;code&gt;DataStream&amp;lt;RawLogGroupList&amp;gt; logStream&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    // SLS消费
    // https://help.aliyun.com/document_detail/63594.html
    Properties configProps = new Properties();
    // 设置访问日志服务的域名
    configProps.put(ConfigConstants.LOG_ENDPOINT, config.getSls().getEndpoint());
    // 设置访问ak
    configProps.put(ConfigConstants.LOG_ACCESSSKEYID, config.getSls().getAk());
    configProps.put(ConfigConstants.LOG_ACCESSKEY, config.getSls().getSk());
    // 设置日志服务的project
    configProps.put(ConfigConstants.LOG_PROJECT, config.getSls().getProject());
    // 设置日志服务的Logstore
    configProps.put(ConfigConstants.LOG_LOGSTORE, config.getSls().getLogStore());
    // 设置消费日志服务起始位置
    configProps.put(ConfigConstants.LOG_CONSUMER_BEGIN_POSITION, &amp;quot;&amp;quot; + (System.currentTimeMillis() / 1000L));
    // 设置日志拉取时间间隔及每次调用拉取的日志数量
    configProps.put(ConfigConstants.LOG_FETCH_DATA_INTERVAL_MILLIS, &amp;quot;1000&amp;quot;);
    configProps.put(ConfigConstants.LOG_MAX_NUMBER_PER_FETCH, &amp;quot;100&amp;quot;);
    // 设置Shards发现周期
    configProps.put(ConfigConstants.LOG_SHARDS_DISCOVERY_INTERVAL_MILLIS, Consts.DEFAULT_SHARDS_DISCOVERY_INTERVAL_MILLIS);

    // 设置日志服务的消息反序列化方法
    RawLogGroupListDeserializer deserializer = new RawLogGroupListDeserializer();
    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
    DataStream&amp;lt;RawLogGroupList&amp;gt; logStream = env.addSource(new FlinkLogConsumer&amp;lt;RawLogGroupList&amp;gt;(deserializer, configProps));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过&lt;code&gt;RawLogGroupList&lt;/code&gt;结构知道&lt;code&gt;logStream&lt;/code&gt;获得的是批量的&lt;code&gt;SLS&lt;/code&gt;日志，单条日志是分组的&lt;code&gt;RawLog&lt;/code&gt;列表，这就需要首先对批量的数据进行展开(&lt;code&gt;flatMap()&lt;/code&gt;)来获得单条数据流&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class RawLogGroupList implements Serializable {
    public List&amp;lt;RawLogGroup&amp;gt; rawLogGroups = new ArrayList();
}

public class RawLogGroup implements Serializable {
    public String source;
    public String topic = &amp;quot;&amp;quot;;
    public Map&amp;lt;String, String&amp;gt; tags = new HashMap();
    public List&amp;lt;RawLog&amp;gt; logs = new ArrayList();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;批量日志展开&#34;&gt;批量日志展开&lt;/h3&gt;

&lt;p&gt;这是整个过流程最关键的一环，这里要定义展开后数据流的结构，不啰嗦直接看结构&lt;code&gt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;f0&lt;/code&gt;:&lt;code&gt;AccessLogAnalysis&lt;/code&gt;是解析&lt;code&gt;uri&lt;/code&gt;的&lt;code&gt;path&lt;/code&gt;+&lt;code&gt;key&lt;/code&gt;的对象，也就是要用做&lt;code&gt;keyBy&lt;/code&gt;的属性&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f1&lt;/code&gt;:&lt;code&gt;Integer&lt;/code&gt;统计数量，单条日志全计为1(&lt;em&gt;根据需求这里可以考些优化，比如Group内有序可以在range过程直接对相同&lt;code&gt;request_time&lt;/code&gt;做聚合&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f2&lt;/code&gt;:&lt;code&gt;Long&lt;/code&gt;日志时间戳，考虑后续作为&lt;code&gt;EventTime&lt;/code&gt;使用，所以将&lt;code&gt;request_time&lt;/code&gt;转为毫秒&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f3&lt;/code&gt;:&lt;code&gt;Long&lt;/code&gt;批量日志的最小时间戳，因为&lt;code&gt;SLS&lt;/code&gt;日志是时间有序的，且单个&lt;code&gt;RawLogGroup&lt;/code&gt;日志升序，所以自然的考虑使用最小时间戳作为&lt;code&gt;watermark&lt;/code&gt;，这样也避免了&lt;strong&gt;arrive late&lt;/strong&gt;的出现&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    // SLS批量日志展开
    DataStream&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt; flatStream = logStream.flatMap(new FlatMapFunction&amp;lt;RawLogGroupList, Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt;() {
        @Override
        public void flatMap(RawLogGroupList value, Collector&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt; out) throws Exception {
            // Log group内时间升序，记录所有分组最小时间戳，即为watermark位置
            long minTimestamp = Long.MAX_VALUE;
            for (RawLogGroup group : value.getRawLogGroups()) {
                if (group.getLogs().size() &amp;gt; 0) {
                    RawLog log = group.getLogs().get(0);
                    long rt = Optional.ofNullable(log.getContents().get(&amp;quot;request_time&amp;quot;)).map(Long::new).orElse(Long.MAX_VALUE);
                    minTimestamp = rt &amp;lt; minTimestamp ? rt : minTimestamp;
                }
            }
            // 取毫秒，排除MAX_VALUE
            minTimestamp = minTimestamp == Long.MAX_VALUE ? minTimestamp : minTimestamp * 1000;

            Integer count = 0;
            for (RawLogGroup group : value.getRawLogGroups()) {
                count += group.getLogs().size();
                for (RawLog log : group.getLogs()) {
                    // URI解析
                    QueryStringDecoder decoder = new QueryStringDecoder(log.getContents().get(&amp;quot;uri&amp;quot;));
                    String path = decoder.path();
                    List&amp;lt;String&amp;gt; keyList = decoder.parameters().get(analysisQueryKey);
                    if (path.equalsIgnoreCase(analysisPath) &amp;amp;&amp;amp; keyList != null &amp;amp;&amp;amp; keyList.size() &amp;gt; 0) {
                        Integer id = Optional.ofNullable(keyList.get(0)).map(Integer::new).orElse(0);
                        AccessLogAnalysis ala = new AccessLogAnalysis();
                        ala.setKey(id);
                        ala.setPath(path);

                        Long timestamp = Optional.ofNullable(log.getContents().get(&amp;quot;request_time&amp;quot;)).map(Long::new).orElse(0L);
                        timestamp *= 1000;

                        out.collect(new Tuple4&amp;lt;&amp;gt;(ala, 1, timestamp, minTimestamp));
                    }

                }
            }
            LOG.info(&amp;quot;raw log count:&amp;quot; + count + &amp;quot; timestamp:&amp;quot; + minTimestamp);
        }
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;eventtime-timewindow&#34;&gt;EventTime &amp;amp; timeWindow&lt;/h3&gt;

&lt;p&gt;有了&lt;code&gt;flatStream&lt;/code&gt;的结果，自定义&lt;code&gt;EventTime&lt;/code&gt;以及&lt;code&gt;Watermark&lt;/code&gt;就比较简单。&lt;br/&gt;&lt;code&gt;.keyBy(0).timeWindow(Time.seconds(60)).sum(1)&lt;/code&gt;流程以&lt;code&gt;f0&lt;/code&gt;为&lt;code&gt;key&lt;/code&gt;分隔，60s为时间窗口对&lt;code&gt;f1&lt;/code&gt;求和。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;DataStream result = flatStream.assignTimestampsAndWatermarks(new AssignerWithPunctuatedWatermarks&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt;() {
    @Nullable
    @Override
    public Watermark checkAndGetNextWatermark(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; lastElement, long extractedTimestamp) {
        return lastElement.f3 &amp;lt;= extractedTimestamp ? new Watermark(lastElement.f3) : null;
    }

    @Override
    public long extractTimestamp(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; element, long previousElementTimestamp) {
        if (element.f2 &amp;gt; 0L) {
            return element.f2;
        } else {
            return previousElementTimestamp;
        }
    }
})
.keyBy(0)
.timeWindow(Time.seconds(60))
.sum(1);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;输出到es&#34;&gt;输出到ES&lt;/h3&gt;

&lt;p&gt;大致参考&lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/connectors/elasticsearch.html&#34;&gt;官方文档&lt;/a&gt;即可，
只是没有认证(&lt;em&gt;生产环境必不可少，想到ES社区的分享，在&lt;a href=&#34;https://www.shodan.io&#34;&gt;shodan.io&lt;/a&gt;上找各种公开免费ES资源😏&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Sink:Elasticsearch
List&amp;lt;HttpHost&amp;gt; httpHosts = new ArrayList&amp;lt;&amp;gt;();
httpHosts.add(new HttpHost(config.getEs().getHostname(), 9200, &amp;quot;http&amp;quot;));

// use a ElasticsearchSink.Builder to create an ElasticsearchSink
ElasticsearchSink.Builder&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt; esSinkBuilder = new ElasticsearchSink.Builder&amp;lt;&amp;gt;(httpHosts, new ElasticsearchSinkFunction&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt;() {
    public IndexRequest createIndexRequest(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; element) {
        Map&amp;lt;String, String&amp;gt; json = new HashMap&amp;lt;&amp;gt;();
        json.put(&amp;quot;path&amp;quot;, element.f0.getPath());
        json.put(&amp;quot;key&amp;quot;, element.f0.getKey().toString());
        json.put(&amp;quot;count&amp;quot;, element.f1.toString());
        json.put(&amp;quot;timestamp&amp;quot;, element.f3.toString());

        return Requests.indexRequest().index(&amp;quot;sls_analysis&amp;quot;).type(&amp;quot;_doc&amp;quot;).source(json);
    }

    @Override
    public void process(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; element, RuntimeContext runtimeContext, RequestIndexer requestIndexer) {
        requestIndexer.add(createIndexRequest(element));
    }
});

// configuration for the bulk requests; this instructs the sink to emit after every element, otherwise they would be buffered
esSinkBuilder.setBulkFlushMaxActions(1);

// provide a RestClientFactory for custom configuration on the internally created REST client
String esUsername = config.getEs().getUsername();
String esPassword = config.getEs().getPassword();
esSinkBuilder.setRestClientFactory(restClientBuilder -&amp;gt; {
    // restClientBuilder.setDefaultHeaders(headers);
    // restClientBuilder.setMaxRetryTimeoutMillis(...)
    // restClientBuilder.setPathPrefix(...)
    restClientBuilder.setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() {
        @Override
        public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpAsyncClientBuilder) {
            CredentialsProvider credentialsProvider = new BasicCredentialsProvider();
            credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(esUsername, esPassword));
            return httpAsyncClientBuilder.setDefaultCredentialsProvider(credentialsProvider);
        }
    });
});

// finally, build and add the sink to the job&#39;s pipeline
result.addSink(esSinkBuilder.build());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里还遇到个小坑（Java丢的太久了😂），在&lt;code&gt;UsernamePasswordCredentials()&lt;/code&gt;中直接使用&lt;code&gt;config.getEs().getUsername()&lt;/code&gt; &lt;code&gt;config.getEs().getPassword()&lt;/code&gt;，导致序列化错误，相关参考&lt;a href=&#34;https://yuzhouwan.com/posts/20644/&#34;&gt;Apache Flink#踩过的坑&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Exception in thread &amp;quot;main&amp;quot; org.apache.flink.api.common.InvalidProgramException: The implementation of the ElasticsearchSinkBase is not serializable. The object probably contains or references non serializable fields.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试-打包&#34;&gt;测试 &amp;amp; 打包&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 测试
$ ./gradlew sls:run --args=&amp;quot;--path /analysis/path&amp;quot;

# 打包
$ ./gradlew clean sls:shadowJar
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;提交job到flink运行&#34;&gt;提交Job到Flink运行&lt;/h3&gt;

&lt;p&gt;上传&lt;code&gt;.jar&lt;/code&gt;到Flink&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Program Arguments
--path /analysis/path
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/flink/sls+es-dashboard.png&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;到kibana看下结果&#34;&gt;到Kibana看下结果&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/flink/sls+es-kibana.png&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GET /sls_analysis/_search
{
  &amp;quot;aggs&amp;quot;: {
    &amp;quot;2&amp;quot;: {
      &amp;quot;terms&amp;quot;: {
        &amp;quot;field&amp;quot;: &amp;quot;key&amp;quot;,
        &amp;quot;size&amp;quot;: 20,
        &amp;quot;order&amp;quot;: {
          &amp;quot;1&amp;quot;: &amp;quot;desc&amp;quot;
        }
      },
      &amp;quot;aggs&amp;quot;: {
        &amp;quot;1&amp;quot;: {
          &amp;quot;sum&amp;quot;: {
            &amp;quot;field&amp;quot;: &amp;quot;count&amp;quot;
          }
        }
      }
    }
  },
  &amp;quot;size&amp;quot;: 0,
  &amp;quot;_source&amp;quot;: {
    &amp;quot;excludes&amp;quot;: []
  },
  &amp;quot;stored_fields&amp;quot;: [
    &amp;quot;*&amp;quot;
  ],
  &amp;quot;script_fields&amp;quot;: {},
  &amp;quot;docvalue_fields&amp;quot;: [],
  &amp;quot;query&amp;quot;: {
    &amp;quot;bool&amp;quot;: {
      &amp;quot;must&amp;quot;: [
        {
          &amp;quot;match_all&amp;quot;: {}
        },
        {
          &amp;quot;match_phrase&amp;quot;: {
            &amp;quot;path&amp;quot;: {
              &amp;quot;query&amp;quot;: &amp;quot;/analysis/path&amp;quot;
            }
          }
        }
      ],
      &amp;quot;filter&amp;quot;: [],
      &amp;quot;should&amp;quot;: [],
      &amp;quot;must_not&amp;quot;: []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;todo&#34;&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Checkpoint&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio安全】网格边缘-Egress</title>
      <link>http://hbchen.com/post/servicemesh/2019-04-11-istio-security-egress/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-04-11-istio-security-egress/</guid>
      
        <description>&lt;p&gt;接上一篇《&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/&#34;&gt;【Istio安全】服务间访问控制-RBAC&lt;/a&gt;》，本文主要介绍网格边缘Egress相关的配置，&lt;code&gt;HTTP&lt;/code&gt;、&lt;code&gt;HTTPS&lt;/code&gt;以及&lt;code&gt;HTTP&lt;/code&gt;转&lt;code&gt;TLS&lt;/code&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Istio版本 &lt;strong&gt;1.1.1&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;开始前的准备&#34;&gt;开始前的准备&lt;/h2&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  # Set the default behavior of the sidecar for handling outbound traffic from the application:
  # ALLOW_ANY - outbound traffic to unknown destinations will be allowed, in case there are no
  #   services or ServiceEntries for the destination port
  # REGISTRY_ONLY - restrict outbound traffic to services defined in the service registry as well
  #   as those defined through ServiceEntries
  # ALLOW_ANY is the default in 1.1.  This means each pod will be able to make outbound requests 
  # to services outside of the mesh without any ServiceEntry.
  # REGISTRY_ONLY was the default in 1.0.  If this behavior is desired, set the value below to REGISTRY_ONLY.
  outboundTrafficPolicy:
    mode: ALLOW_ANY
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;Istio部署配置的&lt;code&gt;global.outboundTrafficPolicy&lt;/code&gt;参数，在1.1开始默认&lt;code&gt;ALLOW_ANY&lt;/code&gt;，这种情况下如果不配置&lt;code&gt;ServiceEntry&lt;/code&gt;，访问外包HTTP流量返回&lt;code&gt;404&lt;/code&gt;，而HTTPS流量可以正常访问，为了测试&lt;code&gt;ServiceEntry&lt;/code&gt;配置效果，将配置改为&lt;code&gt;REGISTRY_ONLY&lt;/code&gt;，方便观察&lt;code&gt;ServiceEntry&lt;/code&gt;配置的效果&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文示例Istio使用helm的values-istio-demo.yaml配置安装&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;部署测试用例&lt;code&gt;sleep&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.1/samples/sleep/sleep.yaml

$ export SOURCE_POD=$(kubectl get pod -l app=sleep -o jsonpath={.items..metadata.name})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;code&gt;outboundTrafficPolicy=ALLOW_ANY&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://hbchen.com
HTTP/1.1 404 Not Found

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 404 Not Found

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
HTTP/2 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改&lt;code&gt;values-istio-demo.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  outboundTrafficPolicy:
    mode: REGISTRY_ONLY
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新部署Istio&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system --values install/kubernetes/helm/istio/values-istio-demo.yaml | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新部署测试用例&lt;code&gt;sleep&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl delete -f https://raw.githubusercontent.com/istio/istio/release-1.1/samples/sleep/sleep.yaml
$ kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.1/samples/sleep/sleep.yaml

$ export SOURCE_POD=$(kubectl get pod -l app=sleep -o jsonpath={.items..metadata.name})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sidecar方式&#34;&gt;Sidecar方式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/istio/egress-sidecar.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;http&#34;&gt;HTTP&lt;/h3&gt;

&lt;p&gt;先定义一个&lt;code&gt;ServiceEntry&lt;/code&gt;，开启&lt;code&gt;www.aliyun.com&lt;/code&gt;、&lt;code&gt;hbchen.com&lt;/code&gt;的外部访问&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http
    protocol: HTTP
  resolution: NONE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://hbchen.com
HTTP/1.1 200 OK

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 301 Moved Permanently
...
command terminated with exit code 35

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
command terminated with exit code 35
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http-https&#34;&gt;HTTP &amp;amp; HTTPS&lt;/h3&gt;

&lt;p&gt;只开&lt;code&gt;80&lt;/code&gt;端口，&lt;code&gt;HTTP&lt;/code&gt;正常，而对于&lt;code&gt;HTTPS&lt;/code&gt;以及有&lt;code&gt;HTTP&lt;/code&gt;重定向&lt;code&gt;HTTPS&lt;/code&gt;的请求仍会失败&lt;code&gt;command terminated with exit code 35&lt;/code&gt;，所以实践中外部服务一般同时开启&lt;code&gt;80&lt;/code&gt;、&lt;code&gt;443&lt;/code&gt;端口&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http-port
    protocol: HTTP
  - number: 443
    name: https-port
    protocol: HTTPS
  resolution: NONE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 301 Moved Permanently
...
HTTP/2 200

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
HTTP/2 200
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http转tls&#34;&gt;HTTP转TLS&lt;/h3&gt;

&lt;p&gt;这时我们看到另一个问题，需要升级&lt;code&gt;HTTPS&lt;/code&gt;的&lt;code&gt;HTTP&lt;/code&gt;请求每次都要&lt;code&gt;301&lt;/code&gt;重定向一次，在不修改代码的情况下可以在&lt;code&gt;proxy&lt;/code&gt;将&lt;code&gt;HTTP&lt;/code&gt;请求升级为&lt;code&gt;TLS&lt;/code&gt;，避免二次跳转，需要加&lt;code&gt;VirtualService&lt;/code&gt; + &lt;code&gt;DestinationRule&lt;/code&gt;来实现。&lt;/p&gt;

&lt;p&gt;在官方示例&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/egress-tls-origination/#%E5%87%BA%E5%8F%A3%E6%B5%81%E9%87%8F%E7%9A%84-tls&#34;&gt;出口流量的-tls&lt;/a&gt;中，仅将&lt;code&gt;HTTP&lt;/code&gt;升级到&lt;code&gt;TLS&lt;/code&gt;，而对正常的&lt;code&gt;HTTPS&lt;/code&gt;没有支持，这里稍作改动，在&lt;code&gt;VirtualService&lt;/code&gt;中为&lt;code&gt;80&lt;/code&gt;端口的&lt;code&gt;destination&lt;/code&gt;定义&lt;code&gt;subset&lt;/code&gt;，这样在&lt;code&gt;DestinationRule&lt;/code&gt;中默认&lt;code&gt;trafficPolicy&lt;/code&gt;不做处理，仅对指定的&lt;code&gt;subset&lt;/code&gt;做&lt;code&gt;HTTPS&lt;/code&gt;转发，使网格内无论发起&lt;code&gt;HTTP&lt;/code&gt;还是&lt;code&gt;HTTPS&lt;/code&gt;的外网请求都可以正常访问。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http-port
    protocol: HTTP
  - number: 443
    name: https-port
    protocol: HTTPS
  resolution: DNS
  location: MESH_EXTERNAL
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: rewrite-port-for-entry
spec:
  hosts:
  - www.aliyun.com
  http:
  - match:
      - port: 80
    route:
    - destination:
        # NOTE: 为HTTP升级流量指定subset
        subset: originate-tls
        host: www.aliyun.com
        port:
          number: 443
  tls:
  - match:
      - port: 443
        sniHosts:
        - www.aliyun.com
    route:
    - destination:
        host: www.aliyun.com
        port:
          number: 443
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: originate-tls-for-entry
spec:
  host: www.aliyun.com
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - name: originate-tls
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
        portLevelSettings:
        - port:
            number: 443
          tls:
            mode: SIMPLE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://hbchen.com
HTTP/1.1 200 OK

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 200 OK

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
HTTP/2 200
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gateway方式&#34;&gt;Gateway方式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/istio/egress-gateway.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方示例&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/egress-gateway/&#34;&gt;配置 Egress gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gateway与Sidecar的区别是将出口流量都转到&lt;code&gt;egressgateway&lt;/code&gt;，再由Gateway进行转发处理，无论Gateway还是Sidecar&lt;code&gt;ServiceEntry&lt;/code&gt;的配置规则都是需要的，这里我们直接开启&lt;code&gt;80&lt;/code&gt;、&lt;code&gt;433&lt;/code&gt;，注意&lt;code&gt;resolution&lt;/code&gt;=&lt;code&gt;DNS&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  ports:
  - number: 80
    name: http-port
    protocol: HTTP
  - number: 443
    name: https-port
    protocol: HTTPS
  resolution: DNS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;访问测试（略）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;http-1&#34;&gt;HTTP&lt;/h3&gt;

&lt;p&gt;流程如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR;
   S[Siedcar]--&amp;gt;|&amp;quot;①HTTP&amp;quot;|VS[VirtualService&amp;lt;br/&amp;gt;www.aliyun.com]
   VS--&amp;gt;|&amp;quot;②gateway=mesh&amp;quot;|EG[EgressGateway]
   EG--&amp;gt;|&amp;quot;③HTTP&amp;quot;|VS
   VS--&amp;gt;|&amp;quot;④gateway=istio-egressgateway&amp;quot;|E[External]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-egressgateway
spec:
  selector:
    istio: egressgateway
  servers:
  - port:
      number: 80
      name: http-port
      protocol: HTTP
    hosts:
    - www.aliyun.com
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: egressgateway-for-aliyun
spec:
  host: istio-egressgateway.istio-system.svc.cluster.local
  subsets:
  - name: aliyun
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: aliyun-through-egress-gateway
spec:
  hosts:
  - www.aliyun.com
  gateways:
  - istio-egressgateway
  - mesh
  http:
  - match:
    - gateways:
      - mesh
      port: 80
    route:
    - destination:
        host: istio-egressgateway.istio-system.svc.cluster.local
        subset: aliyun
        port:
          number: 80
      weight: 100
  - match:
    - gateways:
      - istio-egressgateway
      port: 80
    route:
    - destination:
        host: www.aliyun.com
        port:
          number: 80
      weight: 100
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;(&lt;em&gt;这里只有HTTP&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 301 Moved Permanently
...
HTTP/2 200
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http转tls-1&#34;&gt;HTTP转TLS&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR;
   S[Siedcar]--&amp;gt;|&amp;quot;①HTTP&amp;quot;|VS[VirtualService&amp;lt;br/&amp;gt;www.aliyun.com]
   VS--&amp;gt;|&amp;quot;②gateway=mesh&amp;quot;|EG[EgressGateway]
   EG--&amp;gt;|&amp;quot;③HTTP&amp;quot;|VS
   VS--&amp;gt;|&amp;quot;④gateway=istio-egressgateway&amp;lt;br/&amp;gt;DestinationRule为Subset升级TLS&amp;quot;|E[External]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;与Sidecar方式类似，对于有&lt;code&gt;HTTP&lt;/code&gt;重定向到&lt;code&gt;HTTPS&lt;/code&gt;的流量可以在Gateway代理直接升级为&lt;code&gt;TLS&lt;/code&gt;，减少跳转，实现方式与Sidecar方式类似，为&lt;code&gt;HOST&lt;/code&gt;增加&lt;code&gt;DestinationRule&lt;/code&gt;规则为&lt;code&gt;HTTP&lt;/code&gt;流量发起&lt;code&gt;TLS&lt;/code&gt;请求。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-egressgateway
spec:
  selector:
    istio: egressgateway
  servers:
  - port:
      number: 80
      name: http-port
      protocol: HTTP
    hosts:
    - www.aliyun.com
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: egressgateway-for-aliyun
spec:
  host: istio-egressgateway.istio-system.svc.cluster.local
  subsets:
  - name: aliyun
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: aliyun-through-egress-gateway
spec:
  hosts:
  - www.aliyun.com
  gateways:
  - istio-egressgateway
  - mesh
  http:
  - match:
    - gateways:
      - mesh
      port: 80
    route:
    - destination:
        host: istio-egressgateway.istio-system.svc.cluster.local
        subset: aliyun
        port:
          number: 80
      weight: 100
  - match:
    - gateways:
      - istio-egressgateway
      port: 80
    route:
    - destination:
        host: www.aliyun.com
        # NOTE: 为HTTP升级流量指定subset
        subset: originate-tls
        port:
          number: 443
      weight: 100
---
# NOTE: 注意这里与Sidecar方式类似，需要对HTTP流量单独配置subset，否则影响正常HTTPS流量
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: originate-tls-for-aliyun
spec:
  host: www.aliyun.com
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - name: originate-tls
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
        portLevelSettings:
        - port:
            number: 443
          tls:
            mode: SIMPLE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 200 OK
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;双向&lt;code&gt;TLS&lt;/code&gt;、&lt;code&gt;HTTTPS&lt;/code&gt;透传等这里没有再做测试，有兴趣可以参考官方示例&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/egress-gateway/&#34;&gt;配置 Egress gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;直接调用外部服务&#34;&gt;直接调用外部服务&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/istio/egress-sidecar-ip.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Istio文档&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/egress/#%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1&#34;&gt;直接调用外部服务&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;需要修改helm的values配置更新部署。并且要让新的&lt;code&gt;istio-sidecar-injector&lt;/code&gt;生效，重新部署&lt;code&gt;sleep&lt;/code&gt;用例。这种方式在Sidecar的Proxy中跳过了外部IP，虽然也有&lt;code&gt;excludeIPRanges&lt;/code&gt;方式，但修改麻烦需要更新sidecar，并且这样也失去了Istio的其它能力，所以不怎么实用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  proxy:
    # Minikube
    includeIPRanges: &amp;quot;10.0.0.1/24&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ServiceEntry&lt;/code&gt;配合&lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt;可以使外部流量做比较灵活的管控，并且可以对外部服务使用流量管理的相关功能，Gateway相对Sidecar配置还是略显复杂，而在性能方面官方Blog&lt;a href=&#34;https://istio.io/zh/blog/2019/egress-performance/&#34;&gt;Egress gateway 性能测试&lt;/a&gt;给出的比较结果两者相差不大，至于直接调用方式相对就不怎么实用了。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio源码】Pilot Agent</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-31-istio-code-pilot-agent/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-31-istio-code-pilot-agent/</guid>
      
        <description>&lt;p&gt;接上一篇&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-03-17-istio-code-pilot-discovery/&#34;&gt;《【Istio源码】Pilot Discovery》&lt;/a&gt;，这篇继续分析&lt;strong&gt;Pilot&lt;/strong&gt;的&lt;code&gt;pilot-agent&lt;/code&gt;模块。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pilot-agent&lt;/code&gt;相对&lt;code&gt;pilot-discovery&lt;/code&gt;在控制平面比较简单，&lt;strong&gt;agent&lt;/strong&gt;更多的能力是在数据平面的&lt;code&gt;envoy&lt;/code&gt;，&lt;code&gt;envoy&lt;/code&gt;通过&lt;code&gt;xDS&lt;/code&gt;协议与&lt;code&gt;pilot-discovery&lt;/code&gt;服务进行通信。agent主要负责监控&lt;code&gt;ingress&lt;/code&gt;、&lt;code&gt;mTLS&lt;/code&gt;的证书，发生变更后重启&lt;code&gt;envoy&lt;/code&gt;，以及提供&lt;strong&gt;agent&lt;/strong&gt;状态的HTTP服务(&lt;em&gt;可选服务&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant a as agent
    participant pa as proxy/agent
    participant ew as envoy/watcher
    participant ep as envoy/proxy
    participant s as status
    participant fw as fsnotify.Watcher 
    
    Note over a,fw: agent状态服务
    a -&amp;gt;&amp;gt; s: NewServer()
    s --&amp;gt;&amp;gt; a: statusServer *Server
    a -&amp;gt;&amp;gt; s: statusServer.Run()

    a -&amp;gt;&amp;gt; ep: NewProxy(proxyConfig)
    ep --&amp;gt;&amp;gt; a: envoyProxy proxy.Proxy
    a -&amp;gt;&amp;gt; pa: NewAgent(envoyProxy)
    pa --&amp;gt; a: agent Agent
    a -&amp;gt;&amp;gt; ew: NewWatcher(agent.ConfigCh)，updates = agent.ConfigCh
    ew --&amp;gt;&amp;gt; a: watcher Watcher
    
    Note over a,fw: watcher监控配置变更，通知agent重启envoy
    loop: go
        a -&amp;gt;&amp;gt; ew: watcher.Run()
        ew -&amp;gt;&amp;gt; fw: fw.Watch(certs)，AuthCertsPath、IngressCertsPath
        fw --&amp;gt;&amp;gt; ew: w.watchFileEvents()
        ew -&amp;gt;&amp;gt; ew: &amp;lt;-timeChan，10s延迟
        ew -&amp;gt;&amp;gt; ew: SendConfig()
        ew -&amp;gt;&amp;gt; pa: updates&amp;lt;-
        Note over pa: &amp;lt;-configCh
    end    
    
    Note over a,fw: agent做envoy重启操作，包括频率控制、失败重试等
    loop : go
        a -&amp;gt;&amp;gt; pa: agent.Run()
        Note over pa: rateLimiter.Wait()&amp;lt;br/&amp;gt;控制频率
        alt &amp;lt;-configCh
            Note over pa: 配置更新Envoy热重启&amp;lt;br/&amp;gt;reconcile()
        else &amp;lt;-statusCh  
            Note over pa: Envoy重启后通知处理&amp;lt;br/&amp;gt;失败重试逻辑
        else &amp;lt;-reconcileTimer.C
            Note over pa: 失败重试计时重启&amp;lt;br/&amp;gt;reconcile()
        end
    end
    
    loop: envoy重启
        pa -&amp;gt;&amp;gt; pa: reconcile()
        Note over ep: 默认服务发现地址:&amp;lt;br/&amp;gt;istio-pilot:15010&amp;lt;br/&amp;gt;对应pilot-discovery的地址:&amp;lt;br/&amp;gt;gRPC port:15010
        pa -&amp;gt;&amp;gt; ep: proxy.Run(&amp;lt;-abort)
        ep --&amp;gt;&amp;gt; pa: err error
        pa -&amp;gt;&amp;gt; pa: statusCh&amp;lt;-
    end
    
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio源码】Pilot Discovery</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-17-istio-code-pilot-discovery/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-17-istio-code-pilot-discovery/</guid>
      
        <description>&lt;p&gt;流量管理是网格的基础，Pilot负责三个主要功能：服务治理&lt;code&gt;istio-pilot&lt;/code&gt;、Sidecar注入&lt;code&gt;istio-sidecar-injector&lt;/code&gt;、以及Sidecar&lt;code&gt;istio-proxy&lt;/code&gt;，
分别由三个模块负责：&lt;code&gt;pilot-discovery&lt;/code&gt;、&lt;code&gt;sidecar-injector&lt;/code&gt;、&lt;code&gt;pilot-agent&lt;/code&gt;，这里从&lt;code&gt;pilot-discovery&lt;/code&gt;开始。&lt;/p&gt;

&lt;h2 id=&#34;discovery运行序列&#34;&gt;Discovery运行序列&lt;/h2&gt;

&lt;h3 id=&#34;kube环境简化序列&#34;&gt;kube环境简化序列&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant s as server
    participant f as fileWatcher
    participant i as k8s.io/client-go&amp;lt;br/&amp;gt;informer
    participant h as handler
    
    Note over s: mesh
    s -&amp;gt;&amp;gt; f: addFieWatcher()
    Note over s: meshNetworks
    s -&amp;gt;&amp;gt; f: addFileWatcher()
    Note over s: config
        loop IstioConfigTypes
        s -&amp;gt;&amp;gt; i: cache.NewSharedIndexInformer()
        end
    Note over s: service
        activate i
        s -&amp;gt;&amp;gt; i: Services().Informer()
        s -&amp;gt;&amp;gt; i: Endpoints().Informer()
        s -&amp;gt;&amp;gt; i: Nodes().Informer()
        s -&amp;gt;&amp;gt; i: Pods().Informer()
        deactivate i
    Note over s: discovery
        activate h
        s -&amp;gt;&amp;gt; h: service.AppendServiceHandler()
        s -&amp;gt;&amp;gt; h: service.AppendInstanceHandler()
        s -&amp;gt;&amp;gt; h: config.RegisterEventHandler()
        deactivate h
    alt fsnotify
        f -&amp;gt;&amp;gt; s: fsnotify.Event()
        s -&amp;gt;&amp;gt; s: ds.ConfigUpdate()
    end
        
    alt K8S
        i -&amp;gt;&amp;gt; h: handler.Apply()
        loop handler.funcs
            h -&amp;gt;&amp;gt; s: Event Handler
            s -&amp;gt;&amp;gt; s: ds.ConfigUpdate()
        end
    end
    activate s
    s -&amp;gt;&amp;gt; s: pushChannel &amp;lt;- XdsEvent
    s -&amp;gt;&amp;gt; s: ds.StreamAggregatedResources()Push到xDS
    deactivate s

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;详细序列&#34;&gt;详细序列&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant b as bootstrap
    participant kc as k8s.io/client-go
    participant cmd as cmd
    participant c as config/&amp;lt;br/&amp;gt;aggregate&amp;lt;br/&amp;gt;kube&amp;lt;br/&amp;gt;……
    
    participant k as kube
    participant m as model
    participant pe as proxy/envoy
    participant sr as serviceregistry
    
    
    b -&amp;gt;&amp;gt; b: NewServer()
    Note left of b: initKubeClient()
    b -&amp;gt;&amp;gt; k: kube.CreateClientset()
    k --&amp;gt;&amp;gt; b: kubeClient *kubernetes.Clientset
    
    Note left of b: 网格配置&amp;lt;br/&amp;gt;initMesh()
        Note over kc,cmd: 默认ConfigFile&amp;lt;br/&amp;gt;/etc/istio/config/mesh
        alt args.Mesh.ConfigFile != &amp;quot;&amp;quot;
        b -&amp;gt;&amp;gt; cmd: cmd.ReadMeshConfig(args.Mesh.ConfigFile)
        cmd --&amp;gt;&amp;gt; b: mesh *meshconfig.MeshConfig
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;️addFileWatcher(args.Mesh.ConfigFile)&amp;lt;br/&amp;gt;mesh reload&amp;lt;br/&amp;gt;✅s.EnvoyXdsServer.ConfigUpdate()
        else K8s ConfigMap 获取配置
        b -&amp;gt;&amp;gt; b: GetMeshConfig(s.kubeClient, kube.IstioNamespace, kube.IstioConfigMap)
        b -&amp;gt;&amp;gt; m: model.DefaultMeshConfig()/model.ApplyMeshConfigDefaults(cfgYaml)
        m --&amp;gt;&amp;gt; b: mesh meshconfig.MeshConfig
        end
    
    Note left of b: Mesh网络配置&amp;lt;br/&amp;gt;initMeshNetworks()
        Note over kc,cmd: 默认NetworksConfigFile&amp;lt;br/&amp;gt;/etc/istio/config/meshNetworks
        alt args.NetworksConfigFile != &amp;quot;&amp;quot;
        b -&amp;gt;&amp;gt; cmd: cmd.ReadMeshNetworksConfig()
        cmd --&amp;gt;&amp;gt; b: meshNetworks *meshconfig.MeshNetworks
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;addFileWatcher(args.NetworksConfigFile)&amp;lt;br/&amp;gt;meshNetworks reload&amp;lt;br/&amp;gt;✅s.EnvoyXdsServer.ConfigUpdate()
        end
    
    Note left of b: Mixer&amp;lt;br/&amp;gt;initMixerSan()
        alt s.mesh.DefaultConfig.ControlPlaneAuthPolicy == meshconfig.AuthenticationPolicy_MUTUAL_TLS
        b -&amp;gt;&amp;gt; pe: envoy.GetMixerSAN(args.Namespace)
        pe -&amp;gt;&amp;gt; b: SpiffeURI string
        Note over kc,cmd: s.mixerSAN[SpiffeURI]&amp;lt;br/&amp;gt;NewDiscoveryService的Env
        end
    
    Note left of b: 配置管理&amp;lt;br/&amp;gt;initConfigController()
        alt len(args.MCPServerAddrs) &amp;gt; 0 || len(s.mesh.ConfigSources) &amp;gt; 0
        Note over kc,cmd: s.initMCPConfigController()
            Note over kc,cmd: var clients []*client.Client&amp;lt;br/&amp;gt;var clients2 []*sink.Client&amp;lt;br/&amp;gt;var conns []*grpc.ClientConn&amp;lt;br/&amp;gt;var configStores []model.ConfigStoreCache
            loop s.mesh.ConfigSources
                alt url.Scheme == fsScheme
                b -&amp;gt;&amp;gt; c: memory.NewController(store)
                c --&amp;gt;&amp;gt; b: configController model.ConfigStoreCache
                Note over kc,cmd: configStores = append(configStores, configController)
                else
                b -&amp;gt;&amp;gt; c: coredatamodel.NewController()
                c --&amp;gt;&amp;gt; b: mcpController CoreDataModel
                Note over kc,cmd: clients = append(clients, mcpClient)&amp;lt;br/&amp;gt;clients2 = append(clients2, mcpClient2)&amp;lt;br/&amp;gt;mcpController是MCP Client的Updater&amp;lt;br/&amp;gt;当Client端收到Response时&amp;lt;br/&amp;gt;通过Updater.Apply()接口通知更新
                Note over kc,cmd: conns = append(conns, conn)&amp;lt;br/&amp;gt;configStores = append(configStores, mcpController)
                end
            end
            
            alt len(configStores) == 0
            Note over kc,cmd: ConfigSources未加载配置&amp;lt;br/&amp;gt;从MCPServerAddrs加载
            loop args.MCPServerAddrs
            b -&amp;gt;&amp;gt; c: coredatamodel.NewController()
            c --&amp;gt;&amp;gt; b: mcpController CoreDataModel
            Note over kc,cmd: conns = append(conns, conn)&amp;lt;br/&amp;gt;configStores = append(configStores, mcpController)
            end
            end
            
            
            Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc(go func() {client.Run(ctx)}())&amp;lt;br/&amp;gt;MCP Clients启动&amp;lt;br/&amp;gt;接收到Response通知mcpController&amp;lt;br/&amp;gt;Apply(*Change)&amp;lt;br/&amp;gt;model.ServiceEntry.Type的修改通知到serviceEntryEvents()&amp;lt;br/&amp;gt;❗在external.NewServiceDiscovery()有model.ServiceEntry.Type的handler
            Note over kc,cmd: 配置汇总
            b -&amp;gt;&amp;gt; c: configaggregate.MakeCache(configStores)
            c --&amp;gt;&amp;gt; b: aggregateMcpController model.ConfigStoreCache
            
        else args.Config.Controller != nil
        Note over kc,cmd: s.configController = args.Config.Controller
        else args.Config.FileDir != &amp;quot;&amp;quot;
        Note over kc,cmd: configController := memory.NewController(store)
        else 默认KubeConfig
        Note over kc,cmd: controller, err := s.makeKubeConfigController(args)
        end
        
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc ( go s.configController.Run(stop) )&amp;lt;br/&amp;gt;配置Controller启动&amp;lt;br/&amp;gt;处理配置变更的EventHandler&amp;lt;br/&amp;gt;memory、kube.crd的Controller有Run()实现
        Note over kc,cmd: memory通过makeFileMonitor()监控文件&amp;lt;br/&amp;gt;接收资源变更时更新configStore&amp;lt;br/&amp;gt;并通过monitor.ScheduleProcessEvent()分发事件&amp;lt;br/&amp;gt;❗RegisterEventHandler将handler Append到monitor的handlers
        Note over kc,cmd: kube.crd.cacheHandler运行informer&amp;lt;br/&amp;gt;informer监控不同ConfigType&amp;lt;br/&amp;gt;informer将资源Add、Update、Delete事件统一压入Queue&amp;lt;br/&amp;gt;Queue Run()逐个事件处理，即cacheHandler的hander.funcs&amp;lt;br/&amp;gt;❗RegisterEventHandler将handler Append到hander.funcs
        Note over b,c: 💚💚💚💚💚&amp;lt;br/&amp;gt;RegisterEventHandler()&amp;lt;br/&amp;gt;&amp;lt;br/&amp;gt;❗在Discovery和ServiceRegistry有handler注册
        
        alt hasKubeRegistry(args) &amp;amp;&amp;amp; s.mesh.IngressControllerMode != meshconfig.MeshConfig_OFF
        Note over kc,cmd: K8s ingress的ConfigController
        b -&amp;gt;&amp;gt; c: ingress.NewController()
        c --&amp;gt;&amp;gt; b: ingress model.ConfigStoreCache
        b -&amp;gt;&amp;gt; c: configaggregate.MakeCache(s.configController, ingress)
        c --&amp;gt;&amp;gt; b: configController model.ConfigStoreCache
        b -&amp;gt;&amp;gt; c: ingress.NewStatusSyncer()
        c --&amp;gt;&amp;gt; b: ingressSyncer *StatusSyncer
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc ( go ingressSyncer.Run(stop) )&amp;lt;br/&amp;gt;Ingress Syncer启动
        end
        b -&amp;gt;&amp;gt; m: model.MakeIstioStore(s.configController)
        m --&amp;gt;&amp;gt; b: istioConfigStore IstioConfigStore
        Note over b,c: 💚💚💚💚💚&amp;lt;br/&amp;gt;istioConfigStore提供Istio配置获取&amp;lt;br/&amp;gt;主要为ConfigStore的List()接口
    
    Note left of b: 服务注册&amp;lt;br/&amp;gt;initServiceControllers()
        b -&amp;gt;&amp;gt; sr: aggregate.NewController()
        sr --&amp;gt;&amp;gt; b: serviceControllers *Controller
        loop args.Service.Registries
        Note over b,c: 💚💚💚💚💚&amp;lt;br/&amp;gt;多注册中心&amp;lt;br/&amp;gt;Controller通过AppendServiceHandler()、AppendInstanceHandler()接收外部Handler&amp;lt;br/&amp;gt;在有变更时轮询Handler&amp;lt;br/&amp;gt;❗Discovery会AppendHandler
        alt serviceregistry.MockRegistry
        b -&amp;gt;&amp;gt; b: s.initMemoryRegistry()
        b -&amp;gt;&amp;gt; sr: srmemory.NewDiscovery() aggregate.Registry{}
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        else serviceregistry.KubernetesRegistry
        b -&amp;gt;&amp;gt; b: s.createK8sServiceControllers()
        b -&amp;gt;&amp;gt; sr: kube.NewController()
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        else serviceregistry.ConsulRegistry
        b -&amp;gt;&amp;gt; b: s.initConsulRegistry()
        b -&amp;gt;&amp;gt; sr: consul.NewController()
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        else serviceregistry.MCPRegistry
        Note over kc,cmd: no-op: get service info from MCP ServiceEntries.
        end
        end
        b -&amp;gt;&amp;gt; sr: external.NewServiceDiscovery()
        sr --&amp;gt;&amp;gt; b: serviceEntryStore *ServiceEntryStore
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc()&amp;lt;br/&amp;gt;服务注册Controllers启动
    
    Note left of b: 服务发现&amp;lt;br/&amp;gt;initDiscoveryService()&amp;lt;br/&amp;gt;gRPC和HTTP服务
        b -&amp;gt;&amp;gt; pe: envoy.NewDiscoveryService()
        Note over b,c: 💚💚💚💚💚ds.clearCache()封装为Handler&amp;lt;br/&amp;gt;接收s.ServiceController、s.configController的变更通知&amp;lt;br/&amp;gt;✅s.ServiceController.AppendServiceHandler()&amp;lt;br/&amp;gt;✅s.ServiceController.AppendInstanceHandler()&amp;lt;br/&amp;gt;✅s.configController.RegisterEventHandler()
        pe --&amp;gt;&amp;gt; b: discovery *DiscoveryService
        Note over kc,cmd: HTTP&amp;lt;br/&amp;gt;envoy.DiscoveryService提供/v1/registration以及/debug/pprof/* REST接口
        b --&amp;gt; b: s.mux = discovery.RestContainer.ServeMux
        b -&amp;gt;&amp;gt; pe: envoyv2.NewDiscoveryServer()
        pe --&amp;gt;&amp;gt; b: s.EnvoyXdsServer *DiscoveryServer
        Note over kc,cmd: gRPC&amp;lt;br/&amp;gt;envoyv2.DiscoveryServer&amp;lt;br/&amp;gt;只提供StreamAggregatedResources()服务&amp;lt;br/&amp;gt;xDS管理
        Note over kc,cmd: s.initGrpcServer()&amp;lt;br/&amp;gt;s.httpServer&amp;lt;br/&amp;gt;http.Server{Handler: s.mux}        
        Note over kc,cmd: http listener&amp;lt;br/&amp;gt;grpc listener
        Note over b,c: ❤️❤️❤️️❤️❤️️s.addStartFunc()&amp;lt;br/&amp;gt;s.httpServer.Serve()&amp;lt;br/&amp;gt;s.grpcServer.Serve()
        alt args.DiscoveryOptions.SecureGrpcAddr != &amp;quot;&amp;quot;
        b -&amp;gt;&amp;gt; b: initSecureGrpcServer()
            Note over kc,cmd: s.secureGRPCServer&amp;lt;br/&amp;gt;s.secureHTTPServer
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc()&amp;lt;br/&amp;gt;s.secureHTTPServer.ServeTLS()
        end
        
        Note right of b: 
    
    Note left of b: 监控&amp;lt;br/&amp;gt;initMonitor()
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc()&amp;lt;br/&amp;gt;startMonitor()
    
    Note left of b: 集群&amp;lt;br/&amp;gt;initClusterRegistries()
        b -&amp;gt;&amp;gt; c: clusterregistry.NewMulticluster()
        c --&amp;gt;&amp;gt; b: multicluster *Multicluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;discovery-server流程&#34;&gt;Discovery Server流程&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
    
    
    s(ads.StreamAggregatedResources)
    style s fill:#f9f
    s --&amp;gt; rc(reqChannel)
    s --&amp;gt; pc(pushChannel)
    style rc fill:#f9f
    style pc fill:#f9f
    
    subgraph reqChannel
        rc --&amp;gt; dt{discReq.TypeUrl}
        dt --&amp;gt;|ClusterType| pushCds[&amp;quot;pushCds()&amp;quot;]
        dt --&amp;gt;|ListenerType| pushLds[&amp;quot;pushLds()&amp;quot;]
        dt --&amp;gt;|RouteType| pushRoute[&amp;quot;pushRoute()&amp;quot;]
        dt --&amp;gt;|EndpointType| pushEds[&amp;quot;pushEds()&amp;quot;]
    end
    
    subgraph pushChannel
        nd(&amp;quot;DiscoveryServer&amp;quot;) --&amp;gt; pr(&amp;quot;periodicRefresh&amp;quot;)
        nd --&amp;gt; ash(&amp;quot;s.ServiceController.AppendServiceHandler()&amp;quot;)
        nd --&amp;gt; aih(&amp;quot;s.ServiceController.AppendInstanceHandler()&amp;quot;)
        nd --&amp;gt; reh(&amp;quot;s.configController.RegisterEventHandler()&amp;quot;)
        ash --&amp;gt; clearCache(&amp;quot;clearCache()&amp;quot;)
        aih --&amp;gt; clearCache
        reh --&amp;gt; clearCache
        clearCache --&amp;gt;|full=true| ds(&amp;quot;ds.ConfigUpdate()&amp;quot;)
        pr --&amp;gt; pa(&amp;quot;ads.AdsPushAll()&amp;quot;)         
        
        sp(&amp;quot;ads.startPush()&amp;quot;) --&amp;gt; pc
        
        c(config) --MeshConfig/MeshNetworks/MCPConfig--&amp;gt; ds
        ds --&amp;gt; dp(&amp;quot;doPush()&amp;quot;)
        dp --&amp;gt; push(&amp;quot;Push()&amp;quot;)
        
        push --&amp;gt; pa
        pa --&amp;gt; updateCluster[&amp;quot;eds.updateCluster()&amp;quot;]
        push --&amp;gt; updateServiceShards[&amp;quot;eds.updateServiceShards()&amp;quot;]
        pa --&amp;gt; ei(&amp;quot;eds.edsIncremental()&amp;quot;)
        ei --&amp;gt; updateClusterInc(&amp;quot;eds.updateClusterInc()&amp;quot;)
        pa --&amp;gt; sp
        ei --&amp;gt; sp
        updateClusterInc --&amp;gt; updateCluster
        
        
        pc --&amp;gt; pushConn(pushConnection)
        pushConn -.-&amp;gt; C/E/L/Rds
    end
    
    nd --&amp;gt;|Serve gRPC| s
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio安全】服务间访问控制-RBAC</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/</guid>
      
        <description>&lt;p&gt;Istio提供了非常易用的安全解决方案，包括服务间身份验证&lt;code&gt;mTLS&lt;/code&gt;，服务间访问控制&lt;code&gt;RBAC&lt;/code&gt;，以及终端用户身份验证&lt;code&gt;JWT&lt;/code&gt;等，本文主要介绍如何使用服务间访问控制，同时涉及&lt;code&gt;双向TLS&lt;/code&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Istio版本 &lt;strong&gt;1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;在的&lt;a href=&#34;https://github.com/hb-go/micro-mesh&#34;&gt;github.com/hb-go/micro-mesh&lt;/a&gt;中有结合示例的&lt;a href=&#34;https://github.com/hb-go/micro-mesh/tree/master/deploy/k8s/rbac&#34;&gt;RBAC配置实践&lt;/a&gt;可以参考&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;要实现&lt;code&gt;RBAC&lt;/code&gt;主要理解以下几个类型的&lt;code&gt;yaml&lt;/code&gt;配置，以及之间的关系：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#双向tls&#34;&gt;双向TLS&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Policy&lt;/code&gt;或&lt;code&gt;MeshPolicy&lt;/code&gt;，上游&lt;code&gt;server&lt;/code&gt;开启TLS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DestinationRule&lt;/code&gt;，下游&lt;code&gt;client&lt;/code&gt;开启TLS&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rbac&#34;&gt;RBAC&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ClusterRbacConfig&lt;/code&gt;/&lt;code&gt;RbacConfig&lt;/code&gt;，启用授权及范围&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ServiceRole&lt;/code&gt;，角色权限规则&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ServiceRoleBinding&lt;/code&gt;，角色绑定规则&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optional&#34;&gt;Optional&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ServiceAccount&lt;/code&gt;，&lt;code&gt;ServiceRoleBinding&lt;/code&gt;.&lt;code&gt;subjects&lt;/code&gt;的&lt;code&gt;user&lt;/code&gt;条件
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;假设场景&#34;&gt;假设场景&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;网格内&lt;code&gt;service-1&lt;/code&gt;、&lt;code&gt;service-2&lt;/code&gt;开启RBAC访问控制&lt;/li&gt;
&lt;li&gt;仅&lt;code&gt;service-1&lt;/code&gt;授权给&lt;code&gt;ingressgateway&lt;/code&gt;访问，&lt;code&gt;service-2&lt;/code&gt;则不能被&lt;code&gt;ingressgateway&lt;/code&gt;访问&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-chen/hbchen.com/master/static/img/istio-tls-rbac.png&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;双向tls&#34;&gt;双向TLS&lt;/h2&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E8%AE%A4%E8%AF%81&#34;&gt;Istio文档-认证策略&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E8%AE%A4%E8%AF%81%E7%AD%96%E7%95%A5&#34;&gt;认证策略&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/authn-policy/&#34;&gt;Istio文档-基础认证策略&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/authn-policy/#%E4%B8%BA%E7%BD%91%E6%A0%BC%E4%B8%AD%E7%9A%84%E6%89%80%E6%9C%89%E6%9C%8D%E5%8A%A1%E5%90%AF%E7%94%A8%E5%8F%8C%E5%90%91-tls-%E8%AE%A4%E8%AF%81&#34;&gt;为网格中的所有服务启用双向 TLS 认证&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;1-上游-server-开启tls&#34;&gt;1.上游&lt;code&gt;server&lt;/code&gt;开启TLS&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;a href=&#34;##&#34;&gt;策略范围说明&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网格范围策略&lt;/strong&gt;：在网格范围存储中定义的策略，没有目标选择器部分。网格中最多只能有&lt;strong&gt;一个网格范围&lt;/strong&gt;的策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;命名空间范围的策略&lt;/strong&gt;：在命名空间范围存储中定义的策略，名称为 default 且没有目标选择器部分。每个命名空间最多只能有&lt;strong&gt;一个命名空间范围&lt;/strong&gt;的策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特定于服务的策略&lt;/strong&gt;：在命名空间范围存储中定义的策略，具有非空目标选择器部分。命名空间可以具有&lt;strong&gt;零个，一个或多个特定于服务&lt;/strong&gt;的策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;策略范围可以分别由&lt;code&gt;Policy&lt;/code&gt;、&lt;code&gt;MeshPolicy&lt;/code&gt;设置，&lt;code&gt;Policy&lt;/code&gt;可以选择对&lt;strong&gt;命名空间&lt;/strong&gt;所有服务生效，也可以指定&lt;code&gt;targets&lt;/code&gt;对&lt;strong&gt;特定服务&lt;/strong&gt;生效，&lt;code&gt;MeshPolicy&lt;/code&gt;则是整个网格内生效，对于&lt;strong&gt;命名空间范围&lt;/strong&gt;和&lt;strong&gt;网格范围&lt;/strong&gt;名称都只能为&lt;code&gt;default&lt;/code&gt;。&lt;/br&gt;
同时配置多个策略时使用最窄匹配策略，&lt;strong&gt;特定服务&amp;gt;命名空间范围&amp;gt;网格范围&lt;/strong&gt;，如果多个&lt;strong&gt;特定于服务的策略&lt;/strong&gt;与服务匹配，则随机选择一个。下面是不同策略范围的具体配置参考：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;Policy&lt;/code&gt;特定于服务的策略&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;targets&lt;/code&gt;支持&lt;code&gt;name&lt;/code&gt;以及&lt;code&gt;ports&lt;/code&gt;列表&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;authentication.istio.io/v1alpha1&amp;quot;
kind: &amp;quot;Policy&amp;quot;
metadata:
  name: &amp;quot;policy-name&amp;quot;
spec:
  targets:
  - name: service-name-1
  - name: service-name-2
    ports:
    - number: 8080
  peers:
  - mtls: {}
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;Policy&lt;/code&gt;命名空间范围的策略&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;authentication.istio.io/v1alpha1&amp;quot;
kind: &amp;quot;Policy&amp;quot;
metadata:
  name: &amp;quot;default&amp;quot;
  namespace: &amp;quot;namespace-1&amp;quot;
spec:
  peers:
  - mtls: {}
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;MeshPolicy&lt;/code&gt;网格范围策略&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;authentication.istio.io/v1alpha1&amp;quot;
kind: &amp;quot;MeshPolicy&amp;quot;
metadata:
  name: &amp;quot;default&amp;quot;
spec:
  peers:
  - mtls: {}
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-下游-client-开启tls&#34;&gt;2.下游&lt;code&gt;client&lt;/code&gt;开启TLS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;client&lt;/code&gt;端TLS由目标规则&lt;code&gt;DestinationRule&lt;/code&gt;配置，在流量策略&lt;code&gt;trafficPolicy&lt;/code&gt;中开启&lt;code&gt;tls&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/reference/config/istio.networking.v1alpha3/#destinationrule&#34;&gt;Istio参考配置-通信路由#DestinationRule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/reference/config/istio.networking.v1alpha3/#trafficpolicy&#34;&gt;Istio参考配置-通信路由#TrafficPolicy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: service-name-1
spec:
  host: service-host-1
  # NOTE: 开启TLS
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
  subsets:
  - name: v1
    labels:
      version: v1
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;TLS&lt;code&gt;mode&lt;/code&gt;说明&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;mode值&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;DISABLE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;不要为上游端点使用 TLS。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SIMPLE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;向上游端点发起 TLS 连接。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;MUTUAL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;发送客户端证书进行验证，用双向 TLS 连接上游端点。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ISTIO_MUTUAL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;发送客户端证书进行验证，用双向 TLS 连接上游端点。和 MUTUAL 相比，这种方式使用的双向 TLS 证书系统是由 Istio 生成的。如果使用这种模式，TLSSettings 中的其他字段应该留空。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;rbac&#34;&gt;RBAC&lt;/h2&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E6%8E%88%E6%9D%83&#34;&gt;Istio文档-授权&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E5%90%AF%E7%94%A8%E6%8E%88%E6%9D%83&#34;&gt;启用授权&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E6%8E%88%E6%9D%83%E7%AD%96%E7%95%A5&#34;&gt;授权策略&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/role-based-access-control/&#34;&gt;Istio文档-基于角色的访问控制&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/role-based-access-control/#%E6%9C%8D%E5%8A%A1%E7%BA%A7%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6&#34;&gt;服务级的访问控制&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/setup/kubernetes/upgrade/#%E8%BF%81%E7%A7%BB-rbacconfig-%E5%88%B0-clusterrbacconfig&#34;&gt;Istio文档-迁移 RbacConfig 到 ClusterRbacConfig&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;这里使用的&lt;code&gt;ClusterRbacConfig&lt;/code&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/&#34;&gt;Istio参考配置-授权&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;有关&lt;code&gt;RbacConfig&lt;/code&gt;、&lt;code&gt;ServiceRole&lt;/code&gt;、&lt;code&gt;ServiceRoleBinding&lt;/code&gt;的属性结构Istio文档有详细的配置可以参考:&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/istio.rbac.v1alpha1/&#34;&gt;Istio参考配置-授权-RBAC&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-开启授权-clusterrbacconfig&#34;&gt;1.开启授权&lt;code&gt;ClusterRbacConfig&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;rbac.istio.io/v1alpha1&amp;quot;
kind: ClusterRbacConfig
metadata:
  name: default
  namespace: istio-system
spec:
  mode: &#39;ON_WITH_INCLUSION&#39;
  inclusion:
    #namespaces: [&amp;quot;namespace-1&amp;quot;]
    services: [&amp;quot;service-name-1.namespace-1.svc.cluster.local&amp;quot;, &amp;quot;service-name-2.namespace-1.svc.cluster.local&amp;quot;]
  # NOTE: ENFORCED/PERMISSIVE，严格或宽容模式
  enforcement_mode: ENFORCED
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;enforcement_mode&lt;/code&gt;可以选择&lt;code&gt;ENFORCED&lt;/code&gt;严格模式，或&lt;code&gt;PERMISSIVE&lt;/code&gt;宽容模式，宽容模式便于授权策略需要&lt;strong&gt;变更时进行验证测试&lt;/strong&gt;，&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/role-based-access-control/#%E6%8E%88%E6%9D%83%E8%AE%B8%E5%8F%AF%E6%A8%A1%E5%BC%8F&#34;&gt;Istio任务-授权许可模式&lt;/a&gt;任务中有更具体的场景介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模式&lt;code&gt;mode&lt;/code&gt;说明&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;mode值&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;OFF&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;关闭 Istio RBAC，RbacConfig 的所有配置将会失效，且 Istio RBAC Policies 不会执行。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ON&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;为所有 services 和 namespaces 启用 Istio RBAC。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ON_WITH_INCLUSION&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;仅针对 inclusion 字段中指定的 services 和 namespaces 启用 Istio RBAC。其它不在 inclusion 字段中的 services 和 namespaces 将不会被 Istio RBAC Policies 强制执行。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ON_WITH_EXCLUSION&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;针对除了 exclusion 字段中指定的 services 和 namespaces，启用 Istio RBAC。其它不在 exclusion 字段中的 services 和 namespaces 将按照 Istio RBAC Policies 执行。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;2-角色权限规则-servicerole&#34;&gt;2.角色权限规则&lt;code&gt;ServiceRole&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;namespace&lt;/code&gt; + &lt;code&gt;services&lt;/code&gt; + &lt;code&gt;paths&lt;/code&gt; + &lt;code&gt;methods&lt;/code&gt; 一起定义了如何访问服务，其中&lt;code&gt;services&lt;/code&gt;必选，另外有&lt;code&gt;constraints&lt;/code&gt;可以指定其它约束，支持的约束参考&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/constraints-and-properties/#%E6%94%AF%E6%8C%81%E7%9A%84%E7%BA%A6%E6%9D%9F&#34;&gt;Istio参考配置-授权-约束和属性#支持的约束&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;rbac.istio.io/v1alpha1&amp;quot;
kind: ServiceRole
metadata:
  name: service-role-1
  namespace: default
spec:
  rules:
  - services: [&amp;quot;service-name-1.namespace-1.svc.cluster.local&amp;quot;]
    methods: [&amp;quot;*&amp;quot;]
    # NOTE: 根据约束需要修改
    constraints:
    - key: request.headers[version]
      values: [&amp;quot;v1&amp;quot;, &amp;quot;v2&amp;quot;]
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-角色绑定规则-servicerolebinding&#34;&gt;3.角色绑定规则&lt;code&gt;ServiceRoleBinding&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;user&lt;/code&gt; + &lt;code&gt;properties&lt;/code&gt; 一起定义授权给谁，支持的属性参考&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/constraints-and-properties/#%E6%94%AF%E6%8C%81%E7%9A%84%E5%B1%9E%E6%80%A7&#34;&gt;Istio参考配置-授权-约束和属性#支持的属性&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;rbac.istio.io/v1alpha1&amp;quot;
kind: ServiceRoleBinding
metadata:
  name: service-rb-1
  namespace: default
spec:
  subjects:
  # NOTE: 需要添加 ServiceAccount
  - user: &amp;quot;cluster.local/ns/namespace-1/sa/service-account-2&amp;quot;
    # NOTE: 根据属性需要修改
    properties:
      source.namespace: &amp;quot;default&amp;quot;
  # NOTE: ingressgateway授权
  - user: &amp;quot;cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account&amp;quot;
  roleRef:
    kind: ServiceRole
    name: &amp;quot;service-role-1&amp;quot;
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;optional&#34;&gt;Optional&lt;/h2&gt;

&lt;h3 id=&#34;部署实例添加-serviceaccount&#34;&gt;部署实例添加&lt;code&gt;ServiceAccount&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;对于需要要在&lt;code&gt;ServiceRoleBinding&lt;/code&gt;的&lt;code&gt;subjects&lt;/code&gt;条件中授权的&lt;code&gt;user&lt;/code&gt;，需要在部署实例时指定&lt;code&gt;serviceAccountName&lt;/code&gt;，如前面&lt;code&gt;ServiceRoleBinding&lt;/code&gt;配置要允许&lt;code&gt;service-2&lt;/code&gt;访问&lt;code&gt;service-1&lt;/code&gt;，则部署&lt;code&gt;service-2&lt;/code&gt;时需要配置&lt;code&gt;serviceAccountName: service-account-2&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# NOTE: 创建ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: service-account-2
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: service-name-2-v1
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: service-name-2
        version: v1
    spec:
      # NOTE: 为部署实例指定serviceAccountName
      serviceAccountName: service-account-2
      containers:
      - name: service-name-2-v1
        command: [
          &amp;quot;/main&amp;quot;
        ]
        image: hbchen/service-2:v0.0.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 9080
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;Istio服务网格可以很方便的实现&lt;strong&gt;服务间访问控制&lt;/strong&gt;，通过服务级的授权开关，再结合&lt;code&gt;ServiceRole&lt;/code&gt;、&lt;code&gt;ServiceRoleBinding&lt;/code&gt;的约束和属性条件，可以实现细粒度的访问控制。本文未涉及Istio的终端用户身份验证，后面会结合&lt;code&gt;Ingress&lt;/code&gt;、&lt;code&gt;Egress&lt;/code&gt;的&lt;code&gt;TLS&lt;/code&gt;和&lt;code&gt;JWT&lt;/code&gt;一起分析边缘流量相关的安全问题。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio源码】Mixer</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-17-istio-code-mixer/</link>
      <pubDate>Sun, 17 Mar 2019 17:23:52 +0800</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-17-istio-code-mixer/</guid>
      
        <description>&lt;p&gt;Mixer模块为Istio提供了模块化可扩展的组件，将策略与遥测进行抽象，通过配置模型进行配置。在&lt;a href=&#34;http://hbchen.com/post/2019-03-05-custom-istio-mixer-adapter/&#34;&gt;《【Istio】自定义 Mixer Adapter示例教程(附源码)》&lt;/a&gt;中介绍了如何自定义一个Adapter，本文通过&lt;code&gt;mxier&lt;/code&gt;的源码分析，进一步了解适配器如何工作。&lt;/p&gt;

&lt;p&gt;Istio部署中有两个服务与&lt;code&gt;mixer&lt;/code&gt;有关:&lt;code&gt;istio-policy&lt;/code&gt;、&lt;code&gt;istio-telemetry&lt;/code&gt;，分别负责策略与遥测，运行的都是&lt;code&gt;mixs&lt;/code&gt;；另外&lt;code&gt;mixer&lt;/code&gt;的Client端在Sidecar&lt;code&gt;istio-proxy&lt;/code&gt;，竟像是&lt;code&gt;pilot-agent&lt;/code&gt;，镜像中的&lt;code&gt;Envoy&lt;/code&gt;是&lt;code&gt;istio/proxy&lt;/code&gt;通过&lt;code&gt;Envoy&lt;/code&gt;的&lt;code&gt;filter&lt;/code&gt;扩展了&lt;code&gt;mixerclient&lt;/code&gt;、&lt;code&gt;jwt_auth&lt;/code&gt;、&lt;code&gt;authn&lt;/code&gt;等功能。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;github.com/istio/istio &lt;strong&gt;release 1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;github.com/istio/proxy &lt;strong&gt;release 1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;mixer模块-mixs-server-执行序列&#34;&gt;Mixer模块&lt;code&gt;mixs server&lt;/code&gt;执行序列&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant s as server
    participant a as api
    participant r as runtime
    participant rd as runtine/dispatcher
    participant rc as runtime/config
    participant cs as config/store
    
    s -&amp;gt;&amp;gt; r: runtime.New()
    r --&amp;gt;&amp;gt; s: rt *Runtime
    s -&amp;gt;&amp;gt; r: p.runtimeListen(rt) —&amp;gt; rt.StartListening()
    r -&amp;gt;&amp;gt; cs: store.StartWatch()
    loop 配置监控 
    cs -&amp;gt;&amp;gt; cs: go func() { watchChan&amp;lt;-Event }
    end
    cs --&amp;gt;&amp;gt; r: &amp;lt;-watchChan
    
    loop 配置更新
    r -&amp;gt;&amp;gt; rc: go func() { WatchChanges(watchChan) }
    alt &amp;lt;-watchChan
    Note over rd,rc: &amp;lt;-watchChan Event先做堆积
    cs -&amp;gt;&amp;gt; cs: append(events, event)
    
    else &amp;lt;-timeChan
    Note over rd,rc: &amp;lt;-timeChan 计时器更新配置
    cs -&amp;gt;&amp;gt; r: onConfigChange()
    r -&amp;gt;&amp;gt; rc: ephemeral.ApplyEvent(events)
    rc -&amp;gt;&amp;gt; rc: entries Lock()，更新entries
    r -&amp;gt;&amp;gt; r: processNewConfig()
    r -&amp;gt;&amp;gt; rc: ephemeral.BuildSnapshot()
    Note right of rc: 创建配置快照&amp;lt;br/&amp;gt;entries RLock()&amp;lt;br/&amp;gt;......&amp;lt;br/&amp;gt;e.processRuleConfigs
    rc -&amp;gt;&amp;gt; rc: processXXXConfigs()
    rc --&amp;gt;&amp;gt; r: nweSnapshot *Snapshot
    Note right of r: 获得newHandlers
    r -&amp;gt;&amp;gt; r: handler.NewTable(nweSnapshot)
    Note right of r: 获得newRoutes
    r -&amp;gt;&amp;gt; r: routing.BuildTable(newHandlers, nweSnapshot)
    Note right of r: 更新RoutingContext
    r -&amp;gt;&amp;gt; rd: dispatcher.ChangeRoute(newRoutes)
    
    else &amp;lt;-stop
    Note over rd,rc: &amp;lt;-stop 退出goroutine
    cs --&amp;gt;&amp;gt; r: return
    end
    end
    
    r --&amp;gt;&amp;gt; s: nil or error
    s -&amp;gt;&amp;gt; a: api.NewGRPCServer(s.dispatcher)
    a --&amp;gt;&amp;gt; s: *MixerServer
    s -&amp;gt;&amp;gt; s: grpcServer.Serve()
    
    loop MixerServer
    activate a
    s -&amp;gt;&amp;gt; a: MixerServer Request
    Note right of a: Mixer服务逻辑
    a -&amp;gt;&amp;gt; rd: Check、Quota等调度
    activate rd
    rd -&amp;gt;&amp;gt; rd: session.dispatch()
    Note right of rd: 根据variety、ns筛选&amp;lt;br/&amp;gt;destinations
    rd -&amp;gt;&amp;gt; rd: s.rc.Routes.GetDestinations()
    Note right of rd: 等待Adapter调度完成
    rd -&amp;gt;&amp;gt; rd: s.waitForDispatched()
    rd --&amp;gt;&amp;gt; a: nil or error
    a --&amp;gt;&amp;gt; s: MixerServer Response
    deactivate rd
    deactivate s
    end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过序列分析对&lt;code&gt;mixs server&lt;/code&gt;有整体的了解，对&lt;code&gt;.yaml&lt;/code&gt;配置逻辑的理解在&lt;code&gt;runtime/config/ephemeral.go&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// BuildSnapshot builds a stable, fully-resolved snapshot view of the configuration.
func (e *Ephemeral) BuildSnapshot() (*Snapshot, error) {
	// ……
	
	// NOTE: e.entries中Kind为attributemanifest的属性，以及e.templates中Variety为TEMPLATE_VARIETY_ATTRIBUTE_GENERATOR生产的属性
	attributes := e.processAttributeManifests(monitoringCtx)
	
	// NOTE: e.entries中Kind为handler，且在e.adapters中有定义的Resource
	shandlers := e.processStaticAdapterHandlerConfigs(monitoringCtx)
	
	// NOTE: e.entries中Kind在e.templates中的Resource
	af := ast.NewFinder(attributes)
	instances := e.processInstanceConfigs(monitoringCtx, af, errs)
    
	// New dynamic configurations
	dTemplates := e.processDynamicTemplateConfigs(monitoringCtx, errs)
	dAdapters := e.processDynamicAdapterConfigs(monitoringCtx, dTemplates, errs)
	dhandlers := e.processDynamicHandlerConfigs(monitoringCtx, dAdapters, errs)
	dInstances := e.processDynamicInstanceConfigs(monitoringCtx, dTemplates, af, errs)
    
	// NOTE: 根据规则匹配默认及动态的handlers、instances配置
	rules := e.processRuleConfigs(monitoringCtx, shandlers, instances, dhandlers, dInstances, af, errs)
	// ……
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;istio-proxy中-mixerclient-执行流程&#34;&gt;istio/proxy中&lt;code&gt;mixerclient&lt;/code&gt;执行流程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;src/envoy/BUILD

&lt;ul&gt;
&lt;li&gt;http/mixer:filter_lib&lt;/li&gt;
&lt;li&gt;tcp/mixer:filter_lib&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;src/envoy/http、tcp/mixer/filter.cc

&lt;ul&gt;
&lt;li&gt;分别在&lt;code&gt;decodeHeaders()&lt;/code&gt;和&lt;code&gt;onData()&lt;/code&gt;做&lt;code&gt;Check()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;src/istio/control/http、tcp/request_handler_impl.cc

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Check()&lt;/code&gt;先做属性注入&lt;/li&gt;
&lt;li&gt;src/istio/control/client_context_base.cc，&lt;code&gt;SendCheck()&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;调用&lt;code&gt;mixerclient-&amp;gt;Check()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;src/istio/mixerclient/client_impl.cc

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Check()&lt;/code&gt;先获取缓存&lt;code&gt;checkPolicyCache()&lt;/code&gt;，缓存没有命中则走&lt;code&gt;RemoteCheck()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RemoteCheck()&lt;/code&gt;成功后更新缓存&lt;code&gt;updatePolicyCache()&lt;/code&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TB;
  subgraph src/envoy
  A[mixer:filter_lib]--&amp;gt;|&amp;quot;decodeHeaders()&amp;quot;|B(http/mixer/filter.cc)
  A--&amp;gt;|&amp;quot;onData()&amp;quot;|C(tcp/mixer/filter.cc)
  end
  subgraph srv/istio/control
  B--&amp;gt;|&amp;quot;Check(){属性注入}&amp;quot;|D(http/request_handler_impl.cc)
  C--&amp;gt;|&amp;quot;Check(){属性注入}&amp;quot;|E(tcp/request_handler_impl.cc)
  D--&amp;gt;|&amp;quot;SendCheck()&amp;quot;|F(client_context_base.cc)
  E--&amp;gt;|&amp;quot;SendCheck()&amp;quot;|F
  end
  subgraph srv/istio/mixerclient
  F--&amp;gt;|&amp;quot;Check()&amp;quot;|G(client_impl.cc)
  G--&amp;gt;|&amp;quot;①checkPolicyCache()&amp;quot;|H(check_context.cc)
  G--&amp;gt;|&amp;quot;②RemoteCheck()&amp;quot;|G
  G--&amp;gt;|&amp;quot;③updatePolicyCache()&amp;quot;|H
  end
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio】自定义 Mixer Adapter示例教程(附源码)</title>
      <link>http://hbchen.com/post/2019-03-05-custom-istio-mixer-adapter/</link>
      <pubDate>Tue, 05 Mar 2019 20:44:07 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2019-03-05-custom-istio-mixer-adapter/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;快速开始:&lt;a href=&#34;https://github.com/hb-go/micro-mesh/tree/master/examples/adapter/auth&#34;&gt;micro-mesh/examples/adapter/auth&lt;/a&gt;源码传送门&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;研究Istio下构建简洁的微服务架构，对Istio的研究也更深入，自定义Mixer Adapter必不少，以下结合使用场景做一个自定义适配器的实践分享。&lt;/p&gt;

&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-go/micro-mesh/master/doc/img/micro-mesh.jpg&#34; alt=&#34;auth-adapter&#34; /&gt;
结合&lt;a href=&#34;https://github.com/hb-go/micro-mesh#micro-mesh&#34;&gt;micro-mesh&lt;/a&gt;的实践场景，需要在&lt;code&gt;ingressgateway&lt;/code&gt;与&lt;code&gt;API service&lt;/code&gt;间加入认证&amp;amp;鉴权(JWT&amp;amp;RBAC)，自然考虑Istio提供的&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/&#34;&gt;安全&lt;/a&gt;方案，但使用JWT做认证鉴权在后端是无状态的，这样在使用场景上有一定限制，如:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;密码修改、终端连接限制等场景下无法踢除&lt;/li&gt;
&lt;li&gt;访问控制策略无法实时生效&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;默认方案只是在一些场景下不合适，根据具体需求考虑&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;基于这样的场景可以自定义Adapter来实现，目标:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Token-JWT

&lt;ul&gt;
&lt;li&gt;服务端验证token有效性&lt;/li&gt;
&lt;li&gt;应对密码修改、终端数量限制等场景&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ACL-&lt;a href=&#34;http://github.com/casbin/casbin&#34;&gt;Casbin&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;服务端获取用户角色，做API访问控制&lt;/li&gt;
&lt;li&gt;用户角色及接口授权策略实时生效
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下示例对token验证、访问控制不做具体设计，重点介绍如何自定义一个&lt;code&gt;auth-adapter&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;自定义adapter介绍&#34;&gt;自定义Adapter介绍&lt;/h2&gt;

&lt;p&gt;配置关系及执行流程如图：
&lt;img src=&#34;https://raw.githubusercontent.com/hb-go/micro-mesh/master/doc/img/auth-adapter.jpg&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;属性：使用&lt;code&gt;istio&lt;/code&gt;的&lt;code&gt;attributes&lt;/code&gt;，&lt;code&gt;istio/mixer/testdata/config/attributes.yaml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;属性与适配器输入映射模板：使用&lt;code&gt;istio&lt;/code&gt;的&lt;code&gt;authorization&lt;/code&gt;模板，&lt;code&gt;istio/mixer/template/authorization/template.yaml&lt;/code&gt;，通过&lt;code&gt;template.proto&lt;/code&gt;查看协议内容&lt;/li&gt;
&lt;li&gt;适配器，&lt;code&gt;micro-mesh/examples/adapter/auth/config/auth-adapter.yaml&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;go generate ./...&lt;/code&gt;自动生成&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;适配器服务启动配置，&lt;code&gt;micro-mesh/examples/adapter/auth/config/config.proto&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;适配器服务实例，&lt;code&gt;micro-mesh/examples/adapter/auth/operatorconfig/cluster-service.yaml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;适配器配置，&lt;code&gt;micro-mesh/examples/adapter/auth/operatorconfig/operator-cfg.yaml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;目录结构&#34;&gt;目录结构&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bin                         执行文件
cmd                         
  └ main.go                 适配器入口
config                      配置协议
  ├ adapter.auth.config.pb.html                 #go generate ./... 自动生成
  ├ auth-adapter.yaml       适配器描述文件       #go generate ./... 自动生成
  ├ config.pb.go                                #go generate ./... 自动生成
  ├ config.proto            适配器服务启动配置
  └ config.proto_descriptor                     #go generate ./... 自动生成
operatorconfig              k8s配置
  ├ attributes.yaml         属性                  #copy istio/mixer/testdata/config/attributes.yaml
  ├ cluster-service.yaml    适配器服务实例
  ├ operator-cfg.yaml       适配器配置
  └ template.yaml           属性与适配器输入模板    #copy istio/mixer/template/authorization/template.yaml
testdata                    测试配置
  ├ attributes.yaml         属性                  #copy istio/mixer/testdata/config/attributes.yaml
  ├ auth-adapter.yaml       适配器描述文件         #copy config/auth-adapter.yaml
  ├ operator-cfg.yaml       适配器配置
  └ template.yaml           属性与适配器输入模板    #copy istio/mixer/template/authorization/template.yaml
auth.go                     适配器服务实现
Dockerfile                  Docker镜像
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有3处与适配器实现相关：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;适配器服务启动配置&lt;code&gt;config/config.proto&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;适配器服务实现&lt;code&gt;auth.go&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;适配器入口&lt;code&gt;cmd/main.go&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;接下来使用&lt;a href=&#34;https://github.com/hb-go/micro-mesh/tree/master/examples/adapter/auth&#34;&gt;micro-mesh/examples/adapter/auth&lt;/a&gt;源码按步骤操作，实现本地及&lt;code&gt;GKE&lt;/code&gt;环境的测试部署&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;步骤&#34;&gt;步骤&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;开发环境&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OSX&lt;/li&gt;
&lt;li&gt;Go &lt;strong&gt;1.11.1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;protoc &lt;strong&gt;libprotoc 3.6.1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Istio &lt;strong&gt;1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-istio源码&#34;&gt;1.Istio源码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p $GOPATH/src/istio.io/
cd $GOPATH/src/istio.io/
git clone https://github.com/istio/istio.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-micro-mesh源码&#34;&gt;2.micro-mesh源码&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/hb-go/micro-mesh.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-mixer开发工具&#34;&gt;3.Mixer开发工具&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# build mixer server &amp;amp; client 
cd istio
make mixs
make mixc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;$GOPATH/out/darwin_amd64/release/&lt;/code&gt;生成&lt;code&gt;mixs&lt;/code&gt;、&lt;code&gt;mixc&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-构建auth-adapter项目&#34;&gt;4.构建Auth adapter项目&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# copy auth adapter example
cp {micro-mesh path}/examples/adapter/auth mixer/adapter/auth

cd mixer/adapter/auth
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Optional&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以删除&lt;code&gt;config&lt;/code&gt;目录除&lt;code&gt;config.proto&lt;/code&gt;外的其他文件，看执行go generate后的结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go generate ./...
go build ./...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;go generate&lt;/code&gt;根据&lt;code&gt;config/config.proto&lt;/code&gt;以及&lt;code&gt;auth.go&lt;/code&gt;的注释自动生成&lt;code&gt;config&lt;/code&gt;目录下的其他文件:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;adapter.auth.config.pb.html&lt;/li&gt;
&lt;li&gt;auth-adapter.yaml&lt;/li&gt;
&lt;li&gt;config.pb.go&lt;/li&gt;
&lt;li&gt;config.proto_descriptor&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据&lt;code&gt;auth.go&lt;/code&gt;的以下注释，&lt;code&gt;mixer_codegen.sh&lt;/code&gt;使用&lt;code&gt;authorization&lt;/code&gt;模板生成&lt;code&gt;name&lt;/code&gt;为&lt;code&gt;auth-adapter&lt;/code&gt;的适配器&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// nolint:lll
// Generates the auth adapter&#39;s resource yaml. It contains the adapter&#39;s configuration, name, supported template
// names (metric in this case), and whether it is session or no-session based.
//go:generate $GOPATH/src/istio.io/istio/bin/mixer_codegen.sh -a mixer/adapter/auth/config/config.proto -x &amp;quot;-s=false -n auth-adapter -t authorization&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;5-本地测试&#34;&gt;5.本地测试&lt;/h3&gt;

&lt;p&gt;本地测试使用testdata下的配置，其中&lt;code&gt;operator-cfg.yaml&lt;/code&gt;有几处与正式部署不同：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;handler&lt;/code&gt;的&lt;code&gt;address&lt;/code&gt;使用本地服务&lt;code&gt;&amp;quot;[::]:44225&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;为了方便测试&lt;code&gt;instance&lt;/code&gt;的&lt;code&gt;params&lt;/code&gt;参数以及&lt;code&gt;rule&lt;/code&gt;的&lt;code&gt;math&lt;/code&gt;条件做了简化&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 启动适配器服务
go run cmd/main.go 44225

# 使用testdata下配置启动mixer server
$GOPATH/out/darwin_amd64/release/mixs server \
--configStoreURL=fs://$GOPATH/src/istio.io/istio/mixer/adapter/auth/testdata \
--log_output_level=default:debug,attributes:debug

# 测试Adapter是否生效
$GOPATH/out/darwin_amd64/release/mixc check -s request.host=&amp;quot;localhost&amp;quot; --stringmap_attributes &amp;quot;request.headers=x-custom-token:efg&amp;quot;
# Check RPC completed successfully. Check status was PERMISSION_DENIED (mm-example-auth.handler.istio-system:Unauthorized...)

$GOPATH/out/darwin_amd64/release/mixc check -s request.host=&amp;quot;localhost&amp;quot; --stringmap_attributes &amp;quot;request.headers=x-custom-token:abc&amp;quot;
# Check RPC completed successfully. Check status was OK
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;NOTE:出现预期结果不一致可能是由于mixer cache导致&lt;code&gt;Valid use count: 10000, valid duration: 9.726875254s&lt;/code&gt;，请参考&lt;a href=&#34;http://www.servicemesher.com/categories/istio-mixer-cache&#34;&gt;Istio Mixer Cache&lt;/a&gt;系列文章了解&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;6-打包镜像&#34;&gt;6.打包镜像&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# build执行文件
CGO_ENABLED=0 GOOS=linux \
    go build -a -installsuffix cgo -v -o bin/auth ./cmd/
    
# docker镜像
docker build -t hbchen/micro-mesh-example-adapter-auth:v0.0.1 .
docker push hbchen/micro-mesh-example-adapter-auth:v0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;7-istio环境部署&#34;&gt;7.Istio环境部署&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;部署环境&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GKE &lt;strong&gt;1.12.5-gke.10&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Istio &lt;strong&gt;1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 属性、模板
# attributes.yaml -&amp;gt; istio/mixer/testdata/config/attributes.yaml 
# template.yaml -&amp;gt; istio/mixer/template/authorization/template.yaml
kubectl apply -f examples/adapter/auth/testdata/attributes.yaml -f examples/adapter/auth/testdata/template.yaml

# 适配器
kubectl apply -f examples/adapter/auth/config/auth-adapter.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;这里是以&lt;a href=&#34;https://github.com/hb-go/micro-mesh&#34;&gt;micro-mesh&lt;/a&gt;示例为基础的配置，如果使用&lt;code&gt;bookinfo&lt;/code&gt;或者自己的服务需要做相应的修改&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;operator-cfg.yaml&lt;/code&gt;与本地测试配置不同：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;handler&lt;/code&gt;的&lt;code&gt;address&lt;/code&gt;使用集群服务&lt;code&gt;&amp;quot;mm-example-auth-adapter-service:44225&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;instance&lt;/code&gt;的&lt;code&gt;params&lt;/code&gt;根据&lt;code&gt;authorization&lt;/code&gt;模板及&lt;code&gt;auth-adapter&lt;/code&gt;服务的需求配置&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rule&lt;/code&gt;的&lt;code&gt;match&lt;/code&gt;条件使用&lt;code&gt;destination.service.name == &amp;quot;mm-example-api&amp;quot;&lt;/code&gt;或&lt;code&gt;destination.service.host == &amp;quot;mm-example-api.default.svc.cluster.local&amp;quot;&lt;/code&gt;，仅对&lt;code&gt;mm-example-api&lt;/code&gt;服务生效&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 适配器服务实例部署
kubectl apply -f examples/adapter/auth/operatorconfig/cluster-service.yaml

# 适配器配置
kubectl apply -f examples/adapter/auth/operatorconfig/operator-cfg.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;8-istio环境部署测试&#34;&gt;8.Istio环境部署测试&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;如果没有开Gateway的JWT验证可以忽略&lt;code&gt;Authorization&lt;/code&gt;，其实做了自定义Auth后是多余的😂&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;TOKEN=$(curl https://raw.githubusercontent.com/istio/istio/release-1.1/security/tools/jwt/samples/demo.jwt -s)

curl -H &amp;quot;Authorization: Bearer $TOKEN&amp;quot; -H &amp;quot;x-custom-token: efg&amp;quot; -H &amp;quot;Grpc-Metadata-x-tier: 2&amp;quot; -X GET http://35.192.111.18/v1/example/call/Hobo
curl -H &amp;quot;Authorization: Bearer $TOKEN&amp;quot; -H &amp;quot;x-custom-token: abc&amp;quot; -H &amp;quot;Grpc-Metadata-x-tier: 2&amp;quot; -X GET http://35.192.111.18/v1/example/call/Hobo

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/istio/wiki/Mixer-Out-of-Process-Adapter-Walkthrough&#34;&gt;Mixer Out of Process Adapter Walkthrough&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/google-cloud/simple-istio-mixer-out-of-process-authorization-adapter-5f9363cd9bbc&#34;&gt;Simple Istio Mixer Out of Process Authorization Adapter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>go-micro加入Istio服务网格</title>
      <link>http://hbchen.com/post/2019-01-08-go-micro%E5%8A%A0%E5%85%A5istio%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/</link>
      <pubDate>Thu, 21 Feb 2019 16:59:37 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2019-01-08-go-micro%E5%8A%A0%E5%85%A5istio%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/</guid>
      
        <description>&lt;p&gt;将go-micro服务加入service mesh，Client、Server不需要Registry、Selector、Transport等，通过自定义micro的server &amp;amp; client插件，去掉在istio中不需要的组件依赖。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hb-go/micro/master/doc/img/micro-istio.png&#34; alt=&#34;go-micro&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hb-go/micro-plugins&#34;&gt;hb-go/micro-plugins&lt;/a&gt;实现了gRPC、http的Istio版本Plugin，下面介绍如何使用。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;完整示例参考&lt;a href=&#34;https://github.com/hb-go/micro/tree/master/istio&#34;&gt;hb-go/micro/istio&lt;/a&gt;，示例包括http、gRPC&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&#34;命令行参数&#34;&gt;命令行参数&lt;/h5&gt;

&lt;p&gt;方便服务运行时指定端口，在命令行获取服务server、client端口配置，参数根据具体情况自行设计&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;在服务网格中我倾向统一上下游服务端口，避免不必要的配置以及因此引发的冲突问题&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Client端服务地址&lt;code&gt;CallOptions.Address&lt;/code&gt;解析规则：

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;:&lt;/code&gt;开头，将&lt;code&gt;service.Name&lt;/code&gt;中&lt;code&gt;.&lt;/code&gt;替换为&lt;code&gt;-&lt;/code&gt;，加&lt;code&gt;CallOptions.Address&lt;/code&gt;，如&lt;code&gt;go.micro.api.sample&lt;/code&gt; &lt;code&gt;:9080&lt;/code&gt; =&amp;gt; &lt;code&gt;go-micro-api-sample:9080&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;非&lt;code&gt;:&lt;/code&gt;开头，固定地址&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var (
	serverAddr string
	callAddr   string
	cmdHelp    bool
)

func init() {
	flag.StringVar(&amp;amp;serverAddr, &amp;quot;server_address&amp;quot;, &amp;quot;0.0.0.0:9080&amp;quot;, &amp;quot;server address.&amp;quot;)
	flag.StringVar(&amp;amp;callAddr, &amp;quot;client_call_address&amp;quot;, &amp;quot;:9080&amp;quot;, &amp;quot;client call options address.&amp;quot;)
	flag.Parse()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;自定义server-client插件-创建服务&#34;&gt;自定义server、client插件，创建服务&lt;/h5&gt;

&lt;blockquote&gt;
&lt;p&gt;由于micro框架对命令行的解析问题，创建服务时需要增加&lt;code&gt;micro.Flags(...)&lt;/code&gt;，兼容自定义参数，如:&lt;code&gt;client_call_address&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
	httpClient &amp;quot;github.com/hb-go/micro-plugins/client/istio_http&amp;quot;
	httpServer &amp;quot;github.com/hb-go/micro-plugins/server/istio_http&amp;quot;
)

func main() {
	c := httpClient.NewClient(
		client.ContentType(&amp;quot;application/json&amp;quot;),
		func(o *client.Options) {
			o.CallOptions.Address = callAddr
		},
	)
	s := httpServer.NewApiServer(
		server.Address(serverAddr),
	)

	// New Service
	service := micro.NewService(
		micro.Name(&amp;quot;go.micro.api.sample&amp;quot;),
		micro.Version(&amp;quot;latest&amp;quot;),
		micro.Registry(noop.NewRegistry()),
		micro.Client(c),
		micro.Server(s),

		// 兼容micro cmd parse
		micro.Flags(cli.StringFlag{
			Name:   &amp;quot;client_call_address&amp;quot;,
			EnvVar: &amp;quot;MICRO_CLIENT_CALL_ADDRESS&amp;quot;,
			Usage:  &amp;quot; Invalid!!!&amp;quot;,
		}),
	)

	service.Options().Cmd.Init()
	
	// ……
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;服务部署-yaml&#34;&gt;服务部署.yaml&lt;/h5&gt;

&lt;blockquote&gt;
&lt;p&gt;其它Istio相关.yaml参考完整示例&lt;a href=&#34;https://github.com/hb-go/micro/tree/master/istio/k8s&#34;&gt;hb-go/micro/istio/k8s&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;######################################################################################
# API service
######################################################################################
apiVersion: v1
kind: Service
metadata:
  name: go-micro-api-sample
  labels:
    app: go-micro-api-sample
spec:
  ports:
  - port: 9080
    name: http
  selector:
    app: go-micro-api-sample
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: go-micro-api-sample-v1
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: go-micro-api-sample
        version: v1
    spec:
      containers:
      - name: go-micro-api-sample
        command: [
          &amp;quot;/sample&amp;quot;,
          &amp;quot;-server_address=0.0.0.0:9080&amp;quot;,
          &amp;quot;-client_call_address=:9080&amp;quot;,
        ]
        image: hbchen/go-micro-istio-api-sample:v0.0.5
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 9080
---
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>Spark &#43; Elasticsearch构建推荐系统</title>
      <link>http://hbchen.com/post/2018-10-24-spark-elasticsearch-recommender/</link>
      <pubDate>Wed, 24 Oct 2018 16:23:46 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2018-10-24-spark-elasticsearch-recommender/</guid>
      
        <description>&lt;p&gt;Github &lt;a href=&#34;https://github.com/hb-chen/spark-elasticsearch-recommender&#34;&gt;hb-chen/spark-elasticsearch-recommender&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Zeppelin &lt;code&gt;0.8.0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Spark &lt;code&gt;2.3.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Elasticsearch &lt;code&gt;6.3.2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-环境准备&#34;&gt;1.环境准备&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;Mac OSX&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&#34;zeppeline&#34;&gt;Zeppeline&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# http://www.apache.org/dyn/closer.cgi/zeppelin/zeppelin-0.8.0/zeppelin-0.8.0-bin-netinst.tgz
$ wget http://mirrors.shu.edu.cn/apache/zeppelin/zeppelin-0.8.0/zeppelin-0.8.0-bin-netinst.tgz
$ tar -zxf zeppelin-0.8.0-bin-netinst.tgz
$ cd zeppelin-0.8.0-bin-netinst

# 安装必要interpreter
$ ./bin/install-interpreter.sh --name md,elasticsearch
$ ./bin/zeppelin-daemon.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;spark&#34;&gt;Spark&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# http://spark.apache.org/downloads.html
$ wget https://www.apache.org/dyn/closer.lua/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz
$ tar -zxf spark-2.3.2-bin-hadoop2.7.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;elasticsearch&#34;&gt;Elasticsearch&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# https://www.elastic.co/downloads/past-releases
# Elasticsearch + 6.3.2
$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.zip
$ unzip elasticsearch-6.3.2.zip

# ES-Hadoop + 6.3.2
$ wget https://artifacts.elastic.co/downloads/elasticsearch-hadoop/elasticsearch-hadoop-6.3.2.zip
$ unzip elasticsearch-hadoop-6.3.2.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;h6 id=&#34;elasticsearch-矢量评分插件&#34;&gt;Elasticsearch 矢量评分插件&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/muhleder/elasticsearch-vector-scoring&#34;&gt;muhleder/elasticsearch-vector-scoring&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 修改build.gradle，这样不必Checkout Elasticsearch 
# https://github.com/muhleder/elasticsearch-vector-scoring/issues/1#issuecomment-415267767
buildscript {
  repositories {
    jcenter()
    mavenLocal()
  }
  dependencies {
    classpath &amp;quot;org.elasticsearch.gradle:build-tools:6.3.2&amp;quot;
  }
}

apply plugin: &#39;idea&#39;
apply plugin: &#39;java&#39;
apply plugin: &#39;elasticsearch.esplugin&#39;

licenseFile = rootProject.file(&#39;LICENSE&#39;)
noticeFile = rootProject.file(&#39;NOTICE&#39;)

esplugin {
  name &#39;elasticsearch-vector-scoring&#39;
  description &#39;Provides a fast vector multiplication script.&#39;
  classname &#39;com.gosololaw.elasticsearch.VectorScoringPlugin&#39;
}

dependencies {
  compile &amp;quot;org.elasticsearch:elasticsearch:6.3.2&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 插件安装
$ ./bin/elasticsearch-plugin install {file:///path/to/plugin.zip}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;python依赖库&#34;&gt;Python依赖库&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install elasticsearch
$ pip install numpy
$ pip install tmdbsimple # 忽略，暂时未使用
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;movielens数据集-https-grouplens-org-datasets-movielens-下载&#34;&gt;&lt;a href=&#34;https://grouplens.org/datasets/movielens/&#34;&gt;Movielens数据集&lt;/a&gt;下载&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd data # 与zeppelin-0.8.0-bin-netinst同Path，note中配置PATH_TO_DATA = &amp;quot;../data/ml-latest-small&amp;quot;
$ wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip
$ unzip ml-latest-small.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-启动服务&#34;&gt;2.启动服务&lt;/h4&gt;

&lt;h5 id=&#34;elasticsearch启动&#34;&gt;Elasticsearch启动&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./bin/elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;zeppelin配置及启动&#34;&gt;Zeppelin配置及启动&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cp conf/shiro.ini.template conf/shiro.ini
$ vim conf/shiro.ini
# 管理员账户密码
[users]
admin = 123456, admin

$ cp conf/zeppelin-env.sh.template conf/zeppelin-env.sh
$ vim conf/zeppelin-env.sh
# Spark配置
export SPARK_HOME=/{apache-spark-path}/spark-2.3.2-bin-hadoop2.7
export SPARK_SUBMIT_OPTIONS=&amp;quot;--driver-memory 2G&amp;quot;

$ cp conf/zeppelin-site.xml.template conf/zeppelin-site.xml
$ vim conf/zeppelin-site.xml
# 根据需要可以修改zeppelin.server.port等配置

# 启动
$ ./bin/zeppelin-daemon.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-notebook&#34;&gt;3.Notebook&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Create new interpreter
# md

# elasticsearch
elasticsearch.client.type http
elasticsearch.port	9200

# spark
# 添加Dependencies
artifact /{elasticsearch-hadoop-path}/elasticsearch-hadoop-6.3.2/dist/elasticsearch-spark-20_2.11-6.3.2.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/IBM/elasticsearch-spark-recommender&#34;&gt;使用 Apache Spark 和 Elasticsearch 构建一个推荐系统&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>go-micro框架介绍</title>
      <link>http://hbchen.com/post/2018-03-27-go-micro-%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Tue, 27 Mar 2018 19:09:32 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2018-03-27-go-micro-%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/</guid>
      
        <description>&lt;h2 id=&#34;go-micro-https-github-com-micro-go-micro&#34;&gt;&lt;a href=&#34;https://github.com/micro/go-micro&#34;&gt;go-micro&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;go-micro是Micro的核心，是一套Go语言的可插拔RPC框架，提供服务发现、负载均衡、同步/异步通信、编码、服务接口等，所有组件均设计为Interface，便于扩展。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;micro实践示例&lt;a href=&#34;https://github.com/hb-go/micro&#34;&gt;github.com/ho-go/micro&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/go-micro.jpg&#34; alt=&#34;go-micro&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主要有以下组件构成:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Registry&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;提供一套服务注册、发现、注销、监测机制，服务注册中心支持consul、etcd2/3、zookeeper、gossip、k8s、eureka等&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Selector&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;选择器提供了负载均衡，可以通过过滤方法对微服务进行过滤，并通过不同路由算法选择微服务，以及缓存等&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Transport&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;微服务间同步请求/响应通信方式，相对Go标准net包做了更高的抽象，支持更多的传输方式，如http、grpc、tcp、udp、Rabbitmq等&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Broker&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;微服务间异步发布/订阅通信方式，更好的处理分布式系统解耦问题，默认使用http方式，生产环境通常会使用消息中间件，如Kafka、RabbitMQ、NSQ等&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Codec&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;服务间消息的编解码，支持json、protobuf、bson、msgpack等，与普通编码格式不同都是支持RPC格式&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Server&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;用于启动服务，为服务命名、注册Handler、添加中间件等&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Client&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;提供微服务客户端，通过Registry、Selector、Transport、Broker实现以服务名来查找服务、负载均衡、同步通信、异步消息等&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;micro-https-github-com-micro-micro&#34;&gt;&lt;a href=&#34;https://github.com/micro/micro&#34;&gt;micro&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Micro的工具包，主要由以下部分构成:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;API&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;API网关提供HTTP服务，并将请求路由到指定的微服务，是Micro的统一入口，可以用作反向代理，或者将HTTP请求转到RPC&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Web&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;为Micro提供一套仪表盘，并可作为Web应用的反向代理，有别于普通API将Web应用作为了Micro的一等公民，其实和API差不多，但同时提供了对socket的支持&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sidecar&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;通过HTTP的方式实现go-micro全部功能的RPC代理，通过Sidecar可以方便的将其他语言集成到Micro框架中，方便解决解决应用的异构框架问题&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CLI&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;提供一套命令行工具，可以方便的与Micro服务进行交互，并且可以通过Sidecar代理CLI命令&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bot&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;通过Bot可以在Micro环境中方便的与Slack、HipChat、XMPP等进行集成，通过消息的方式模仿CLI功能&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;go-plugins-https-github-com-micro-go-plugins&#34;&gt;&lt;a href=&#34;https://github.com/micro/go-plugins&#34;&gt;go-plugins&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;go-plugins是Micro的插件库，除go-micro相应组件的扩展外，还有其他如Trace、KV存储、监控等&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Centos VSFTP配置</title>
      <link>http://hbchen.com/post/2014-10-17-centos-vsftp/</link>
      <pubDate>Fri, 17 Oct 2014 16:18:00 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2014-10-17-centos-vsftp/</guid>
      
        <description>&lt;p&gt;安装&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install vsftp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#/etc/vsftpd/vsftpd.conf
#关闭匿名登录
#anonymous_enable=NO

user_list中的说明是userlist_deny
#userlist_enable=NO

FTP root
#local_root=/mnt/ftp

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加登录用户&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;添加用户
$ useradd Hobo
设置密码
$ passwd Hobo
$加入user_list
$ echo Hobo &amp;gt;&amp;gt; /etc/vsftpd/user_list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重启&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$service vsftpd restart
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>MySQL Backup</title>
      <link>http://hbchen.com/post/2014-10-17-mysql-backup/</link>
      <pubDate>Fri, 17 Oct 2014 14:04:00 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2014-10-17-mysql-backup/</guid>
      
        <description>&lt;p&gt;MySQL备份脚本，支持mysqldump,mysqlhotcopy,tar三种方式，+定时任务自动备份。&lt;/p&gt;

&lt;p&gt;Gist
&lt;a href=&#34;https://gist.github.com/Hobo86/effd4b45b50f576bf4d1&#34;&gt;https://gist.github.com/Hobo86/effd4b45b50f576bf4d1&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#脚本属性设为可执行
$ chmod +x mysql_backup.sh
 
#编辑定时任务
$ vi /etc/crontab
 
如：每天03:01执行备份脚本
01 3 * * * root /usr/sbin/mysql_backup.sh
 
#重启定时任务
$ /etc/rc.d/init.d/crond restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gist
&lt;a href=&#34;https://gist.github.com/Hobo86/29b27d361a4c59545348&#34;&gt;https://gist.github.com/Hobo86/29b27d361a4c59545348&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#mysql_backup.sh
#!/bin/bash
 
DBName=db_name
 
DBUser=root
 
DBPasswd=123456
 
BackupPath=/mnt/backup/
 
LogFile=/mnt/backup/db_name.log
 
DBPath=/mnt/mysql/
 
BackupMethod=mysqldump
 
#BackupMethod=mysqlhotcopy
 
#BackupMethod=tar
 
 
NewFile=&amp;quot;$BackupPath&amp;quot;db_name_$(date +%y%m%d).tgz
 
DumpFile=&amp;quot;$BackupPath&amp;quot;db_name_$(date +%y%m%d)
 
OldFile=&amp;quot;$BackupPath&amp;quot;db_name_$(date +%y%m%d --date=&#39;5 days ago&#39;).tgz
 
#SettingEnd
 
echo &amp;quot;-------------------------------------------&amp;quot;&amp;gt;&amp;gt;$LogFile
echo $(date +%Y-%m-%d%t%H:%M:%S)&amp;gt;&amp;gt;$LogFile
 
echo &amp;quot;--------------------------&amp;quot;&amp;gt;&amp;gt;$LogFile
 
#DeleteOldFile
if [ -f $OldFile ]
	then
		rm -f $OldFile&amp;gt;&amp;gt;$LogFile 2&amp;gt;&amp;amp;1
		echo &amp;quot;[$OldFile]DeleteOldFileSuccess!&amp;quot;&amp;gt;&amp;gt;$LogFile
	else
		echo &amp;quot;[$OldFile]NoOldBackupFile!&amp;quot;&amp;gt;&amp;gt;$LogFile
fi
 
if [ -f $NewFile ] 
	then
		echo &amp;quot;[$NewFile]TheBackupFileisexists,Can&#39;tBackup!&amp;quot;&amp;gt;&amp;gt;$LogFile
	else
		case $BackupMethod in
		mysqldump)
 			if [ -z $DBPasswd ] 
				then
					mysqldump -u$DBUser --opt $DBName&amp;gt;$DumpFile
				else
					mysqldump -u$DBUser -p$DBPasswd --opt $DBName&amp;gt;$DumpFile
			fi
 
			tar czvf $NewFile $DumpFile&amp;gt;&amp;gt;$LogFile 2&amp;gt;&amp;amp;1
			echo &amp;quot;[$NewFile]BackupSuccess!&amp;quot;&amp;gt;&amp;gt;$LogFile
 			rm -rf $DumpFile
		;;
 
		mysqlhotcopy)
 			rm -rf $DumpFile
 			mkdir $DumpFile
 
			if [ -z $DBPasswd ] 
				then
					mysqlhotcopy -u$DBUser $DBName $DumpFile&amp;gt;&amp;gt;$LogFile 2&amp;gt;&amp;amp;1
				else
					mysqlhotcopy -u$DBUser -p$DBPasswd $DBName $DumpFile&amp;gt;&amp;gt;$LogFile2&amp;gt;&amp;amp;1
			fi
 
			tar czvf $NewFile $DumpFile&amp;gt;&amp;gt;$LogFile 2&amp;gt;&amp;amp;1
			echo &amp;quot;[$NewFile]BackupSuccess!&amp;quot;&amp;gt;&amp;gt;$LogFile
			rm -rf $DumpFile
		;;
 
		*)
			/etc/init.d/mysqldstop&amp;gt;/dev/null2&amp;gt;&amp;amp;1
			tar czvf $NewFile $DBPath$DBName&amp;gt;&amp;gt;$LogFile 2&amp;gt;&amp;amp;1
			/etc/init.d/mysqldstart&amp;gt;/dev/null2&amp;gt;&amp;amp;1
			echo &amp;quot;[$NewFile]BackupSuccess!&amp;quot;&amp;gt;&amp;gt;$LogFile
		;;
 
		esac
fi
echo &amp;quot;-------------------------------------------&amp;quot;&amp;gt;&amp;gt;$LogFile
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>[转]Git-项目自动部署</title>
      <link>http://hbchen.com/post/2014-10-17-xiang-mu-zi-dong-bu-shu-git/</link>
      <pubDate>Fri, 17 Oct 2014 13:29:00 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2014-10-17-xiang-mu-zi-dong-bu-shu-git/</guid>
      
        <description>&lt;p&gt;Git push后自动更新项目部署，&amp;rdquo;[deploy]&amp;ldquo;部署的分支为master。&lt;/p&gt;

&lt;p&gt;Gist
&lt;/br&gt;&lt;a href=&#34;https://gist.github.com/icyleaf/566767&#34;&gt;https://gist.github.com/icyleaf/566767&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ vi post-receive

#!/bin/sh
#
# git autodeploy script when it matches the string &amp;quot;[deploy]&amp;quot;
#
# @author    icyleaf &amp;lt;icyleaf.cn@gmail.com&amp;gt;
# @link      http://icyleaf.com
# @version   0.1
#
# Usage:
#       1. put this into the post-receive hook file itself below
#       2. `chmod +x post-recive` 
#       3. Done!
 
# Check the remote git repository whether it is bare
IS_BARE=$(git rev-parse --is-bare-repository)
if [ -z &amp;quot;$IS_BARE&amp;quot; ]; then
	echo &amp;gt;&amp;amp;2 &amp;quot;fatal: post-receive: IS_NOT_BARE&amp;quot;
	exit 1
fi
 
# Get the latest commit subject
SUBJECT=$(git log -1 --pretty=format:&amp;quot;%s&amp;quot;)
 
# Deploy the HEAD sources to publish
IS_PULL=$(echo &amp;quot;$SUBJECT&amp;quot; | grep &amp;quot;\[deploy\]&amp;quot;)
if [ -z &amp;quot;$IS_PULL&amp;quot; ]; then
	echo &amp;gt;&amp;amp;2 &amp;quot;tips: post-receive: IS_NOT_PULL&amp;quot;
	exit 1
fi
 
# Check the deploy dir whether it exists
DEPLOY_DIR=/home/icyleaf/php/icyleaf/
if [ ! -d $DEPLOY_DIR ] ; then
	echo &amp;gt;&amp;amp;2 &amp;quot;fatal: post-receive: DEPLOY_DIR_NOT_EXIST: \&amp;quot;$DEPLOY_DIR\&amp;quot;&amp;quot;
	exit 1
fi
 
# Check the deploy dir whether it is git repository
#
#IS_GIT=$(git rev-parse --git-dir 2&amp;gt;/dev/null)
#if [ -z &amp;quot;$IS_GIT&amp;quot; ]; then
#	echo &amp;gt;&amp;amp;2 &amp;quot;fatal: post-receive: IS_NOT_GIT&amp;quot;
#	exit 1
#fi
 
# Goto the deploy dir and pull the latest sources
cd $DEPLOY_DIR
env -i git reset --hard
env -i git pull
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>Redmine Plugins</title>
      <link>http://hbchen.com/post/2014-04-15-redmine-plugins/</link>
      <pubDate>Tue, 15 Apr 2014 12:09:00 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2014-04-15-redmine-plugins/</guid>
      
        <description>&lt;p&gt;Git版本库工具-&lt;a href=&#34;https://github.com/CtrlC-Root/redmine-gitolite/&#34;&gt;Gitolite&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;知识积累工具-&lt;a href=&#34;https://github.com/alexbevi/redmine_knowledgebase/&#34;&gt;Knowledgebase&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Mac安装配置MongoDB&#43;RockMongo</title>
      <link>http://hbchen.com/post/2014-03-11-mac-mongodb-rockmongo/</link>
      <pubDate>Tue, 11 Mar 2014 18:00:00 +0800</pubDate>
      
      <guid>http://hbchen.com/post/2014-03-11-mac-mongodb-rockmongo/</guid>
      
        <description>&lt;p&gt;MongoDB安装
&lt;/br&gt;使用brew安装很方便
&lt;/br&gt;&lt;a href=&#34;http://docs.mongodb.org/manual/tutorial/install-mongodb-on-os-x/&#34;&gt;http://docs.mongodb.org/manual/tutorial/install-mongodb-on-os-x/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装完成后可以选择修改配置文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#mongod.conf
#dbpath,logpath,bind_ip
vi /usr/local/etc/mongod.conf

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#为了方便使用配置.bash_profile
vi ~/.bash_profile

#添加以下内容
export PATH=$PATH:/usr/local/opt/mongodb/bin
alias mongodb_start=&#39;sudo launchctl load -w /usr/local/Cellar/mongodb/2.4.9/homebrew.mxcl.mongodb.plist&#39;
alias mongodb_stop=&#39;sudo launchctl unload -w /usr/local/Cellar/mongodb/2.4.9/homebrew.mxcl.mongodb.plist&#39;
alias mongodb_restart=&#39;mongodb_stop; mongodb_start;&#39;

#这样直接使用mongodb_start,mongodb_stop,mongodb_restart很方便

#启动
mongodb_start

#配置用户名密码
mongo
db show
use test
db.addUser(&amp;quot;root&amp;quot;, &amp;quot;123456&amp;quot;)

#重启
mongodb_restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;管理工具RockMongo，下载后根据自己的PHP环境配置
&lt;/br&gt;&lt;a href=&#34;http://rockmongo.com/downloads&#34;&gt;http://rockmongo.com/downloads&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装php-mongo&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#我用的php54，记下安装后的路径
brew php54-mongo

#配置php.ini
#添加或者修改extension=&amp;quot;mongo.so&amp;quot;
extension=&amp;quot;/usr/local/Cellar/php54-mongo/1.4.5/mongo.so&amp;quot;

#启动/重启Php环境
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
  </channel>
</rss>