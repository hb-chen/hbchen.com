<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HB-技术实践</title>
    <link>http://hbchen.com/</link>
    <description>Recent content on HB-技术实践</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>HB Studio &lt;a href=&#34;https://beian.miit.gov.cn/&#34; target=&#34;_blank&#34;&gt;蜀ICP备18021614号-1&lt;/a&gt;</copyright>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="http://hbchen.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://hbchen.com/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>http://hbchen.com/about/</guid>
      
        <description>

&lt;h2 id=&#34;about&#34;&gt;About&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/micro-in-cn&#34;&gt;Micro中国站&lt;/a&gt;成员&lt;/li&gt;
&lt;li&gt;Golang、PHP、Objective-C&amp;hellip; 一线码农，全栈架构&lt;/li&gt;
&lt;li&gt;专注于微服务架构与服务网格的应用&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;github&#34;&gt;GitHub&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;go-micro实践 &lt;a href=&#34;https://github.com/micro-in-cn/starter-kit&#34;&gt;micro-in-cn/starter-kit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Echo实践 &lt;a href=&#34;https://github.com/hb-go/echo-web&#34;&gt;hb-go/echo-web&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Istio微服务架构实践 &lt;a href=&#34;https://github.com/hb-go/micro-mesh&#34;&gt;hb-go/micro-mesh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More &lt;a href=&#34;https://github.com/hb-chen&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;微信&#34;&gt;微信&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/wechat.jpg&#34; alt=&#34;微信&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>【Istio】Rust 开发 wasm 扩展</title>
      <link>http://hbchen.com/post/servicemesh/2020-05-22-istio-wasm-rust/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2020-05-22-istio-wasm-rust/</guid>
      
        <description>&lt;p&gt;Istio &lt;strong&gt;1.5&lt;/strong&gt; 开始支持在数据面支持&lt;code&gt;Wasm&lt;/code&gt;扩展，相关规范以及SDK在&lt;a href=&#34;https://github.com/proxy-wasm&#34;&gt;proxy-wasm&lt;/a&gt;，目前提供有三种 SDK 实现，分别是&lt;code&gt;C++&lt;/code&gt;、&lt;code&gt;Rust&lt;/code&gt;和&lt;code&gt;AssemblyScript&lt;/code&gt;，其中&lt;code&gt;AssemblyScript&lt;/code&gt;在&lt;a href=&#34;https://github.com/solo-io/proxy-runtime&#34;&gt;solo-io/proxy-runtime&lt;/a&gt;。除了 SDK Solo 还发布了 &lt;a href=&#34;https://webassemblyhub.io/&#34;&gt;WebAssembly Hub&lt;/a&gt;，并配有&lt;code&gt;wasme&lt;/code&gt; CLI 工具，为 Wasm 扩展的开发提供了不错体验。本文主要介绍如何使用 Rust SDK 开发 Istio Wasm 扩展。&lt;/p&gt;

&lt;h2 id=&#34;wasme-工具&#34;&gt;Wasme 工具&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.solo.io/web-assembly-hub/latest/tutorial_code/getting_started/&#34;&gt;WebAssembly Hub Getting Started&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ curl -sL https://run.solo.io/wasme/install | sh
$ export PATH=$HOME/.wasme/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme --version

wasme version 0.0.14
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rust-项目&#34;&gt;Rust 项目&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.rust-lang.org/zh-CN/tools/install&#34;&gt;Rust安装&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ rustc --version

rustc 1.43.1 (8d69840ab 2020-05-04)
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;创建Rust项目&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;lib&lt;/code&gt;模板创建项目&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cargo new hello-wold --lib 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编辑&lt;code&gt;Cargo.toml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;添加依赖&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]
log = &amp;quot;0.4.8&amp;quot;
proxy-wasm = &amp;quot;0.1.0&amp;quot; # The Rust SDK for proxy-wasm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置动态库编译&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[lib]
path = &amp;quot;src/lib.rs&amp;quot;
crate-type = [&amp;quot;cdylib&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wasm-扩展&#34;&gt;Wasm 扩展&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;源码&lt;a href=&#34;https://github.com/hb-chen/wasm-hello-world-rust&#34;&gt;hb-chen/wasm-hello-world-rust&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;先通过 Rust SDK 了解扩展功能，编辑&lt;code&gt;src/lib.rs&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use proxy_wasm as wasm;

struct HelloWorld {
    context_id: u32,
}

impl wasm::traits::Context for HelloWorld {}
impl wasm::traits::RootContext for HelloWorld{}
impl wasm::traits::StreamContext for HelloWorld{}
impl wasm::traits::HttpContext for HelloWorld{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装依赖&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cargo build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要了解扩展看下几个 Context 的结构，其中&lt;code&gt;on_*&lt;/code&gt;开头的便是扩展点，其他&lt;code&gt;get_*&lt;/code&gt;、&lt;code&gt;set_*&lt;/code&gt;、&lt;code&gt;add_*&lt;/code&gt;等提供了不能接口能力。&lt;/p&gt;

&lt;p&gt;为 Request 添加自定义 Header&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use log::info;
use proxy_wasm as wasm;

#[no_mangle]
pub fn _start() {
    proxy_wasm::set_log_level(wasm::types::LogLevel::Trace);
    proxy_wasm::set_http_context(
        |context_id, _root_context_id| -&amp;gt; Box&amp;lt;dyn wasm::traits::HttpContext&amp;gt; {
            Box::new(HelloWorld { context_id })
        },
    )
}

struct HelloWorld {
    context_id: u32,
}

impl wasm::traits::Context for HelloWorld {}

impl wasm::traits::HttpContext for HelloWorld {
    fn on_http_request_headers(&amp;amp;mut self, num_headers: usize) -&amp;gt; wasm::types::Action {
        info!(&amp;quot;Got {} HTTP headers in #{}.&amp;quot;, num_headers, self.context_id);
        let headers = self.get_http_request_headers();
        let mut authority = &amp;quot;&amp;quot;;

        for (name, value) in &amp;amp;headers {
            if name == &amp;quot;:authority&amp;quot; {
                authority = value;
            }
        }

        self.set_http_request_header(&amp;quot;x-hello&amp;quot;, Some(&amp;amp;format!(&amp;quot;Hello world from {}&amp;quot;, authority)));

        wasm::types::Action::Continue
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cargo build --target wasm32-unknown-unknown --release
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;runtime-config.json&lt;/code&gt;是&lt;code&gt;wasme build&lt;/code&gt;时需要的，可以通过&lt;code&gt;wasme init&lt;/code&gt;创建一个&lt;code&gt;cpp&lt;/code&gt;项目获得&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;type&amp;quot;: &amp;quot;envoy_proxy&amp;quot;,
  &amp;quot;abiVersions&amp;quot;: [
    &amp;quot;v0-097b7f2e4cc1fb490cc1943d0d633655ac3c522f&amp;quot;
  ],
  &amp;quot;config&amp;quot;: {
    &amp;quot;rootIds&amp;quot;: [
      &amp;quot;hello_world&amp;quot;
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打包&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme build precompiled target/wasm32-unknown-unknown/release/hello_world.wasm --tag webassemblyhub.io/hbchen/hello_world:v0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme list

NAME                          TAG  SIZE   SHA      UPDATED
webassemblyhub.io/hbchen/hello_world v0.1 1.9 MB 2e95e556 22 May 20 10:27 CST
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;wasme build&lt;/code&gt;三种方式，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme build -h

Available Commands:
  assemblyscript Build a wasm image from an AssemblyScript filter using NPM-in-Docker
  cpp            Build a wasm image from a CPP filter using Bazel-in-Docker
  precompiled    Build a wasm image from a Precompiled filter.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;本地测试-envoy&#34;&gt;本地测试 Envoy&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme deploy envoy webassemblyhub.io/hbchen/hello_world:v0.1 --envoy-image=istio/proxyv2:1.6.0 --bootstrap=envoy-bootstrap.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[2020-05-24 03:03:41.736][12][info][wasm] [external/envoy/source/extensions/common/wasm/context.cc:1103] wasm log hello_world hello_world : Got 16 HTTP headers in #9.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:8080/headers&#34;&gt;http://localhost:8080/headers&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;headers&amp;quot; : {
    &amp;quot;X-Hello&amp;quot; : &amp;quot;Hello world from localhost:8080&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;wasme deploy&lt;/code&gt;三种方式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme deploy -h

Available Commands:
  envoy       Run Envoy locally in Docker and attach a WASM Filter.
  gloo        Deploy an Envoy WASM Filter to the Gloo Gateway Proxies (Envoy).
  istio       Deploy an Envoy WASM Filter to Istio Sidecar Proxies (Envoy).
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;webassembly-hub-使用&#34;&gt;WebAssembly Hub 使用&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.solo.io/web-assembly-hub/latest/tutorial_code/getting_started/#create-a-user-on-webassemblyhub-io-https-webassemblyhub-io&#34;&gt;Create a User on webassemblyhub.io &amp;amp; Log In from the wasme command line&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Push 镜像&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme push webassemblyhub.io/hbchen/hello_world:v0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;发布到-istio&#34;&gt;发布到 Istio&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;httpbin 用例自己部署，本例&lt;code&gt;namespace=ns-httpbin&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;可以分别通过&lt;code&gt;wasme&lt;/code&gt;工具或&lt;code&gt;operator&lt;/code&gt;添加扩展&lt;/p&gt;

&lt;h3 id=&#34;cli-手动添加&#34;&gt;CLI 手动添加&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme deploy istio webassemblyhub.io/hbchen/hello_world:v0.1 \
  --id=hello-world-filter \
  --namespace=ns-httpbin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;http://{ingress-host}:{port}/headers&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;headers&amp;quot; : {
    &amp;quot;X-Hello&amp;quot; : &amp;quot;Hello world from {ingress-host}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;卸载&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ wasme undeploy istio \
  --id=hello-world-filter \
  --namespace=ns-httpbin
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;operator&#34;&gt;Operator&lt;/h3&gt;

&lt;p&gt;CRD&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl apply -f https://github.com/solo-io/wasme/releases/latest/download/wasme.io_v1_crds.yaml

customresourcedefinition.apiextensions.k8s.io/filterdeployments.wasme.io created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Operator&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl apply -f https://github.com/solo-io/wasme/releases/latest/download/wasme-default.yaml

namespace/wasme created
configmap/wasme-cache created
serviceaccount/wasme-cache created
serviceaccount/wasme-operator created
clusterrole.rbac.authorization.k8s.io/wasme-operator created
clusterrole.rbac.authorization.k8s.io/wasme-cache created
clusterrolebinding.rbac.authorization.k8s.io/wasme-operator created
clusterrolebinding.rbac.authorization.k8s.io/wasme-cache created
daemonset.apps/wasme-cache created
deployment.apps/wasme-operator created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Filter&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: wasme.io/v1
kind: FilterDeployment
metadata:
  name: hello-world-filter
  namespace: ns-httpbin
spec:
  deployment:
    istio:
      kind: Deployment
  filter:
    image: webassemblyhub.io/hbchen/hello_world:v0.1
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Filter 状态&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get filterdeployments.wasme.io -n ns-httpbin -o yaml hello-world-filter

status:
  observedGeneration: &amp;quot;1&amp;quot;
  workloads:
    httpbin:
      state: Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意看下 Pod 是否成功，如果&lt;code&gt;READY 1/2&lt;/code&gt;可能是&lt;code&gt;istio-proxy&lt;/code&gt;没有启动，测试时这里遇到问题&lt;code&gt;wasme-cache&lt;/code&gt;经常失败，可能是网络问题，并且失败后不能续传。可以进入 Pod 看缓存的尺寸是否和&lt;code&gt;hello_world.wasm&lt;/code&gt;尺寸一致，缓存路径&lt;code&gt;/var/local/lib/wasme-cache/&lt;/code&gt;，不一致就等缓存完成后再测试。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;http://{ingress-host}:{port}/headers&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;headers&amp;quot; : {
    &amp;quot;X-Hello&amp;quot; : &amp;quot;Hello world from {ingress-host}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;卸载&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl delete FilterDeployment -n ns-httpbin hello-world-filter
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ref&#34;&gt;Ref&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.solo.io/web-assembly-hub/latest/tutorial_code/&#34;&gt;WebAssembly Hub Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/blog/2020/deploy-wasm-declarative/&#34;&gt;Declarative WebAssembly deployment for Istio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.red-badger.com/extending-istio-with-rust-and-webassembly&#34;&gt;Extending Istio with Rust and WebAssembly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.solo.io/web-assembly-hub/latest/tutorial_code/deploy_tutorials/deploying_with_istio/&#34;&gt;Deploying Wasm Filters to Istio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/blog/2020/wasmhub-istio/&#34;&gt;Extended and Improved WebAssemblyHub to Bring the Power of WebAssembly to Envoy and Istio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>【DevOps】Drone CI/CD Go &#43; node &#43; kubernetes</title>
      <link>http://hbchen.com/post/devops/2020-05-07-drone/</link>
      <pubDate>Thu, 07 May 2020 20:38:53 +0800</pubDate>
      
      <guid>http://hbchen.com/post/devops/2020-05-07-drone/</guid>
      
        <description>&lt;p&gt;本文介绍如何使用 Drone 持续构建与发布 Golang + node + kubernetes 应用。&lt;/p&gt;

&lt;h2 id=&#34;docker-部署-drone&#34;&gt;Docker 部署 Drone&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;docker-compose.yaml&lt;/code&gt;示例， 其中配置项如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Key&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GITHUB_USER_NAME&lt;/td&gt;
&lt;td&gt;GitHub 的&lt;code&gt;username&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;TOKEN&lt;/td&gt;
&lt;td&gt;API 或 Cli 连接 Drone 服务用的 token，可以随机生成:&lt;code&gt;openssl rand -hex 16&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;GITHUB_CLIENT_ID&lt;/td&gt;
&lt;td&gt;参考 Drone 文档 &lt;a href=&#34;https://docs.drone.io/server/provider/github/#create-an-oauth-application&#34;&gt;GitHub 引导&lt;/a&gt; 创建 &lt;a href=&#34;https://github.com/settings/developers&#34;&gt;OAuth Application&lt;/a&gt;，配置参考如下:&lt;br/&gt;&lt;code&gt;Homepage URL&lt;/code&gt;为&lt;code&gt;http://{SERVER_HOST}&lt;/code&gt;，注意如果不是&lt;code&gt;80&lt;/code&gt;端口需要带端口，如&lt;code&gt;http://drone.hbchen.com:8000&lt;/code&gt;&lt;br/&gt;&lt;code&gt;Authorization callback URL&lt;/code&gt;为&lt;code&gt;{Homepage URL}/login&lt;/code&gt;，如&lt;code&gt;http://drone.hbchen.com:8000/login&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;GITHUB_CLIENT_SECRET&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;SERVER_HOST&lt;/td&gt;
&lt;td&gt;绑定的域名，如&lt;code&gt;drone.hbchen.com&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;RPC_SECRET&lt;/td&gt;
&lt;td&gt;Drone server 和 runner 通信用的 secret，可以随机生成:&lt;code&gt;openssl rand -hex 16&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;RUNNER_DASHBOARD_USERNAME&lt;/td&gt;
&lt;td&gt;&lt;code&gt;可选&lt;/code&gt;，Runner 可以在&lt;code&gt;3000&lt;/code&gt;端口提供一个 dashboard，如果需要可以配置用户名和密码&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;RUNNER_DASHBOARD_PASSWORD&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;如果外网使用的不是80端口（如此处使用&lt;code&gt;8000&lt;/code&gt;），在激活一个 Repo 后需要修改 Repo Webhook 的地址，增加端口&lt;/li&gt;
&lt;li&gt;为用户添加 admin 权限，做 cache 挂载 volume 时需要将 Repo 的 &lt;code&gt;Project settings&lt;/code&gt; 设置为 &lt;code&gt;trusted&lt;/code&gt;，要 admin 才有此权限&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: &#39;3&#39;

services:
  drone-server:
    image: drone/drone:1.6
    restart: always
    ports:
      - 8000:80
    volumes:
      - /var/lib/drone:/data
    environment:
      - DRONE_USER_CREATE=username:{GITHUB_USER_NAME},machine:false,admin:true,token:{TOKEN}
      - DRONE_GITHUB_SERVER=https://github.com
      - DRONE_GITHUB_CLIENT_ID={GITHUB_CLIENT_ID}
      - DRONE_GITHUB_CLIENT_SECRET={GITHUB_CLIENT_SECRET}
      - DRONE_GITHUB_SKIP_VERIFY=true
      - DRONE_SERVER_HOST={SERVER_HOST}
      - DRONE_SERVER_PROTO=http
      - DRONE_RPC_SECRET={RPC_SECRET}

  drone-runner:
    image: drone/drone-runner-docker:1.2
    restart: always
    ports:
      - 3000:3000
    depends_on:
      - drone-server
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - DRONE_RPC_HOST=drone-server
      - DRONE_RPC_PROTO=http
      - DRONE_RPC_SECRET={RPC_SECRET}
      - DRONE_RUNNER_NAME=drone-runner
      - DRONE_RUNNER_CAPACITY=2
      - DRONE_UI_USERNAME={RUNNER_DASHBOARD_USERNAME}
      - DRONE_UI_PASSWORD={RUNNER_DASHBOARD_PASSWORD}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;drone-pipeline&#34;&gt;Drone Pipeline&lt;/h2&gt;

&lt;h3 id=&#34;secret-配置&#34;&gt;Secret 配置&lt;/h3&gt;

&lt;p&gt;Pipeline 涉及到 Secret 配置与我们的目标相关，以&lt;a href=&#34;https://github.com/micro-in-cn/starter-kit/blob/master/.drone.yml&#34;&gt;micro-in-cn/starter-kit/.drone.yml&lt;/a&gt;为例：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Docker 镜像发布

&lt;ul&gt;
&lt;li&gt;push 镜像需要仓库用户名及密码&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;k8s 部署

&lt;ul&gt;
&lt;li&gt;kubectl 需要配置&lt;code&gt;server&lt;/code&gt;、&lt;code&gt;ca&lt;/code&gt;和&lt;code&gt;token&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;k8s 配置获取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1.取一个 Pod 的 Secret 或者单独创建一个 account&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl describe po {pod-name} | grep SecretName
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.取Secret的ca和token&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl get secret {secret-name} -o yaml | egrep &#39;ca.crt:|token:&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.drone secret 配置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;k8s_server&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cat ~/.kube/config&lt;/code&gt;，&lt;em&gt;适用于&lt;code&gt;minikube&lt;/code&gt;环境&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;k8s_ca&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;ca直接使用&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;k8s_token&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;token做base64解码后使用&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;kubectl&lt;/code&gt;部署需要对应的account有授权&lt;/strong&gt;，根据自己的环境情况配置&lt;br/&gt;
测试可以将clusterrole=cluster-admin授权给serviceaccount&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Error from server (Forbidden): services is forbidden: User &amp;quot;system:serviceaccount:default:default&amp;quot; cannot list resource &amp;quot;services&amp;quot; in API group &amp;quot;&amp;quot; in the namespace &amp;quot;default&amp;quot;
kubectl create clusterrolebinding cluster-admin-role-bound --clusterrole=cluster-admin --serviceaccount={namespace}:{service-account}
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;使用 drone cli 工具连接 drone server&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;喜欢 web 操作可以选择在控制台配置 secret&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export DRONE_SERVER=http://drone.hbchen.com:8000
export DRONE_TOKEN={前面配置的TOKEN}
drone info
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;drone secret add --repository=micro-in-cn/starter-kit --name=ali_registry_username --data={xxx}
drone secret add --repository=micro-in-cn/starter-kit --name=ali_registry_password --data={xxx}
drone secret add --repository=micro-in-cn/starter-kit --name=k8s_server --data={xxx}
drone secret add --repository=micro-in-cn/starter-kit --name=k8s_ca --data={xxx}
drone secret add --repository=micro-in-cn/starter-kit --name=k8s_token --data={xxx}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译-缓存&#34;&gt;编译&amp;amp;缓存&lt;/h3&gt;

&lt;p&gt;在项目编译时都会有大量的依赖下载，这些对编译速度影响很大，并且容易导致失败，所以需要使用缓存，避免每次都要重新拉取依赖，以&lt;a href=&#34;https://github.com/micro-in-cn/starter-kit/blob/master/console/web&#34;&gt;micro-in-cn/starter-kit/console/web&lt;/a&gt;为例，有 Golang 和 node 的编译，使用 drone 社区&lt;code&gt;drillster/drone-volume-cache&lt;/code&gt;插件对 Golang 和 node 依赖进行缓存。基本过程就是在编译前将&lt;code&gt;cache&lt;/code&gt;加载到相应目录，编译后重新将&lt;code&gt;cache&lt;/code&gt;写回&lt;code&gt;volume&lt;/code&gt;，编译时 Golang 需要指定&lt;code&gt;GOPATH&lt;/code&gt;，node 指定&lt;code&gt;global cache&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# 挂载 host 缓存目录
volumes:
  - name: cache
    host:
      path: /tmp/drone_cache

steps:
  - name: restore-cache
    image: drillster/drone-volume-cache
    settings:
      restore: true
      mount:
        - ./.npm-cache
        - ./console/web/vue/node_modules
        - ./_gopath
    volumes:
      - name: cache
        path: /cache
    when:
      event:
        - push
  - name: build-vue
    image: node:10.16.3-alpine
    commands:
      - cd console/web/vue
      - npm config set cache ./.npm-cache --global
      - npm install
      - export VUE_APP_BASE_API=
      - npm run build:prod
    when:
      event:
        - push
  - name: build-golang
    image: golang:1.13-alpine
    environment:
      GOPATH: /drone/src/github.com/micro-in-cn/starter-kit/_gopath
      GOOS: linux
      GOARCH: amd64
      CGO_ENABLED: 0
      GOPROXY: https://mirrors.aliyun.com/goproxy/,direct
      GOSUMDB: off
    commands:
      - cd console/web
      - go version
      - go build -o ./bin/linux_amd64/console-web main.go plugin.go
    when:
      event:
        - push
  - name: rebuild-cache
    image: drillster/drone-volume-cache
    settings:
      rebuild: true
      mount:
        - ./.npm-cache
        - ./console/web/vue/node_modules
        - ./_gopath
    volumes:
      - name: cache
        path: /cache
    when:
      event:
        - push
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;发布镜像-部署&#34;&gt;发布镜像&amp;amp;部署&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;docker username 和 password 通过 secret 获取&lt;/li&gt;
&lt;li&gt;k8s 先用 secret 配置环境变量，使用时再从环境变量去取&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  - name: publish-xxx
    image: plugins/docker
    settings:
      tags: latest
      dockerfile: ./console/api/Dockerfile
      context: ./console/web
      repo: registry.cn-hangzhou.aliyuncs.com/hb-chen/starter-kit-console-api
      registry: registry.cn-hangzhou.aliyuncs.com
      username:
        from_secret: ali_registry_username
      password:
        from_secret: ali_registry_password
    when:
      event:
        - push
  - name: deploy-xxx
    image: dtzar/helm-kubectl:3.1.1
    environment:
      SERVER:
        from_secret: k8s_server
      CERTIFICATE_AUTHORITY_DATA:
        from_secret: k8s_ca
      USER_TOKEN:
        from_secret: k8s_token
    commands:
      - kubectl config set-cluster k8s --server=&amp;quot;$${SERVER}&amp;quot;
      - kubectl config set clusters.k8s.certificate-authority-data &amp;quot;$${CERTIFICATE_AUTHORITY_DATA}&amp;quot;
      - kubectl config set-credentials k8s-admin --token=&amp;quot;$${USER_TOKEN}&amp;quot;
      - kubectl config set-context default --cluster=k8s --user=k8s-admin
      - kubectl config use-context default
      - helm template micro ./deploy/k8s/helm/starter-kit/charts/service --namespace starter-kit --set nameOverride=console-api --set micro.command=/console-api --set image.repository=registry.cn-hangzhou.aliyuncs.com/hb-chen/starter-kit-console-api --set image.tag=${DRONE_TAG=latest} --set image.pullPolicy=Always --set serviceAccount.create=true --set serviceAccount.name=micro-services | kubectl apply -f -
    when:
      event:
        - push
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】开发协作-本地服务接入线上集成环境</title>
      <link>http://hbchen.com/post/microservice/2020-03-22-micro-dev-local/</link>
      <pubDate>Sun, 22 Mar 2020 10:53:43 +0800</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2020-03-22-micro-dev-local/</guid>
      
        <description>&lt;p&gt;在&lt;a href=&#34;http://hbchen.com/post/microservice/2019-11-30-go-micro-service-chain/&#34;&gt;微服务协作开发、灰度发布之流量染色&lt;/a&gt;介绍了如何通过流量染色在开发环境进行多服务、多版本的协作开发，
但这都是在服务已经发布到集成环境情况下，开发过程中对于单个服务的开发/维护者往往需要快速的将本地服务集成到在线环境，以完成更好集成测试，而不是等待发布流程，
这样一是节约时间，二是避免将有问题的服务发布到线上集成环境，对Ta人造成影响。本文将介绍在&lt;code&gt;micro&lt;/code&gt;生态如何通过&lt;code&gt;network&lt;/code&gt;将本地服务加入到线上集成环境，既可以快速测试，又不影响集成环境。&lt;/p&gt;

&lt;h1 id=&#34;方案&#34;&gt;方案&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/micro/dev-local.png&#34; alt=&#34;network_dev_local&#34; /&gt;&lt;/p&gt;

&lt;p&gt;整体方案一是&lt;code&gt;go-micro&lt;/code&gt;的服务的&lt;code&gt;proxy&lt;/code&gt;方式，，并且在代理中有&lt;code&gt;router&lt;/code&gt;筛选功能，二是&lt;code&gt;network&lt;/code&gt;提供连接不同网络环境的能力。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;首先在线上和本地部署&lt;code&gt;network&lt;/code&gt;服务，有关&lt;code&gt;network&lt;/code&gt;的内容可以参考本文&lt;a href=&#34;http://hbchen.com/post/microservice/2019-11-15-go-micro-network/&#34;&gt;【go-micro】Network初探&lt;/a&gt;，
有了&lt;code&gt;network&lt;/code&gt;的基础剩下的工作就是&lt;code&gt;proxy&lt;/code&gt;的&lt;code&gt;router&lt;/code&gt;筛选功能，实现参考 PR&lt;a href=&#34;https://github.com/micro/go-micro/pull/897&#34;&gt;#897&lt;/a&gt;，
从实现我们知道通过&lt;code&gt;Micro-Router&lt;/code&gt;、&lt;code&gt;Micro-Network&lt;/code&gt;和&lt;code&gt;Micro-Gateway&lt;/code&gt;三个&lt;code&gt;metadata&lt;/code&gt;可以对&lt;code&gt;router&lt;/code&gt;进行筛选，而使用&lt;code&gt;Micro-Address&lt;/code&gt;以及基于&lt;code&gt;label&lt;/code&gt;的筛选还处于&lt;strong&gt;&lt;em&gt;TODO&lt;/em&gt;&lt;/strong&gt;状态。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;其次在线上及本地所有服务都需要是用&lt;code&gt;network&lt;/code&gt;做为代理(&lt;code&gt;MICRO_PROXY=go.micro.network&lt;/code&gt;)包括网关(&lt;em&gt;注意默认网关不支持服务筛选，导致网关不能用network做代理&lt;/em&gt;)，这样服务间所有流量都通过&lt;code&gt;network&lt;/code&gt;进行代理转发。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最后考虑所有服务都可以自助路由到个人本地，我们不能直接使用&lt;code&gt;Micro-Router&lt;/code&gt;，因为&lt;code&gt;Micro-Router&lt;/code&gt;会在全链路生效，需要使用&lt;code&gt;metadata&lt;/code&gt;来传递&lt;code&gt;router&lt;/code&gt;筛选信息，
再通过&lt;code&gt;Client/Call Wrap&lt;/code&gt;实现&lt;code&gt;Micro-Router&lt;/code&gt;的恢复和清理，在识别到调用服务需要筛选时添加&lt;code&gt;Micro-Router&lt;/code&gt;，否则清理&lt;code&gt;Micro-Router&lt;/code&gt;，避免向下传导，实践参考&lt;a href=&#34;https://github.com/micro-in-cn/starter-kit/tree/master/pkg/plugin/wrapper/client/router_filter&#34;&gt;router_filter&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;实践参考&lt;/em&gt;&lt;/strong&gt; &lt;a href=&#34;https://github.com/micro-in-cn/starter-kit#%E6%9C%AC%E5%9C%B0%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%85%A5-network%E4%BB%A3%E7%90%86&#34;&gt;micro-in-cn/starter-kit#本地服务接入-network代理&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;局限性-问题&#34;&gt;局限性/问题&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;所有服务都要使用&lt;code&gt;network&lt;/code&gt;做代理，如果框架能够在&lt;code&gt;CallOption&lt;/code&gt;中支持动态使用代理将会更好&lt;/li&gt;
&lt;li&gt;所有服务都需要添加&lt;code&gt;Client/Call Wrap&lt;/code&gt;，需要统一的规范约定&lt;/li&gt;
&lt;li&gt;在网关层与&lt;a href=&#34;http://hbchen.com/post/microservice/2019-11-30-go-micro-service-chain/#%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E7%AD%9B%E9%80%89-%E5%9D%91&#34;&gt;流量染色&lt;/a&gt;遇到相同的问题即：&lt;strong&gt;&lt;em&gt;不支持服务筛选，导致网关不能用network做代理&lt;/em&gt;&lt;/strong&gt;，需要去掉&lt;code&gt;SelectOption&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;另一个思路是在本地开&lt;code&gt;micro api&lt;/code&gt; + &lt;code&gt;聚合服务&lt;/code&gt;，聚合服务再通过 network 代理访问线上服务&lt;/strong&gt;，可以满足一般场景的需求&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;为了避免误协作过程中路由到Ta人本地环境，可以再增加&lt;code&gt;Micro-Network&lt;/code&gt;规则，线上与本地&lt;code&gt;network&lt;/code&gt;使用不同名称(&lt;em&gt;未实测&lt;/em&gt;)

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;如果框架能够在路由选择上有&lt;code&gt;route.Link=local&lt;/code&gt;这样的本地优先策略会有一个更好的体验&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio】使用istioctl安装</title>
      <link>http://hbchen.com/post/servicemesh/2020-03-22-istio-install-istioctl/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2020-03-22-istio-install-istioctl/</guid>
      
        <description>&lt;p&gt;&lt;code&gt;istioctl&lt;/code&gt;是当前官方推荐的安装方式，相比&lt;code&gt;helm&lt;/code&gt;有更好的体验，但实践过程中也遇到些问题，在此对&lt;code&gt;1.5.0&lt;/code&gt;版本的使用做个整理。
包括默认安装、可观察性组件、外部Chart等自定义安装。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安装 Istio 环境&lt;/li&gt;
&lt;li&gt;部署 httpbin 用例&lt;/li&gt;
&lt;li&gt;Prometheus、Grafana和Kiali组件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;minikube version: v1.7.2&lt;/li&gt;
&lt;li&gt;kubernetes version: v1.16.7&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;istioctl&#34;&gt;istioctl&lt;/h1&gt;

&lt;p&gt;参考&lt;a href=&#34;https://istio.io/docs/setup/getting-started/#download&#34;&gt;官方文档&lt;/a&gt;下载或者到&lt;a href=&#34;https://github.com/istio/istio/releases/tag/1.5.0&#34;&gt;Github&lt;/a&gt;选择平台下载，
然后将&lt;code&gt;bin&lt;/code&gt;目录加入 path 环境变量。&lt;/p&gt;

&lt;p&gt;检验&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl version
2020-03-21T10:21:14.012409Z	warn	will use `--remote=false` to retrieve version info due to `no Istio pods in namespace &amp;quot;istio-system&amp;quot;`
1.5.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;istio-默认安装&#34;&gt;Istio 默认安装&lt;/h1&gt;

&lt;p&gt;默认安装很简单，只需要一个&lt;code&gt;manifest apply&lt;/code&gt;命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl manifest apply
This will install the default Istio profile into the cluster. Proceed? (y/N) y
Detected that your cluster does not support third party JWT authentication. Falling back to less secure first party JWT. See https://istio.io/docs/ops/best-practices/security/#configure-third-party-service-account-tokens for details.
- Applying manifest for component Base...
✔ Finished applying manifest for component Base.
- Applying manifest for component Pilot...
✔ Finished applying manifest for component Pilot.
  Waiting for resources to become ready...
  Waiting for resources to become ready...
- Applying manifest for component IngressGateways...
- Applying manifest for component AddonComponents...
✔ Finished applying manifest for component AddonComponents.
✔ Finished applying manifest for component IngressGateways.

✔ Installation complete
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;如果安装过程遇到镜像无法下载导致失败，可以使用&lt;code&gt;--set&lt;/code&gt;设置替换镜像，默认安装涉及两个镜像源配置:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;istio相关镜像：&lt;code&gt;--set hub=dockerhub.azk8s.cn/istio&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;prometheus镜像：&lt;code&gt;--set values.prometheus.hub=dockerhub.azk8s.cn/prom&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl manifest apply \
--set hub=dockerhub.azk8s.cn/istio \
--set values.prometheus.hub=dockerhub.azk8s.cn/prom
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;检验&lt;code&gt;Pod&lt;/code&gt;，只有三个运行实例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl get po -n istio-system
    NAME                                    READY   STATUS    RESTARTS   AGE
    istio-ingressgateway-78f757846c-7sqg7   1/1     Running   0          69s
    istiod-65c5b8df9d-qglhr                 1/1     Running   0          87s
    prometheus-6fd77b7876-dk4xq             2/2     Running   0          67s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检验&lt;code&gt;Service&lt;/code&gt;，注意&lt;code&gt;istio-ingressgateway&lt;/code&gt;暴露的端口，后面&lt;code&gt;prometheus&lt;/code&gt;、&lt;code&gt;grafana&lt;/code&gt;和&lt;code&gt;kiali&lt;/code&gt;的&lt;code&gt;gateway&lt;/code&gt;会用到&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get svc -n istio-system
    NAME                   TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                      AGE
    istio-ingressgateway   LoadBalancer   10.100.77.12     &amp;lt;pending&amp;gt;     15020:31791/TCP,80:31302/TCP,443:31151/TCP,15029:31679/TCP,15030:31818/TCP,15031:31327/TCP,15032:30470/TCP,15443:31898/TCP   101s
    istio-pilot            ClusterIP      10.98.216.5      &amp;lt;none&amp;gt;        15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                                                                     2m3s
    istiod                 ClusterIP      10.109.224.120   &amp;lt;none&amp;gt;        15012/TCP,443/TCP                                                                                                            2m2s
    prometheus             ClusterIP      10.105.60.208    &amp;lt;none&amp;gt;        9090/TCP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时测试网关&lt;code&gt;80&lt;/code&gt;端口映射的&lt;code&gt;31302&lt;/code&gt;会得到&lt;code&gt;404&lt;/code&gt;，因为我们还没有任何服务，&lt;code&gt;INGRESS_HOST&lt;/code&gt;参考&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/ingress/ingress-control/#determining-the-ingress-ip-and-ports&#34;&gt;官方文档&lt;/a&gt;根据环境获取，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -I  http://{INGRESS_HOST}:31302
    HTTP/1.1 404 Not Found
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;部署httpbin&#34;&gt;部署httpbin&lt;/h1&gt;

&lt;p&gt;首先为&lt;code&gt;namespace&lt;/code&gt;添加&lt;code&gt;istio-injection=enabled&lt;/code&gt;标签，开启自动注入&lt;code&gt;sidecar&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl label namespace default istio-injection=enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;部署&lt;code&gt;httpbin&lt;/code&gt;服务以及网关&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd {istio-1.5.0_path}
kubectl apply -f samples/httpbin/httpbin.yaml -f samples/httpbin/httpbin-gateway.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检验&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl get po -n default
    NAME                       READY   STATUS    RESTARTS   AGE
    httpbin-779c54bf49-dgcs4   2/2     Running   0          39s

kubectl get gateway -n default
    NAME              AGE
    httpbin-gateway   2m1s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;测试服务&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -I  http://192.168.39.130:31302
    HTTP/1.1 200 OK

curl http://192.168.39.130:31302/get
    {...}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;可观察性组件&#34;&gt;可观察性组件&lt;/h1&gt;

&lt;p&gt;Istio的一大特点可观察性，主要由&lt;code&gt;Prometheus&lt;/code&gt;、&lt;code&gt;Grafana&lt;/code&gt;、&lt;code&gt;Kiali&lt;/code&gt;和&lt;code&gt;Tracing&lt;/code&gt;，其中&lt;code&gt;Prometheus&lt;/code&gt;是默认安装组件。
前面在安装后检验&lt;code&gt;Service&lt;/code&gt;时有提到&lt;code&gt;istio-ingressgateway&lt;/code&gt;暴露的端口，其中有四个端口分别对应这4个服务：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;端口&lt;/th&gt;
&lt;th&gt;映射&lt;/th&gt;
&lt;th&gt;服务&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;15029&lt;/td&gt;
&lt;td&gt;31679&lt;/td&gt;
&lt;td&gt;kiali&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;15030&lt;/td&gt;
&lt;td&gt;31818&lt;/td&gt;
&lt;td&gt;prometheus&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;15031&lt;/td&gt;
&lt;td&gt;31327&lt;/td&gt;
&lt;td&gt;grafana&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;15032&lt;/td&gt;
&lt;td&gt;30470&lt;/td&gt;
&lt;td&gt;tracing&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;虽然端口已经暴露，但每个服务对应的&lt;code&gt;gateway&lt;/code&gt;需要自定义开启，配置路径为&lt;code&gt;values.gateways.istio-ingressgateway.telemetry_addon_gateways.xxx_gateway&lt;/code&gt;，
对应&lt;code&gt;yaml&lt;/code&gt;为&lt;code&gt;gateways/istio-ingress/templates/addongateway.yaml&lt;/code&gt;，配置间&lt;code&gt;istio-ingress&lt;/code&gt;的&lt;code&gt;values&lt;/code&gt;。
在&lt;code&gt;addongateway.yaml&lt;/code&gt;模板中都默认为&lt;code&gt;https&lt;/code&gt;，如果测试不方便需要自己手动修改&lt;code&gt;gateway&lt;/code&gt;，也可以参考后面的&lt;a href=&#34;#外部Chart&#34;&gt;#外部Chart&lt;/a&gt;进行自定义安装。&lt;/p&gt;

&lt;h2 id=&#34;prometheus&#34;&gt;Prometheus&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Prometheus&lt;/code&gt;默认是安装，所以只需要启用&lt;code&gt;gateway&lt;/code&gt;即可&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl manifest apply \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.prometheus_gateway.enabled=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Gateway改为HTTP服务&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-prometheus-gateway
  namespace: istio-system
  labels:
    app: prometheus
    release: istio
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15030
        name: https-prometheus
        protocol: HTTP
      hosts:
        - &amp;quot;*&amp;quot;
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;访问 http://{INGRESS_HOST}:31818 即可进入Prometheus的Web页面，先为&lt;code&gt;httpbin&lt;/code&gt;灌入一些流量然后看&lt;code&gt;Prometheus&lt;/code&gt;数据情况&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hey -z 60s -c 2 http://{INGRESS_HOST}:31302/get
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/prometheus-httpbin.png&#34; alt=&#34;prometheus httpbin&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;grafana-kiali-tracing&#34;&gt;Grafana &amp;amp; Kiali &amp;amp; Tracing&lt;/h2&gt;

&lt;p&gt;这三个服务默认是不启动的，所以需要手动设置&lt;code&gt;enabled&lt;/code&gt;，其中&lt;code&gt;kiali&lt;/code&gt;需要增加一个&lt;code&gt;createDemoSecret=true&lt;/code&gt;的配置，使用默认用户名(admin)和密码(admin)创建密钥，否则会有异常:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Kiali secret is missing. Users are prohibited from accessing Kiali until an administrator creates a valid secret. Please refer to the Kiali documentation for more details.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl manifest apply \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.prometheus_gateway.enabled=true \
--set addonComponents.grafana.enabled=true \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.grafana_gateway.enabled=true \
--set addonComponents.kiali.enabled=true \
--set values.kiali.createDemoSecret=true \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.kiali_gateway.enabled=true \
--set addonComponents.tracing.enabled=true \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.tracing_gateway.enabled=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样将&lt;code&gt;gateway&lt;/code&gt;改为&lt;code&gt;http&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-prometheus-gateway
  namespace: istio-system
  labels:
    app: prometheus
    release: istio
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15030
        name: https-prometheus
        protocol: HTTP
      hosts:
        - &amp;quot;*&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-grafana-gateway
  namespace: istio-system
  labels:
    app: grafana
    release: istio
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15031
        name: https-grafana
        protocol: HTTP
      hosts:
        - &amp;quot;*&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-kiali-gateway
  namespace: istio-system
  labels:
    app: kiali
    release: istio
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15029
        name: https-kiali
        protocol: HTTP
      hosts:
        - &amp;quot;*&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-tracing-gateway
  namespace: istio-system
  labels:
    app: tracing
    release: istio
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15032
        name: https-tracing
        protocol: HTTP
      hosts:
        - &amp;quot;*&amp;quot;
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在再次给&lt;code&gt;httpbin&lt;/code&gt;灌入流量查看各个服务的效果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hey -z 300s -c 2 http://{INGRESS_HOST}:31302/get
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Grafana&lt;/strong&gt;
&lt;img src=&#34;http://hbchen.com/img/istio/grafana-httpbin.png&#34; alt=&#34;grafana httpbin&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kiali&lt;/strong&gt;
&lt;img src=&#34;http://hbchen.com/img/istio/kiali-httpbin.png&#34; alt=&#34;kiali httpbin&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tracing&lt;/strong&gt;
&lt;img src=&#34;http://hbchen.com/img/istio/tracing-httpbin.png&#34; alt=&#34;tracing httpbin&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;外部chart-坑&#34;&gt;外部Chart-坑&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://istio.io/docs/setup/install/istioctl/#install-from-external-charts&#34;&gt;官方文档&lt;/a&gt;有关使用外部Chart的部分存在问题，&lt;code&gt;installPackagePath&lt;/code&gt;无效，需要用&lt;code&gt;install_package_path&lt;/code&gt;替换，同时需要指定&lt;code&gt;profile&lt;/code&gt;，应该也是istio实现&lt;a href=&#34;https://github.com/istio/istio/issues/22368&#34;&gt;BUG&lt;/a&gt;，
文档修改和BUG修复的PR &lt;a href=&#34;https://github.com/istio/istio.io/pull/6939&#34;&gt;istio/istio.io#6939&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/istio/istio/pull/22371&#34;&gt;istio/istio#22371&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;release-1.5 最新版本已经修复此问题(&lt;em&gt;文档更新PR &lt;a href=&#34;https://github.com/istio/istio.io/pull/6939&#34;&gt;istio/istio.io#6939&lt;/a&gt;未被采纳&lt;/em&gt;)，所以如果&lt;code&gt;istioctl&lt;/code&gt;使用的是&lt;code&gt;1.5.0&lt;/code&gt;的Release版本此问题仍然存在，在使用这一部分文档(&lt;a href=&#34;https://istio.io/docs/setup/install/istioctl/#install-from-external-charts&#34;&gt;install-from-external-charts&lt;/a&gt;)时需要要注意&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;addongateway.yaml&lt;/code&gt;的Gateway改为HTTP&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# Template for telemetry addon gateways
{{ $gateway := index .Values &amp;quot;gateways&amp;quot; &amp;quot;istio-ingressgateway&amp;quot; }}
{{ range $addon := $gateway.telemetry_addon_gateways }}
{{ if $addon.enabled }}
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-{{ $addon.name }}-gateway
  namespace: {{ $.Release.Namespace }}
  labels:
    app: {{ $addon.name }}
    release: {{ $.Release.Name }}
spec:
  selector:
    istio: ingressgateway
  servers:
{{- if $addon.tls }}
    - port:
        number: {{ $addon.port }}
        name: https-{{ $addon.name }}
        protocol: HTTPS
      tls:
        mode: SIMPLE
        serverCertificate: /etc/istio/ingressgateway-certs/tls.crt
        privateKey: /etc/istio/ingressgateway-certs/tls.key
      hosts:
        - &amp;quot;*&amp;quot;
  {{- else }}
    - port:
        number: {{ $addon.port }}
        name: http-{{ $addon.name }}
        protocol: HTTP
        hosts:
          - &amp;quot;*&amp;quot;
{{- end }}
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: {{ $addon.name }}-virtual-service
  namespace: {{ $.Release.Namespace }}
  labels:
    app: {{ $addon.name }}
    release: {{ $.Release.Name }}
spec:
  hosts:
    - &amp;quot;*&amp;quot;
  gateways:
    - istio-{{ $addon.name }}-gateway
  http:
    - match:
        - port: {{ $addon.port }}
      route:
        - destination:
            host: {{ $addon.name }}.{{ $.Release.Namespace }}.svc.{{ $.Values.global.proxy.clusterDomain }}
            port:
              number: {{ $addon.desPort }}
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: {{ $addon.name }}
  namespace: {{ $.Release.Namespace }}
  labels:
    app: {{ $addon.name }}
    release: {{ $.Release.Name }}
spec:
  host: {{ $addon.name }}.{{ $.Release.Namespace }}.svc.{{ $.Values.global.proxy.clusterDomain }}
  trafficPolicy:
    tls:
      mode: DISABLE
---
{{- end }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定外部Chart部署&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl manifest apply \
--set profile=$PWD/install/kubernetes/operator/profiles/default.yaml \
--set install_package_path=$PWD/install/kubernetes/operator/charts \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.prometheus_gateway.enabled=true \
--set addonComponents.grafana.enabled=true \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.grafana_gateway.enabled=true \
--set addonComponents.kiali.enabled=true \
--set values.kiali.createDemoSecret=true \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.kiali_gateway.enabled=true \
--set addonComponents.tracing.enabled=true \
--set values.gateways.istio-ingressgateway.telemetry_addon_gateways.tracing_gateway.enabled=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&lt;code&gt;--set&lt;/code&gt;过于麻烦可以使用&lt;code&gt;yaml&lt;/code&gt;文件进行配置，&lt;code&gt;profile&lt;/code&gt;和&lt;code&gt;install_package_path&lt;/code&gt;的路径以istio的下载路径为例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ vi profile.yaml

apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  namespace: istio-system
  name: istio-operator
spec:
  profile: {istio-path}/install/kubernetes/operator/profiles/default.yaml
  install_package_path: {istio-path}/install/kubernetes/operator/charts
  
  addonComponents:
    prometheus:
      enabled: true
    kiali:
      enabled: true
    grafana:
      enabled: true
    tracing:
      enabled: true

  values:
    gateways:
      istio-ingressgateway:
        telemetry_addon_gateways:
          prometheus_gateway:
            enabled: true
          grafana_gateway:
            enabled: true
          kiali_gateway:
            enabled: true
          tracing_gateway:
            enabled: true
    kiali:
      createDemoSecret: true
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;istioctl manifest apply \
-f profile.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有关自定义安装的&lt;code&gt;chart&lt;/code&gt;、&lt;code&gt;profile&lt;/code&gt;在&lt;a href=&#34;https://github.com/hb-chen/istio-operator&#34;&gt;hb-chen/istio-operator&lt;/a&gt;有些示例可以参考。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio源码】Citadel &amp; Node Agent</title>
      <link>http://hbchen.com/post/servicemesh/2020-01-07-istio-code-security/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2020-01-07-istio-code-security/</guid>
      
        <description>&lt;p&gt;Istio安全主要包括&lt;strong&gt;认证&lt;/strong&gt;和&lt;strong&gt;授权&lt;/strong&gt;，有关授权的&lt;code&gt;RBAC&lt;/code&gt;使用参考之前的文章&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/#1-开启授权-clusterrbacconfig&#34;&gt;【Istio安全】服务间访问控制-RBAC&lt;/a&gt;
，不过&lt;code&gt;RBAC&lt;/code&gt;已经&lt;a href=&#34;https://istio.io/docs/reference/config/security/istio.rbac.v1alpha1/&#34;&gt;准备废弃&lt;/a&gt;被&lt;code&gt;Authorization&lt;/code&gt;替代，
&lt;strong&gt;认证&lt;/strong&gt;则分为&lt;strong&gt;服务间身份验证&lt;/strong&gt;和&lt;strong&gt;来源身份认证&lt;/strong&gt;，服务间身份验证Istio提供了&lt;strong&gt;双向TLS&lt;/strong&gt;方案，其中涉及的秘钥管理服务，主要由&lt;code&gt;istio/security&lt;/code&gt;模块的
&lt;code&gt;Citadel&lt;/code&gt;和&lt;code&gt;Node Agent&lt;/code&gt;提供，本文主要分析这部分的源码实现。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Istio 1.14.0&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;pki&#34;&gt;PKI&lt;/h1&gt;

&lt;p&gt;首先参考&lt;a href=&#34;https://preliminary.istio.io/zh/docs/concepts/security/#pki&#34;&gt;官方文档&lt;/a&gt;[&lt;a href=&#34;https://istio.io/docs/concepts/security/#pki&#34;&gt;en&lt;/a&gt;]看下几种不同场景的方案，其中&lt;code&gt;Kubernetes 方案&lt;/code&gt;最简单，
&lt;code&gt;Kubernetes 中的代理节点&lt;/code&gt;更适合生产，具体优势&lt;a href=&#34;https://preliminary.istio.io/zh/docs/tasks/security/citadel-config/auth-sds&#34;&gt;参考&lt;/a&gt;[&lt;a href=&#34;https://istio.io/docs/tasks/security/citadel-config/auth-sds/&#34;&gt;en&lt;/a&gt;]。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 方案

&lt;ul&gt;
&lt;li&gt;Citadel 监视 Kubernetes apiserver，为每个现有和新的服务帐户创建 SPIFFE 证书和密钥对。Citadel 将证书和密钥对存储为 Kubernetes secret。&lt;/li&gt;
&lt;li&gt;创建 pod 时，Kubernetes 会根据其服务帐户通过 Kubernetes secret volume 将证书和密钥对挂载到 pod 上。&lt;/li&gt;
&lt;li&gt;Citadel 监视每个证书的生命周期，并通过重写 Kubernetes secret 自动轮换证书。&lt;/li&gt;
&lt;li&gt;Pilot 生成安全命名信息，该信息定义了哪些 Service Account 可以运行哪些服务。Pilot 然后将安全命名信息传递给 envoy sidecar。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;本地机器方案

&lt;ul&gt;
&lt;li&gt;Citadel 创建 gRPC 服务来接受证书签名请求（CSR）。&lt;/li&gt;
&lt;li&gt;节点代理生成私钥和 CSR，并将 CSR 及其凭据发送给 Citadel 进行签名。&lt;/li&gt;
&lt;li&gt;Citadel 验证 CSR 承载的凭证，并签署 CSR 以生成证书。&lt;/li&gt;
&lt;li&gt;节点代理将从 Citadel 接收的证书和私钥发送给 Envoy。&lt;/li&gt;
&lt;li&gt;上述 CSR 过程会定期重复进行证书和密钥轮换。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Kubernetes 中的代理节点

&lt;ul&gt;
&lt;li&gt;Citadel 创建一个 gRPC 服务来接受 CSR 请求。&lt;/li&gt;
&lt;li&gt;Envoy 通过 Envoy secret 发现服务（SDS）API 发送证书和密钥请求。&lt;/li&gt;
&lt;li&gt;收到 SDS 请求后，节点代理会创建私钥和 CSR，并将 CSR 及其凭据发送给 Citadel 进行签名。&lt;/li&gt;
&lt;li&gt;Citadel 验证 CSR 中携带的凭证，并签署 CSR 以生成证书。&lt;/li&gt;
&lt;li&gt;节点代理通过 Envoy SDS API 将从 Citadel 接收的证书和私钥发送给 Envoy。&lt;/li&gt;
&lt;li&gt;上述 CSR 过程会定期重复进行证书和密钥轮换。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;ca管理-citadel&#34;&gt;CA管理-Citadel&lt;/h1&gt;

&lt;p&gt;Citadel(源码入口&lt;code&gt;istio/security/cmd/istio_ca&lt;/code&gt;)是Istio自带的秘钥管理服务，使用代理节点也支持外部CA系统，如：VaultCA和GoogleCA。&lt;/p&gt;

&lt;p&gt;包括以下能力：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;证书管理:&lt;code&gt;pki/ca&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#istioca&#34;&gt;IstioCA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;工作负载的证书轮换:&lt;code&gt;k8s/controller&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#secretcontroller&#34;&gt;SecretController&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;证书签名服务:&lt;code&gt;server/ca&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#server&#34;&gt;Server&lt;/a&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;TODO 配图&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;istioca&#34;&gt;IstioCA&lt;/h2&gt;

&lt;p&gt;IstioCa支持两种方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自签名证书，自动轮换&lt;a href=&#34;#selfsignedca&#34;&gt;SelfSignedCA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;外部文件证书
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;selfsignedca&#34;&gt;SelfSignedCA&lt;/h3&gt;

&lt;p&gt;自签名证书，自动轮换管理由&lt;code&gt;SelfSignedCARootCertRotator&lt;/code&gt;实现，默认&lt;code&gt;1小时&lt;/code&gt;做一次证书的检查。&lt;/p&gt;

&lt;h2 id=&#34;secretcontroller&#34;&gt;SecretController&lt;/h2&gt;

&lt;p&gt;在Kubernetes方案中工作负载的证书管理，Citadel通过修改&lt;code&gt;secret&lt;/code&gt;对工作负载的证书进行管理，&lt;code&gt;SecretController&lt;/code&gt;监控&lt;code&gt;ServiceAccount&lt;/code&gt;的创建、删除，
&lt;code&gt;Secret&lt;/code&gt;的删除、更新，以及&lt;code&gt;Namespace&lt;/code&gt;的更新，在产生变更时修改&lt;code&gt;secret&lt;/code&gt;完成证书的轮换，同时&lt;code&gt;Pilot Agent&lt;/code&gt;会监控&lt;code&gt;secret&lt;/code&gt;的变更，并重启Envoy使配置生效，完成证书的轮换。&lt;/p&gt;

&lt;h2 id=&#34;server&#34;&gt;Server&lt;/h2&gt;

&lt;p&gt;证书服务，与&lt;code&gt;nodeagent&lt;/code&gt;的&lt;code&gt;caclient&lt;/code&gt;交互，包括服务的认证及鉴权等&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;gRPC服务如下:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CertificateService

&lt;ul&gt;
&lt;li&gt;CreateCertificate(context.Context, *IstioCertificateRequest) (*IstioCertificateResponse, error)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;CAService&lt;code&gt;废弃&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;HandleCSR(context.Context, *CsrRequest) (*CsrResponse, error)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;authenticator&#34;&gt;Authenticator&lt;/h3&gt;

&lt;p&gt;gRPC服务认证，默认一个&lt;code&gt;ClientCertAuthenticator&lt;/code&gt;，当启动SDS时添加了&lt;code&gt;KubeJWTAuthenticator&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;authorizer&#34;&gt;Authorizer&lt;/h3&gt;

&lt;p&gt;gRPC服务&lt;code&gt;CAService&lt;/code&gt;和&lt;code&gt;CertificateService&lt;/code&gt;的鉴权&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;服务的&lt;code&gt;Authorizer&lt;/code&gt;都是&lt;code&gt;TODO&lt;/code&gt;状态&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;registry&lt;/strong&gt;提供了一个身份授权的注册表&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kube/ServiceController

&lt;ul&gt;
&lt;li&gt;监控&lt;code&gt;Service&lt;/code&gt;创建、删除与修改&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;kube/ServiceAccountController

&lt;ul&gt;
&lt;li&gt;监控&lt;code&gt;ServiceAccount&lt;/code&gt;创建、删除与修改
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;node-agent-k8s&#34;&gt;Node Agent K8S&lt;/h1&gt;

&lt;p&gt;NodeAgent(源码入口&lt;code&gt;istio/security/cmd/node_agent_k8s&lt;/code&gt;)是Citadel在工作负载&lt;code&gt;node&lt;/code&gt;或者网关&lt;code&gt;pod&lt;/code&gt;中的代理，为Envoy提供&lt;code&gt;SDS&lt;/code&gt;服务，并与Citadel交互发起&lt;code&gt;CSR&lt;/code&gt;请求。
使用&lt;strong&gt;Kubernetes中的代理节点&lt;/strong&gt;模式时Citadel可以运行为&lt;code&gt;server-only&lt;/code&gt;模式，即不做工作负载的证书管理。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;TODO 配图&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Node Agent源码均在&lt;code&gt;nodeagent&lt;/code&gt;目录&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;ca-client&#34;&gt;CA Client&lt;/h2&gt;

&lt;p&gt;提供CSR签名接口，服务实现支持&lt;code&gt;citadel&lt;/code&gt;、&lt;code&gt;google&lt;/code&gt;、&lt;code&gt;vault&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Client接口&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Client interface defines the clients need to implement to talk to CA for CSR.
type Client interface {
	CSRSign(ctx context.Context, csrPEM []byte, subjectID string,
		certValidTTLInSec int64) ([]string /*PEM-encoded certificate chain*/, error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;secret-fetcher&#34;&gt;Secret Fetcher&lt;/h2&gt;

&lt;p&gt;作为Workload代理时根据不同的Provider实例化CA Client，或者作为Ingress Gateway代理时监控&lt;code&gt;secret&lt;/code&gt;变更，并通知到&lt;code&gt;secretcache&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Workload代理以&lt;code&gt;DaemonSet&lt;/code&gt;在&lt;code&gt;node&lt;/code&gt;上运行，使用CA Client与CA Server交互&lt;/li&gt;
&lt;li&gt;Ingress Gateway代理与Workload部署方式不同，代理在Pod内运行，而不是&lt;code&gt;DaemonSet&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;监控&lt;code&gt;secret&lt;/code&gt;的创建、删除和更新，用于捕获Ingress Gateway的TLS配置&lt;/li&gt;
&lt;li&gt;&lt;code&gt;secret&lt;/code&gt;有变更时通过&lt;code&gt;AddCache&lt;/code&gt;、&lt;code&gt;DeleteCache&lt;/code&gt;和&lt;code&gt;UpdateCache&lt;/code&gt;方法通知&lt;code&gt;secretcache&lt;/code&gt;到&lt;code&gt;DeleteK8sSecret&lt;/code&gt;和&lt;code&gt;UpdateK8sSecret&lt;/code&gt;，再由&lt;code&gt;sds.NotifyProxy&lt;/code&gt;通知SDS服务&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preliminary.istio.io/zh/docs/tasks/traffic-management/ingress/secure-ingress-sds/#configure-a-TLS-ingress-gateway-using-sds&#34;&gt;使用SDS的优势&lt;/a&gt;[&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/ingress/secure-ingress-sds/#configure-a-tls-ingress-gateway-using-sds&#34;&gt;en&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Ingress Gateway的TLS的默认配置方式是&lt;a href=&#34;https://preliminary.istio.io/zh/docs/tasks/traffic-management/ingress/secure-ingress-mount/&#34;&gt;文件挂载&lt;/a&gt;[&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/ingress/secure-ingress-mount/&#34;&gt;en&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;secret-cache&#34;&gt;Secret Cache&lt;/h2&gt;

&lt;p&gt;秘钥缓存，负责秘钥的轮换&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;默认&lt;code&gt;10分钟&lt;/code&gt;做一次检查，对即将过期的做轮换，默认&lt;code&gt;1小时&lt;/code&gt;后过期的证书就做更新

&lt;ul&gt;
&lt;li&gt;如果轮询时&lt;code&gt;token&lt;/code&gt;过期会返回&lt;code&gt;secret=nil&lt;/code&gt;，这时SDS服务在收到&lt;code&gt;notify&lt;/code&gt;后需要将连接断开重连&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;产生轮换时通过&lt;code&gt;sds.NotifyProxy&lt;/code&gt;通知到SDS服务，SDS服务通过&lt;code&gt;connKey&lt;/code&gt;找到对应的&lt;code&gt;client&lt;/code&gt;，并通过SDS的&lt;code&gt;StreamSecrets&lt;/code&gt;将新的证书推送到&lt;code&gt;Pod&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;generateSecret&lt;/code&gt;时，如果检测到&lt;code&gt;rootCert&lt;/code&gt;为&lt;code&gt;nil&lt;/code&gt;或者与&lt;code&gt;certChainPEM&lt;/code&gt;的不一致，将触发&lt;code&gt;rootCert&lt;/code&gt;的更新

&lt;ul&gt;
&lt;li&gt;SDS服务将新的&lt;code&gt;rootCert&lt;/code&gt;加入到可信&lt;code&gt;CA&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;SecretManager接口&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// SecretManager defines secrets management interface which is used by SDS.
type SecretManager interface {
	// GenerateSecret generates new secret and cache the secret.
	GenerateSecret(ctx context.Context, connectionID, resourceName, token string) (*model.SecretItem, error)

	// ShouldWaitForIngressGatewaySecret indicates whether a valid ingress gateway secret is expected.
	ShouldWaitForIngressGatewaySecret(connectionID, resourceName, token string) bool

	// SecretExist checks if secret already existed.
	// This API is used for sds server to check if coming request is ack request.
	SecretExist(connectionID, resourceName, token, version string) bool

	// DeleteSecret deletes a secret by its key from cache.
	DeleteSecret(connectionID, resourceName string)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sds-service&#34;&gt;SDS Service&lt;/h2&gt;

&lt;p&gt;SDS服务实现&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NotifyProxy&lt;/code&gt;接收&lt;code&gt;secret&lt;/code&gt;变更的通知

&lt;ul&gt;
&lt;li&gt;查找&lt;code&gt;client&lt;/code&gt;的&lt;code&gt;connection&lt;/code&gt;，通过&lt;code&gt;pushChannel&lt;/code&gt;将&lt;code&gt;secret&lt;/code&gt;变更事件分发给SDS服务接口&lt;code&gt;StreamSecrets&lt;/code&gt;，然后推送到Envoy&lt;/li&gt;
&lt;li&gt;事件类型：

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Secret_TlsCertificate&lt;/code&gt;TLS证书&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Secret_ValidationContext&lt;/code&gt;可信CA&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;接收Envoy对SDS服务&lt;code&gt;StreamSecrets&lt;/code&gt;和&lt;code&gt;FetchSecrets&lt;/code&gt;请求，&lt;code&gt;SecretManager.GenerateSecret()&lt;/code&gt;生成秘钥&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;ref&#34;&gt;Ref&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59825498&#34;&gt;深度解析Istio系列之安全模块篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.fleeto.us/post/istio-security-notes/&#34;&gt;Istio 安全设置笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】微服务协作开发、灰度发布之流量染色</title>
      <link>http://hbchen.com/post/microservice/2019-11-30-go-micro-service-chain/</link>
      <pubDate>Sat, 30 Nov 2019 16:40:32 +0800</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-11-30-go-micro-service-chain/</guid>
      
        <description>&lt;p&gt;协作开发与灰度发布是微服务框架在流量治理能力方面的两个体现，本文结合&lt;strong&gt;go-micro&lt;/strong&gt;实践对流量进行染色，实现开发环境的多分支协作，
以及生产环境的灰度发布。&lt;/p&gt;

&lt;h1 id=&#34;场景&#34;&gt;场景&lt;/h1&gt;

&lt;h2 id=&#34;开发环境多服务-多分支协作&#34;&gt;开发环境多服务、多分支协作&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/micro/chain-dev.png&#34; alt=&#34;micro-chain-dev&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;QA&lt;/code&gt;组测试&lt;code&gt;v1.2&lt;/code&gt;和&lt;code&gt;v2.0&lt;/code&gt;链路

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;v2.0&lt;/code&gt; + &lt;code&gt;v1.2&lt;/code&gt;链路&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v1.1&lt;/code&gt;组仅关注&lt;code&gt;v1.1&lt;/code&gt;的版本开发

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;v1.1&lt;/code&gt; + &lt;code&gt;master&lt;/code&gt;链路&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v1.2&lt;/code&gt;组在&lt;code&gt;v1.1&lt;/code&gt;开发新版&lt;code&gt;srv-2&lt;/code&gt;服务

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;v1.2&lt;/code&gt; + &lt;code&gt;v1.1&lt;/code&gt; + &lt;code&gt;master&lt;/code&gt;链路&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v2.0&lt;/code&gt;组仅关注&lt;code&gt;v2.0&lt;/code&gt;的版本开发

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;v2.0&lt;/code&gt; + &lt;code&gt;master&lt;/code&gt;链路
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;生产环境灰度发布&#34;&gt;生产环境灰度发布&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/micro/chain-gray.png&#34; alt=&#34;micro-chain-gray&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;普通用户

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Pro&lt;/code&gt;链路&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;灰度测试用户

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Gray&lt;/code&gt; + &lt;code&gt;Pro&lt;/code&gt;链路&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;QA

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Pre&lt;/code&gt; + &lt;code&gt;Pro&lt;/code&gt;链路&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;流量染色&#34;&gt;流量染色&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;流量染色核心：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;gateway对请求进行染色

&lt;ul&gt;
&lt;li&gt;染色规则可以是&lt;code&gt;host&lt;/code&gt;、&lt;code&gt;header&lt;/code&gt;字段、&lt;code&gt;agent&lt;/code&gt;终端信息、用户筛选、流量比例等等&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;染色信息在服务间传递

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;go-micro&lt;/code&gt;中&lt;code&gt;http&lt;/code&gt;请求的&lt;code&gt;header&lt;/code&gt;以及&lt;code&gt;rpc&lt;/code&gt;请求的&lt;code&gt;metadata&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;服务调用时根据染色信息对服务进行筛选，实现调用链路的管控&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们基于&lt;code&gt;go-micro&lt;/code&gt;实践的是实现&lt;strong&gt;多链路染色&lt;/strong&gt;，染色链路带有优先级，如&lt;a href=&#34;#开发环境多服务-多分支协作&#34;&gt;开发环境多服务、多分支协作&lt;/a&gt;的&lt;code&gt;v1.2&lt;/code&gt;组，
虽然&lt;code&gt;v1.1&lt;/code&gt;和&lt;code&gt;v1.2&lt;/code&gt;都有&lt;code&gt;srv-2&lt;/code&gt;服务，但我们在染色信息中&lt;code&gt;v1.2&lt;/code&gt;在前优先选择，所以可以实现多分支同时染色(PS：如果两个分支中两个服务的优先级相反无法实现，需要设计更复杂的染色方案)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;网关染色及&lt;code&gt;client wrapper&lt;/code&gt;实现参考我实现的两个&lt;code&gt;chain&lt;/code&gt;插件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-plugins/tree/master/micro/chain&#34;&gt;hb-chen/micro-plugin/micro/chain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-plugins/tree/master/wrapper/select/chain&#34;&gt;hb-chen/micro-plugin/wrapper/select/chain&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;染色&#34;&gt;染色&lt;/h2&gt;

&lt;p&gt;在网关对流量进行&lt;strong&gt;染色&lt;/strong&gt;，基于&lt;code&gt;mciro&lt;/code&gt;的插件，可以方便的实现，具体染色规则需要根据自身需求实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;// 链路染色
api.Register(chain.New(chain.WithChainsFunc(func(r *http.Request) []string {
	return []string{&amp;quot;v2.0&amp;quot;, &amp;quot;v1.2&amp;quot;}
})))

web.Register(chain.New(chain.WithChainsFunc(func(r *http.Request) []string {
	return []string{&amp;quot;v2.0&amp;quot;}
})))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;调用链路管控&#34;&gt;调用链路管控&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;go-micro&lt;/code&gt;实现调用链路管控，最大的障碍就是&lt;strong&gt;网关&lt;/strong&gt;，&lt;code&gt;API&lt;/code&gt;及&lt;code&gt;Web&lt;/code&gt;均不支持服务筛选，需要自己二次开发，相关问题也反馈给社区看后续计划&lt;a href=&#34;https://github.com/micro/go-micro/issues/1003&#34;&gt;#1003&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;网关服务筛选-坑&#34;&gt;网关服务筛选-坑&lt;/h3&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;此方法仅用于测试，具体原因 vtolstov 在社区提的PR&lt;a href=&#34;https://github.com/micro/go-micro/pull/1388&#34;&gt;#1388&lt;/a&gt;有 asim 的反馈&lt;/li&gt;
&lt;li&gt;自定义 Router 实现网关对服务筛选的支持，实现参考我 fork 的分支版本 &lt;a href=&#34;https://github.com/hb-chen/micro/tree/gateway-2.4.0/gateway&#34;&gt;hb-chen/micro/gateway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;API网关&lt;/strong&gt;仅尝试了&lt;code&gt;api handler&lt;/code&gt;，修改相对简单，只需要增加&lt;code&gt;ClientWrapper&lt;/code&gt;，并去掉指定的负载策略即可。如果使用其他&lt;code&gt;handler&lt;/code&gt;需要逐个解决。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;1. &lt;code&gt;micro/main.go&lt;/code&gt;添加&lt;code&gt;ClientWrapper&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {
	cmd.Init(
		// 链路染色
		micro.WrapClient(chain.NewClientWrapper()),
	)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;2. &lt;code&gt;go-micro/api/handler/api.go&lt;/code&gt;去掉&lt;code&gt;strategy&lt;/code&gt;，&lt;code&gt;rpc handler&lt;/code&gt;类似&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// create strategy
// so := selector.WithStrategy(strategy(service.Services))

// if err := c.Call(cx, req, rsp, client.WithSelectOption(so)); err != nil {
if err := c.Call(cx, req, rsp); err != nil {
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Web网关&lt;/strong&gt;相对麻烦，不能方便的使用&lt;code&gt;micro&lt;/code&gt;的&lt;code&gt;options&lt;/code&gt;，暂时测试在&lt;code&gt;web&lt;/code&gt;模块实现&lt;code&gt;filter&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;1. &lt;code&gt;micro/web/web.go&lt;/code&gt;修改&lt;code&gt;func (s *srv) proxy() http.Handler&lt;/code&gt;，增加&lt;code&gt;SelectOption&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (s *srv) proxy() http.Handler {
	sel := s.service.Client().Options().Selector

	director := func(r *http.Request) {
		kill := func() {
			r.URL.Host = &amp;quot;&amp;quot;
			r.URL.Path = &amp;quot;&amp;quot;
			r.URL.Scheme = &amp;quot;&amp;quot;
			r.Host = &amp;quot;&amp;quot;
			r.RequestURI = &amp;quot;&amp;quot;
		}

		parts := strings.Split(r.URL.Path, &amp;quot;/&amp;quot;)
		if len(parts) &amp;lt; 2 {
			kill()
			return
		}
		if !re.MatchString(parts[1]) {
			kill()
			return
		}

		// NOTE: 添加SelectOption
		val := r.Header.Get(&amp;quot;X-Micro-Chain&amp;quot;)
		chains := strings.Split(val, &amp;quot;;&amp;quot;)

		next, err := sel.Select(Namespace+&amp;quot;.&amp;quot;+parts[1], selector.WithFilter(filterChain(chains)))
		if err != nil {
			kill()
			return
		}

		s, err := next()
		if err != nil {
			kill()
			return
		}

		r.Header.Set(BasePathHeader, &amp;quot;/&amp;quot;+parts[1])
		r.URL.Host = s.Address
		r.URL.Path = &amp;quot;/&amp;quot; + strings.Join(parts[2:], &amp;quot;/&amp;quot;)
		r.URL.Scheme = &amp;quot;http&amp;quot;
		r.Host = r.URL.Host
	}

	return &amp;amp;proxy{
		Default:  &amp;amp;httputil.ReverseProxy{Director: director},
		Director: director,
	}
}

// NOTE: SelectOption的filter实现
func filterChain(chains []string) selector.Filter {
	return func(old []*registry.Service) []*registry.Service {
		if len(chains) == 0 {
			return old
		}

		var services []*registry.Service

		chain := &amp;quot;&amp;quot;
		idx := 0
		for _, service := range old {
			serv := new(registry.Service)
			var nodes []*registry.Node

			for _, node := range service.Nodes {
				if node.Metadata == nil {
					continue
				}

				val := node.Metadata[&amp;quot;chain&amp;quot;]
				if len(val) == 0 {
					continue
				}

				if len(chain) &amp;gt; 0 &amp;amp;&amp;amp; idx == 0 {
					if chain == val {
						nodes = append(nodes, node)
					}
					continue
				}

				// chains按顺序优先匹配
				ok, i := inArray(val, chains)
				if ok &amp;amp;&amp;amp; idx &amp;gt; i {
					// 出现优先链路，services清空，nodes清空
					idx = i
					services = services[:0]
					nodes = nodes[:0]
				}

				if ok {
					chain = val
					nodes = append(nodes, node)
				}
			}

			// only add service if there&#39;s some nodes
			if len(nodes) &amp;gt; 0 {
				// copy
				*serv = *service
				serv.Nodes = nodes
				services = append(services, serv)
			}
		}

		if len(services) == 0 {
			return old
		}

		return services
	}
}

func inArray(s string, d []string) (bool, int) {
	for k, v := range d {
		if s == v {
			return true, k
		}
	}
	return false, 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;服务筛选&#34;&gt;服务筛选&lt;/h3&gt;

&lt;p&gt;普通服务的筛选框架支持没有什么问题，首先要为服务添加&lt;code&gt;metadata&lt;/code&gt;信息，不赘述。其次要对&lt;code&gt;Client&lt;/code&gt;进行包装，服务调用时添加&lt;code&gt;SelectOption&lt;/code&gt;，
实现参考我的&lt;a href=&#34;https://github.com/hb-go/micro-plugins/tree/master/wrapper/select/chain&#34;&gt;chain&lt;/a&gt;插件。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;1. 添加&lt;code&gt;metadata&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;md := make(map[string]string)
md[&amp;quot;chain&amp;quot;] = &amp;quot;v2.0&amp;quot;

// New Service
service := micro.NewService(
	micro.Name(&amp;quot;go.micro.api.xxx&amp;quot;),
	micro.Version(&amp;quot;latest&amp;quot;),
	micro.Metadata(md),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;2. Wrap Client&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;需要注意的是&lt;code&gt;service&lt;/code&gt;初始过程，有类似&lt;code&gt;micro new&lt;/code&gt;模板将service client注入到context的方法，需要分两次Init()，先WrapClient，再WrapHandler，
否则注入的&lt;code&gt;client&lt;/code&gt;将是未被包装的。这也是micro比较常遇到的&lt;strong&gt;坑&lt;/strong&gt;！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Initialise service
// NOTE: 注意有类似micro new模块将service client注入到context的方法，需要分两次Init()，否则注入的Client并未被包装
service.Init(
	micro.WrapClient(chain.NewClientWrapper()),
)
service.Init(
	// create wrap for the Example srv client
	micro.WrapHandler(client.AccountWrapper(service)),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;ref&#34;&gt;Ref&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/UBoRKt3l91ffPagtjExmYw&#34;&gt;大规模微服务场景下灰度发布与流量染色实践&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】Network mTLS &amp; 自签名证书</title>
      <link>http://hbchen.com/post/microservice/2019-11-27-go-micro-network-mtls/</link>
      <pubDate>Wed, 27 Nov 2019 20:39:14 +0800</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-11-27-go-micro-network-mtls/</guid>
      
        <description>&lt;p&gt;在&lt;a href=&#34;http://hbchen.com/post/microservice/2019-11-15-go-micro-network/&#34;&gt;【go-micro】Network初探&lt;/a&gt;我们分析了&lt;code&gt;network&lt;/code&gt;的应用场景以及存在的不足之处，
其中对于安全不足研究的不够深入，&lt;code&gt;tunnel&lt;/code&gt;是在&lt;code&gt;transport&lt;/code&gt;基础上建立的，而&lt;code&gt;transport&lt;/code&gt;层有&lt;code&gt;mTLS&lt;/code&gt;的支持，所以当时所说的在安全方面只有&lt;code&gt;header&lt;/code&gt;中的&lt;code&gt;token&lt;/code&gt;是错误的。
只是&lt;code&gt;micro&lt;/code&gt;当前在&lt;code&gt;network&lt;/code&gt;还没有做&lt;code&gt;mTLS&lt;/code&gt;环境变量的支持，本文将做一个简单的分享为&lt;code&gt;network&lt;/code&gt;增加&lt;code&gt;mTLS&lt;/code&gt;支持。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;刚刚(2019-11-27)&lt;code&gt;micro&lt;/code&gt;又发布了新版本&lt;code&gt;1.17.0&lt;/code&gt;，继续采坑🤣&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;network修改&#34;&gt;Network修改&lt;/h2&gt;

&lt;p&gt;当前&lt;code&gt;micro&lt;/code&gt;的&lt;code&gt;network&lt;/code&gt;模块并没有提供&lt;code&gt;TLS&lt;/code&gt;环境变量配置的支持，需要自己修改源码，在&lt;a href=&#34;https://github.com/micro/micro&#34;&gt;micro/micro&lt;/a&gt;的&lt;code&gt;internal/helper&lt;/code&gt;有&lt;code&gt;TLSConfig()&lt;/code&gt;方法可以从&lt;code&gt;GLOBAL OPTIONS&lt;/code&gt;中生成&lt;code&gt;*tls.Config&lt;/code&gt;，
参考当前&lt;code&gt;micro&lt;/code&gt;实现&lt;code&gt;mTLS&lt;/code&gt;两个&lt;code&gt;command&lt;/code&gt;(&lt;code&gt;api&lt;/code&gt;和&lt;code&gt;web&lt;/code&gt;)，对&lt;code&gt;network&lt;/code&gt;的&lt;code&gt;tunnel&lt;/code&gt;做如下修改:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// create a tunnel
tunOpts := []tunnel.Option{
	tunnel.Address(Address),
	tunnel.Nodes(nodes...),
	tunnel.Token(Token),
}
if ctx.GlobalBool(&amp;quot;enable_tls&amp;quot;) {
	config, err := helper.TLSConfig(ctx)
	if err != nil {
		fmt.Println(err.Error())
		return
	}
	config.InsecureSkipVerify = true

	tunOpts = append(tunOpts, tunnel.Transport(
		quic.NewTransport(transport.TLSConfig(config)),
	))
}
tun := tunnel.NewTunnel(tunOpts...)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意这里我们设置了&lt;code&gt;InsecureSkipVerify&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;，由于是双向认证，如果&lt;code&gt;InsecureSkipVerify&lt;/code&gt;为&lt;code&gt;false&lt;/code&gt;，&lt;code&gt;network&lt;/code&gt;将无法正常连接&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;mtls&#34;&gt;mTLS&lt;/h2&gt;

&lt;p&gt;首先参考下图对&lt;code&gt;mTLS&lt;/code&gt;有个了解，&lt;code&gt;server&lt;/code&gt;和&lt;code&gt;client&lt;/code&gt;都需要通过&lt;code&gt;CA&lt;/code&gt;对彼此的证书进行验证&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/micro/mtls.png&#34; alt=&#34;network_multi_cluster&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们只生成一个&lt;code&gt;CA&lt;/code&gt;和&lt;code&gt;CSR&lt;/code&gt;证书，对于生产环境根据自己的场景需要更为完善和复杂的证书管理，这里没有涉及，后面会结合&lt;code&gt;micro&lt;/code&gt;生态与安全相关的&lt;code&gt;mTLS&lt;/code&gt;做更多的研究分享。&lt;/p&gt;

&lt;h3 id=&#34;ca证书&#34;&gt;CA证书&lt;/h3&gt;

&lt;p&gt;使用&lt;a href=&#34;https://github.com/square/certstrap&#34;&gt;certstrap&lt;/a&gt;工具生成&lt;code&gt;CA&lt;/code&gt;证书&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# MacOS
$ brew install certstrap

# 未输入密码
$ certstrap init --common-name &amp;quot;MicroCA&amp;quot; --expires &amp;quot;20 years&amp;quot;
    Enter passphrase (empty for no passphrase): 
    Enter same passphrase again: 
    Created out/MicroCA.key
    Created out/MicroCA.crt
    Created out/MicroCA.crl
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;csr证书&#34;&gt;CSR证书&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ certstrap request-cert -cn network  
	Enter passphrase (empty for no passphrase): 
    Enter same passphrase again: 
    Created out/network.key
    Created out/network.csr
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;csr证书签名&#34;&gt;CSR证书签名&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ certstrap sign network --CA MicroCA
	Created out/network.crt from out/network.csr signed by out/MicroCA.key
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;运行network-mtls&#34;&gt;运行Network + mTLS&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./micro \
--registry=etcd \
--transport=tcp \
--enable_tls=true \
--tls_cert_file=conf/tls/network.crt  \
--tls_key_file=conf/tls/network.key  \
--tls_client_ca_file=conf/tls/MicroCA.crt \
network

$ ./micro \
--registry=consul \
--transport=tcp \
--enable_tls=true \
--tls_cert_file=conf/tls/network.crt  \
--tls_key_file=conf/tls/network.key  \
--tls_client_ca_file=conf/tls/MicroCA.crt \
network \
--nodes=localhost:8085 \
--address=:8086
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Network routes&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;如果&lt;code&gt;routes&lt;/code&gt;中看不到&lt;code&gt;link=network&lt;/code&gt;应该是&lt;code&gt;network&lt;/code&gt;间未能建立连接&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./micro --registry=etcd --transport=tcp network routes  
+------------------+----------------------+----------------------+--------------------------------------+----------+--------+---------+
|     SERVICE      |       ADDRESS        |       GATEWAY        |                ROUTER                | NETWORK  | METRIC |  LINK   |
+------------------+----------------------+----------------------+--------------------------------------+----------+--------+---------+
| consul           | 1919625842587659968  | 17017708900476934200 | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | network |
| go.micro.network | 15624894091238291400 | 17017708900476934200 | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | network |
| go.micro.network | 192.168.1.4:58527    |                      | df521f3c-a39e-455b-abbf-ada184a900c9 | go.micro | 1      | local   |
| go.micro.network | 192.168.1.4:58528    |                      | df521f3c-a39e-455b-abbf-ada184a900c9 | go.micro | 1      | local   |
| go.micro         | 192.168.1.4:8085     |                      | df521f3c-a39e-455b-abbf-ada184a900c9 | go.micro | 1      | local   |
| go.micro         | 9876822083478954444  | 17017708900476934200 | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | network |
+------------------+----------------------+----------------------+--------------------------------------+----------+--------+---------+

./micro --registry=consul --transport=tcp network routes
+------------------+----------------------+---------------------+--------------------------------------+----------+--------+---------+
|     SERVICE      |       ADDRESS        |       GATEWAY       |                ROUTER                | NETWORK  | METRIC |  LINK   |
+------------------+----------------------+---------------------+--------------------------------------+----------+--------+---------+
| consul           | 127.0.0.1:8300       |                     | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | local   |
| go.micro         | 192.168.1.4:8086     |                     | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | local   |
| go.micro         | 9480410441638176179  | 3307701226171868606 | df521f3c-a39e-455b-abbf-ada184a900c9 | go.micro | 2      | network |
| go.micro.network | 11801771601773192119 | 3307701226171868606 | df521f3c-a39e-455b-abbf-ada184a900c9 | go.micro | 2      | network |
| go.micro.network | 192.168.1.4:58843    |                     | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | local   |
| go.micro.network | 192.168.1.4:58844    |                     | f5dc3933-3ccc-4dc0-bafe-cbfd7abebf60 | go.micro | 1      | local   |
+------------------+----------------------+---------------------+--------------------------------------+----------+--------+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ref&#34;&gt;Ref&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.gitdig.com/about/&#34;&gt;Go 编程: 快速生成自签名证书与双向认证(mTLS)&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】Network初探</title>
      <link>http://hbchen.com/post/microservice/2019-11-15-go-micro-network/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-11-15-go-micro-network/</guid>
      
        <description>&lt;p&gt;Network是micro社区正在主力打造的解决多&amp;rdquo;云&amp;rdquo;环境的解决方案，下面结合最近的研究做个总结，主要包括&lt;code&gt;network&lt;/code&gt;适用的几种场景分析，
以及在这些场景需求下&lt;code&gt;network&lt;/code&gt;还有哪些不足。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://micro.mu/docs/network.html&#34;&gt;Network Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://micro.mu/docs/service-network.html&#34;&gt;Service Network&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;proxy&#34;&gt;Proxy&lt;/h2&gt;

&lt;p&gt;在分析&lt;code&gt;network&lt;/code&gt;之前先了解&lt;code&gt;micro&lt;/code&gt;的&lt;code&gt;proxy&lt;/code&gt;模式，服务之间调用不需要服务发现，而是通过&lt;code&gt;proxy&lt;/code&gt;做转发，由&lt;code&gt;proxy&lt;/code&gt;完成服务的发现和调用。
&lt;code&gt;network&lt;/code&gt;实现了一个特殊的代理，它的服务发现并不只是通过注册中心，同时有&lt;code&gt;network&lt;/code&gt;之间共享的服务。
&lt;img src=&#34;http://hbchen.com/img/micro/proxy.png&#34; alt=&#34;micro-proxy&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;服务可见性&#34;&gt;服务可见性&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;network&lt;/code&gt;通过共享服务信息，实现跨&lt;code&gt;network&lt;/code&gt;的服务可见，从而实现代理的服务发现，并且共享是有可见性的，当前&lt;code&gt;advertise_strategy&lt;/code&gt;有&lt;code&gt;3+1&lt;/code&gt;种方案:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;none&lt;/code&gt;不共享服务

&lt;ul&gt;
&lt;li&gt;即只接受外部服务，适合边缘节点，依赖中心服务场景&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;all&lt;/code&gt;共享全部服务&lt;/li&gt;
&lt;li&gt;&lt;code&gt;best&lt;/code&gt;共享最优路由

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;local&lt;/code&gt;仅共享集群内部服务，而不共享从其他&lt;code&gt;network&lt;/code&gt;共享得到的服务，实际是&lt;code&gt;best&lt;/code&gt;的一个筛选项，这也是为什么说它是&lt;code&gt;3+1&lt;/code&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;截止&lt;code&gt;v1.6.0&lt;/code&gt;版本还没有此功能，需要使用&lt;code&gt;master&lt;/code&gt;分支，&lt;a href=&#34;https://github.com/micro/go-micro/pull/932&#34;&gt;PR#932&lt;/a&gt;增加了此策略的支持，
以micro的发版速度应该要不了多久就会有Release版🤣&lt;/p&gt;

&lt;p&gt;Network在不断完善，本文参考版本为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/micro/micro/tree/98d9b1f332a2&#34;&gt;micro/tree/98d9b1f332a2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/micro/go-micro/tree/9f481542f38d&#34;&gt;go-micro/tree/9f481542f38d&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;应用场景&#34;&gt;应用场景&lt;/h2&gt;

&lt;h3 id=&#34;多集群&#34;&gt;多集群&lt;/h3&gt;

&lt;p&gt;多集群场景分两种一是&lt;strong&gt;集群服务共享&lt;/strong&gt;，二是&lt;strong&gt;多中心/主备集群&lt;/strong&gt;，在&lt;code&gt;advertise_strategy&lt;/code&gt;策略选择有区别。&lt;/p&gt;

&lt;h4 id=&#34;集群服务共享&#34;&gt;集群服务共享&lt;/h4&gt;

&lt;p&gt;集群服务共享是指不同集群拥有不同的服务，实现集群间的服务发现，选择的策略是&lt;code&gt;advertise_strategy=local&lt;/code&gt;，&lt;code&gt;network&lt;/code&gt;仅共享自身服务，
如果&lt;code&gt;DC B&lt;/code&gt;与&lt;code&gt;DC C&lt;/code&gt;需要共享服务，那么需要直接建立连接，而不是通过&lt;code&gt;DC A&lt;/code&gt;
&lt;img src=&#34;http://hbchen.com/img/micro/network_multi_cluster_1.png&#34; alt=&#34;network_multi_cluster&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;多中心-主备集群&#34;&gt;多中心/主备集群&lt;/h4&gt;

&lt;p&gt;多中心/主备集群是将同一套服务部署在多个中心，可能是多活，也可能是分主备，选择的策略是&lt;code&gt;advertise_strategy=best&lt;/code&gt;，但现在&lt;code&gt;network&lt;/code&gt;在负载策略上还没有&lt;strong&gt;就近原则&lt;/strong&gt;
&lt;img src=&#34;http://hbchen.com/img/micro/network_multi_cluster_2.png&#34; alt=&#34;network_multi_cluster&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;中心服务-边缘&#34;&gt;中心服务+边缘&lt;/h3&gt;

&lt;p&gt;对于边缘计算场景，边缘节点可能是不提供服务的，比如只上报数据，可以选择&lt;code&gt;advertise_strategy=none&lt;/code&gt;，当然有的可能又是提供服务的，可以选择&lt;code&gt;advertise_strategy=local&lt;/code&gt;，
但&lt;code&gt;DC A&lt;/code&gt;并不会将&lt;code&gt;DC C&lt;/code&gt;的服务共享给&lt;code&gt;DC B&lt;/code&gt;。因为&lt;code&gt;network&lt;/code&gt;间通过&lt;code&gt;tunnel&lt;/code&gt;通信，边缘节点可以是任意网络，只要连接到中心服务的&lt;code&gt;network&lt;/code&gt;即可。
&lt;img src=&#34;http://hbchen.com/img/micro/network_edge.png&#34; alt=&#34;network_edge&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;不足&#34;&gt;不足&lt;/h2&gt;

&lt;h3 id=&#34;network高可用及性能&#34;&gt;Network高可用及性能&lt;/h3&gt;

&lt;p&gt;要考虑&lt;code&gt;network&lt;/code&gt;的高可用，必须支持多副本水平扩展，现在同一集群内&lt;code&gt;network&lt;/code&gt;会共享服务，但当前&lt;code&gt;network&lt;/code&gt;的服务可见性并没有将集群内&lt;code&gt;node&lt;/code&gt;与直连的&lt;code&gt;node&lt;/code&gt;节点做区分，
如果集群内出现n个副本，那么最差的情况下可能要在&lt;code&gt;network&lt;/code&gt;的&lt;code&gt;pod&lt;/code&gt;间跳转n次。理想状态应该是对于集群内仅共享与&lt;code&gt;node&lt;/code&gt;直连的&lt;strong&gt;集群外服务&lt;/strong&gt;（这是当前&lt;code&gt;network&lt;/code&gt;不具备），
而对集群外共享本集群服务，这样可以确保集群内&lt;code&gt;network&lt;/code&gt;代理最多经过&lt;strong&gt;两跳&lt;/strong&gt;即可调用集群外服务。
&lt;img src=&#34;http://hbchen.com/img/micro/network_problem_ha.png&#34; alt=&#34;network_edge&#34; /&gt;
图中红色标记的&lt;code&gt;go.micro.srv.s-2 gateway-a-2&lt;/code&gt;、&lt;code&gt;go.micro.srv.s-2 gateway-a-3&lt;/code&gt;不应该出现在&lt;code&gt;network&lt;/code&gt;的&lt;code&gt;routes&lt;/code&gt;中，避免同一集群内没必要的路由。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;有关&lt;code&gt;network&lt;/code&gt;的多副本还需要进一步研究，比如4个后会不会出现链路循环，以及具体路由负载策略等&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;总的来说是&lt;code&gt;advertise_strategy&lt;/code&gt;需要更完善的策略支持，做必要的隔离、筛选，一是服务的可见性问题，二是服务规模增加后&lt;code&gt;network&lt;/code&gt;间的数据通信也会成为瓶颈。&lt;/p&gt;

&lt;h3 id=&#34;路由负载策略&#34;&gt;路由负载策略&lt;/h3&gt;

&lt;p&gt;路由负载选择需要优先级、筛选等策略，如local优先，这样我们可以实现主备集群，以及集群间流量切换等场景的应用&lt;/p&gt;

&lt;h3 id=&#34;安全&#34;&gt;安全&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;更正：这里我们忽略了&lt;code&gt;tunnel&lt;/code&gt;的&lt;code&gt;transport&lt;/code&gt;，在&lt;code&gt;transport&lt;/code&gt;层是有&lt;code&gt;mTLS&lt;/code&gt;支持的，具体参考&lt;a href=&#34;http://hbchen.com/post/microservice/2019-11-27-go-micro-tunnel-mtls/&#34;&gt;【go-micro】自签名证书&amp;amp;Tunnel mTLS&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;del&gt;&lt;code&gt;network&lt;/code&gt;间的连接是通过&lt;code&gt;tunnel&lt;/code&gt;完成，而&lt;code&gt;tunnel&lt;/code&gt;在安全方面只是在&lt;code&gt;message&lt;/code&gt;的&lt;code&gt;header&lt;/code&gt;中放了一个&lt;code&gt;token&lt;/code&gt;用于相互验证，这也是需要加强的部分。&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&#34;network模拟测试&#34;&gt;Network模拟测试&lt;/h2&gt;

&lt;p&gt;可以本地使用不同的注册中心模拟多个集群，简单的&lt;code&gt;mdns&lt;/code&gt;、&lt;code&gt;consul&lt;/code&gt;和&lt;code&gt;etcd&lt;/code&gt;就可以模拟出三个集群，如果有公网服务器当然更好。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】微服务快速开始</title>
      <link>http://hbchen.com/post/microservice/2019-10-13-go-micro-quick-start/</link>
      <pubDate>Sun, 13 Oct 2019 15:27:12 +0800</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-10-13-go-micro-quick-start/</guid>
      
        <description>&lt;p&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start&#34;&gt;github.com/hb-go/micro-quick-start&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这只是一个简易教程，是结合演示文稿&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/blob/master/micro-quick-start.pdf&#34;&gt;micro-quick-start.pdf&lt;/a&gt;的代码示例，
结合演示文稿可以快速了解微服务与&lt;code&gt;go-micro&lt;/code&gt;框架，并可以结合代码示例进行验证测试，文稿中有关于&lt;a href=&#34;#micro自定义&#34;&gt;&lt;code&gt;micro&lt;/code&gt;自定义&lt;/a&gt;以及&lt;code&gt;go-micro&lt;/code&gt;现成组件的使用这里并没有全部示范，
详细参考文稿，本教程每个示例均对应一个&lt;code&gt;commit&lt;/code&gt;，可以快速查看/比较示例相关代码，包含以下几个阶段：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/e76368bbee7dec646d13f1d9644b9d529e88074f&#34;&gt;服务创建&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;通过&lt;code&gt;micro new&lt;/code&gt;创建服务后进行完善，使模板创建的服务可以运行&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/5f7de50b10c19e19ef546144d6a11adf69ad1cfd&#34;&gt;自定义Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/ff70f21ba9d6a9bbf889598c0837e058706bf2fd&#34;&gt;自定义Transport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/615d4604e251bf1188fe12a0be22e05ca9c4ebf9&#34;&gt;服务筛选&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/703851f4364c541c436896f85badb836859c3b7e&#34;&gt;自定义Wrapper-监控&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/2f0baa1f5117d44809be07d6435fe36aeb1b9990&#34;&gt;超时&amp;amp;重试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/11453df1566721c1b8aa50d253e3454986aa2c4f&#34;&gt;限流&amp;amp;熔断&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/8573ae85a7bd70038c0e0a18900bfa76d4cddb6c&#34;&gt;配置-consul&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/d3f79f6c427822c1646ee7ccb2a4ba68c81681fd&#34;&gt;链路追踪&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hb-go/micro-quick-start/commit/8979073c7f473635e84d0300b61a749b66bc3bd1&#34;&gt;k8s部署&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;micro自定义&#34;&gt;micro自定义&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;micro&lt;/code&gt;做为网关往往需要自定义，&lt;code&gt;micro&lt;/code&gt;提供了&lt;code&gt;plugin&lt;/code&gt;的自定义，以下是部分参考，如增加组件&lt;code&gt;tcp&lt;/code&gt;、&lt;code&gt;kubernetes&lt;/code&gt;，使用&lt;code&gt;go-plugins&lt;/code&gt;中已有的&lt;code&gt;micro/metrics&lt;/code&gt;插件，
以及完全自定义一个&lt;code&gt;metrics&lt;/code&gt;插件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;github.com/micro/go-micro/util/log&amp;quot;
	&amp;quot;github.com/micro/go-plugins/micro/metrics&amp;quot;
	&amp;quot;github.com/micro/micro/api&amp;quot;
	&amp;quot;github.com/micro/micro/plugin&amp;quot;
	&amp;quot;github.com/micro/micro/web&amp;quot;
	&amp;quot;github.com/prometheus/client_golang/prometheus&amp;quot;
	&amp;quot;github.com/prometheus/client_golang/prometheus/promhttp&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;strconv&amp;quot;

	// tcp transport
	_ &amp;quot;github.com/micro/go-plugins/transport/tcp&amp;quot;

	// k8s registry
	_ &amp;quot;github.com/micro/go-plugins/registry/kubernetes&amp;quot;
)

// Metrics
func init() {
	api.Register(metrics.NewPlugin())
	web.Register(metrics.NewPlugin())
}

// 自定义Metrics
func init() {
	api.Register(plugin.NewPlugin(
		plugin.WithHandler(
			func(h http.Handler) http.Handler {
				return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
					r.Header.Get(&amp;quot;&amp;quot;)
				})
			}),
	))

	api.Register(plugin.NewPlugin(
		plugin.WithHandler(
			func(h http.Handler) http.Handler {
				md := make(map[string]string)

				opsCounter := prometheus.NewCounterVec(
					prometheus.CounterOpts{
						Namespace: &amp;quot;micro&amp;quot;,
						Name:      &amp;quot;request_total&amp;quot;,
						Help:      &amp;quot;How many go-micro requests processed, partitioned by method and status&amp;quot;,
					},
					[]string{&amp;quot;path&amp;quot;, &amp;quot;method&amp;quot;, &amp;quot;code&amp;quot;},
				)

				timeCounterSummary := prometheus.NewSummaryVec(
					prometheus.SummaryOpts{
						Namespace: &amp;quot;micro&amp;quot;,
						Name:      &amp;quot;upstream_latency_microseconds&amp;quot;,
						Help:      &amp;quot;Service backend method request latencies in microseconds&amp;quot;,
					},
					[]string{&amp;quot;path&amp;quot;, &amp;quot;method&amp;quot;},
				)

				timeCounterHistogram := prometheus.NewHistogramVec(
					prometheus.HistogramOpts{
						Namespace: &amp;quot;micro&amp;quot;,
						Name:      &amp;quot;request_duration_seconds&amp;quot;,
						Help:      &amp;quot;Service method request time in seconds&amp;quot;,
					},
					[]string{&amp;quot;path&amp;quot;, &amp;quot;method&amp;quot;},
				)

				reg := prometheus.NewRegistry()
				wrapreg := prometheus.WrapRegistererWith(md, reg)
				wrapreg.MustRegister(
					opsCounter,
					timeCounterSummary,
					timeCounterHistogram,
				)

				prometheus.DefaultGatherer = reg
				prometheus.DefaultRegisterer = wrapreg

				return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
					// 拦截metrics path，默认&amp;quot;/metrics&amp;quot;
					if r.URL.Path == &amp;quot;/metrics&amp;quot; {
						promhttp.Handler().ServeHTTP(w, r)
						return
					}

					path := r.URL.Path
					method := r.Method
					timer := prometheus.NewTimer(prometheus.ObserverFunc(func(v float64) {
						us := v * 1000000 // make microseconds
						timeCounterSummary.WithLabelValues(path, method).Observe(us)
						timeCounterHistogram.WithLabelValues(path, method).Observe(v)
					}))
					defer timer.ObserveDuration()

					ww := wrapWriter{ResponseWriter: w}
					h.ServeHTTP(&amp;amp;ww, r)
					log.Logf(&amp;quot;statusCode: %d, %s&amp;quot;, ww.StatusCode, strconv.Itoa(ww.StatusCode))
					opsCounter.WithLabelValues(path, method, strconv.Itoa(ww.StatusCode)).Inc()
				})
			}),
	))

}

type wrapWriter struct {
	StatusCode int
	http.ResponseWriter
}

func (ww *wrapWriter) WriteHeader(statusCode int) {
	log.Logf(&amp;quot;statusCode: %d&amp;quot;, statusCode)
	ww.StatusCode = statusCode
	ww.ResponseWriter.WriteHeader(statusCode)
}
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【服务网格-gRPC】网关grpc-gateway</title>
      <link>http://hbchen.com/post/servicemesh/2019-08-30-mesh-grpc-01/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-08-30-mesh-grpc-01/</guid>
      
        <description>&lt;p&gt;在网格中使用&lt;code&gt;gRPC&lt;/code&gt;可以方便的定义服务，而当需要对外提供服务时往往&lt;code&gt;HTTP&lt;/code&gt;接口比较普遍，&lt;code&gt;grpc-gateway&lt;/code&gt;提供了&lt;code&gt;RESTful JSON API&lt;/code&gt;转&lt;code&gt;gRPC&lt;/code&gt;的代理服务。
在&lt;code&gt;mesh&lt;/code&gt;中&lt;code&gt;grpc-gateway&lt;/code&gt;的角色更像一个&lt;strong&gt;服务聚合层&lt;/strong&gt;，将内部&lt;code&gt;gRPC&lt;/code&gt;服务聚合并提供&lt;code&gt;HTTP&lt;/code&gt;接口服务，在使用的过程中也遇到些问题，如：进程内路由、Header映射等，这里结合使用经验做个总结。&lt;/p&gt;

&lt;h1 id=&#34;接口定义&#34;&gt;接口定义&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;gRPC&lt;/code&gt;的服务定义这里不做过多关联介绍，&lt;code&gt;grpc-gateway&lt;/code&gt;协议支持两种方式添加，一是在&lt;code&gt;.proto&lt;/code&gt;的服务定义中以&lt;code&gt;option&lt;/code&gt;的方式直接绑定；
二是使用单独的&lt;code&gt;.yaml&lt;/code&gt;文件定义。接口定义遵循&lt;a href=&#34;https://cloud.google.com/service-infrastructure/docs/service-management/reference/rpc/google.api#http&#34;&gt;google.api&lt;/a&gt;大家可以参考，
主要内容在&lt;code&gt;HttpRule&lt;/code&gt;，具体字段参考协议&lt;a href=&#34;https://github.com/googleapis/googleapis/blob/master/google/api/http.proto&#34;&gt;http.proto&lt;/a&gt;更清晰，
比如:&lt;code&gt;response_body&lt;/code&gt;在文档中并没有提到，用于选择&lt;code&gt;Response&lt;/code&gt;结构的某一字段作为响应内容。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;grpc-gateway&lt;/code&gt;文档参考

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grpc-ecosystem.github.io/grpc-gateway/docs/usage.html&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://grpc-ecosystem.github.io/grpc-gateway/docs/grpcapiconfiguration.html&#34;&gt;Usage without annotations (gRPC API Configuration)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package example;

import &amp;quot;google/api/annotations.proto&amp;quot;;

message StringMessage {
    string value = 1;
}

service YourService {
    rpc Echo (StringMessage) returns (StringMessage) {
       option (google.api.http) = {
           post: &amp;quot;/v1/example/echo&amp;quot;
           body: &amp;quot;*&amp;quot;
       };
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;type: google.api.Service
config_version: 3

http:
  rules:
  - selector: example.YourService.Echo
    post: /v1/example/echo
    body: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;进程内路由&#34;&gt;进程内路由&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/grpc/grpc-gateway.png&#34; alt=&#34;grpc-gateway&#34; /&gt;
&lt;code&gt;grpc-gateway&lt;/code&gt;的代理方式是&lt;code&gt;gRPC&lt;/code&gt;远程调用，在&lt;code&gt;mesh&lt;/code&gt;中有已经有&lt;code&gt;ingress&lt;/code&gt;网关，如果继续用&lt;code&gt;rpc&lt;/code&gt;调用，
将在链路上又增加一层网络开销&lt;code&gt;ingress -&amp;gt; grpc-gatewap -&amp;gt; grpc server&lt;/code&gt;，而我们的主要目的是将&lt;code&gt;gRPC&lt;/code&gt;服务映射成&lt;code&gt;HTTP&lt;/code&gt;并不需要其它能力，
所以我们期望&lt;code&gt;grpc-gateway&lt;/code&gt;能够进程将&lt;code&gt;HTTP&lt;/code&gt;请求转发给&lt;code&gt;gRPC&lt;/code&gt;服务。&lt;/p&gt;

&lt;p&gt;针对这一需求需要&lt;code&gt;gRPC&lt;/code&gt;服务支持进程内调用，社区现有的方案是&lt;a href=&#34;https://github.com/grpc/grpc-go/tree/master/test/bufconn&#34;&gt;test/bufconn&lt;/a&gt;，
示例参考&lt;a href=&#34;https://github.com/grpc-ecosystem/grpc-gateway/pull/947#issuecomment-502578553&#34;&gt;grpc-gateway/pull/947&lt;/a&gt;中的讨论。
至于直接&lt;strong&gt;进程内调&lt;/strong&gt;&lt;code&gt;Contributor&lt;/code&gt;的最新回复是8月份启动&lt;a href=&#34;https://github.com/grpc/grpc-go/issues/906#issuecomment-513856927&#34;&gt;grpc-go/issues/906&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;另一个临时的方案是我提交到&lt;code&gt;grpc-gateway&lt;/code&gt;的&lt;code&gt;PR&lt;/code&gt; &lt;a href=&#34;https://github.com/grpc-ecosystem/grpc-gateway/pull/947&#34;&gt;pull/947&lt;/a&gt;，已经&lt;code&gt;merge&lt;/code&gt;到&lt;code&gt;master&lt;/code&gt;，
但此方案仅支持&lt;code&gt;Unary&lt;/code&gt;，不支持&lt;code&gt;Streaming&lt;/code&gt;，不过对于网关应该能够满足大部分场景的需求。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func RegisterXXXHandlerServer(ctx context.Context, mux *runtime.ServeMux, server XXXServer) error
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;header传递&#34;&gt;Header传递&lt;/h1&gt;

&lt;p&gt;在&lt;code&gt;tracing&lt;/code&gt;等场景我们往往需要将&lt;code&gt;Header&lt;/code&gt;信息在服务之间传递，包括&lt;code&gt;RESTful API&lt;/code&gt;请求。首先&lt;code&gt;grpc-gateway&lt;/code&gt;的&lt;code&gt;NewServeMux()&lt;/code&gt;需要&lt;code&gt;runtime.WithMetadata()&lt;/code&gt;Option，
筛选&lt;code&gt;HTTP Header&lt;/code&gt;映射为&lt;code&gt;metadata&lt;/code&gt;；其次如果是使用&lt;a href=&#34;https://github.com/grpc/grpc-go/tree/master/test/bufconn&#34;&gt;test/bufconn&lt;/a&gt;方案，
在&lt;code&gt;RegisterXXXHandlerFromEndpoint(...,opts []grpc.DialOption)&lt;/code&gt; &lt;code&gt;opts&lt;/code&gt;的&lt;code&gt;grpc.WithChainUnaryInterceptor()&lt;/code&gt;中需要增加&lt;code&gt;metadata&lt;/code&gt;的映射。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;grpc-gateway&lt;/code&gt;的另一个方式是&lt;code&gt;runtime.WithIncomingHeaderMatcher()&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了方便使用可以参考我的&lt;code&gt;metadata&lt;/code&gt;插件&lt;a href=&#34;https://github.com/hb-go/grpc-contrib/tree/master/metadata&#34;&gt;github.com/hb-go/grpc-contrib/metadata&lt;/a&gt;，
支持指定&lt;strong&gt;Header&lt;/strong&gt;和&lt;strong&gt;前缀匹配&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hb-go/grpc-contrib/metadata&lt;/code&gt;示例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;mux := runtime.NewServeMux(
    runtime.WithMetadata(metadata.GatewayMetadataAnnotator(
        metadata.WithHeader(&amp;quot;x-request-id&amp;quot;),
        metadata.WithPrefix(&amp;quot;x-prefix&amp;quot;),
    )),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;err := pb.RegisterXXXHandlerFromEndpoint(ctx, mux, &amp;quot;&amp;quot;,
    []grpc.DialOption{
        grpc.WithChainUnaryInterceptor(
            metadata.UnaryClientInterceptor(
                metadata.WithHeader(&amp;quot;x-request-id&amp;quot;),
                metadata.WithPrefix(&amp;quot;x-prefix&amp;quot;),
            ),
        ),
    },
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Istio&lt;/code&gt;环境要完整&lt;code&gt;tracing&lt;/code&gt;链路，&lt;code&gt;ClientConn&lt;/code&gt;需要与&lt;code&gt;grpc-gateway&lt;/code&gt;一样，在&lt;code&gt;DialOption&lt;/code&gt;的&lt;code&gt;grpc.WithChainUnaryInterceptor()&lt;/code&gt;中加入&lt;code&gt;metadata.UnaryClientInterceptor(...)&lt;/code&gt;，
&lt;code&gt;Header&lt;/code&gt;说明参考&lt;code&gt;Istio&lt;/code&gt;文档&lt;a href=&#34;https://istio.io/faq/distributed-tracing/#how-to-support-tracing&#34;&gt;WHAT IS REQUIRED FOR DISTRIBUTED TRACING WITH ISTIO?&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;metadata.WithHeader(&amp;quot;x-request-id&amp;quot;),
metadata.WithHeader(&amp;quot;x-b3-traceid&amp;quot;),
metadata.WithHeader(&amp;quot;x-b3-spanid&amp;quot;),
metadata.WithHeader(&amp;quot;x-b3-parentspanid&amp;quot;),
metadata.WithHeader(&amp;quot;x-b3-sampled&amp;quot;),
metadata.WithHeader(&amp;quot;x-b3-flags&amp;quot;),
metadata.WithHeader(&amp;quot;b3&amp;quot;),
metadata.WithHeader(&amp;quot;x-ot-span-context&amp;quot;),
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;TODO&lt;/p&gt;

&lt;h1 id=&#34;参数映射&#34;&gt;参数映射&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;body&lt;/li&gt;
&lt;li&gt;path&lt;/li&gt;
&lt;li&gt;queue&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】使用kubernetes注册中心</title>
      <link>http://hbchen.com/post/microservice/2019-06-27-go-micro-use-kubernetes-registry/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-06-27-go-micro-use-kubernetes-registry/</guid>
      
        <description>&lt;p&gt;&lt;code&gt;go-micro&lt;/code&gt;部署到&lt;code&gt;kubernetes&lt;/code&gt;环境，可以选择&lt;code&gt;kubernetes&lt;/code&gt;注册中心插件，减少组件依赖简化运维。&lt;/p&gt;

&lt;h1 id=&#34;主要工作&#34;&gt;主要工作&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;部署示例&lt;a href=&#34;https://github.com/hb-go/micro/tree/master/k8s&#34;&gt;hb-go/micro&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;micro&lt;/code&gt;选择自己编译，而不是直接&lt;code&gt;go get -u github.com/micro/micro&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自定义选择插件的支持&lt;/li&gt;
&lt;li&gt;自己发布镜像，官方&lt;code&gt;microhq/micro&lt;/code&gt;上的镜像没有版本，容易出现兼容问题&lt;/li&gt;
&lt;li&gt;另外非常重要的一点&lt;strong&gt;保证本地与线上&lt;code&gt;micro&lt;/code&gt;的一致&lt;/strong&gt;，只需要替换注册中心&lt;code&gt;--registry=kubernetes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;go build&lt;/code&gt;打包服务时增加&lt;code&gt;kubernetes&lt;/code&gt;插件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
	_ &amp;quot;github.com/micro/go-plugins/registry/kubernetes&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;rbac问题&#34;&gt;RBAC问题&lt;/h1&gt;

&lt;p&gt;如果&lt;code&gt;kubernetes&lt;/code&gt;开启了&lt;code&gt;RBAC&lt;/code&gt;，在部署服务时需要配置&lt;code&gt;RBAC&lt;/code&gt;，包括&lt;code&gt;micro web&lt;/code&gt;、&lt;code&gt;micro api&lt;/code&gt;服务，否则服务注册/发现将失败&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2019/06/27 12:54:13 K8s: request failed with code 403
2019/06/27 12:54:13 K8s: request failed with body:
2019/06/27 12:54:13 {&amp;quot;kind&amp;quot;:&amp;quot;Status&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;metadata&amp;quot;:{},&amp;quot;status&amp;quot;:&amp;quot;Failure&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;pods \&amp;quot;micro-web-79545546b4-p5vbt\&amp;quot; is forbidden: User \&amp;quot;system:serviceaccount:default:default\&amp;quot; cannot patch resource \&amp;quot;pods\&amp;quot; in API group \&amp;quot;\&amp;quot; in the namespace \&amp;quot;default\&amp;quot;&amp;quot;,&amp;quot;reason&amp;quot;:&amp;quot;Forbidden&amp;quot;,&amp;quot;details&amp;quot;:{&amp;quot;name&amp;quot;:&amp;quot;micro-web-79545546b4-p5vbt&amp;quot;,&amp;quot;kind&amp;quot;:&amp;quot;pods&amp;quot;},&amp;quot;code&amp;quot;:403}
2019/06/27 12:54:13 Server register error: K8s: error
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rbac-yaml&#34;&gt;RBAC yaml&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: ServiceAccount
metadata:
  name: micro-services
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: micro-registry
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - pods
  verbs:
  - list
  - patch
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: micro-registry
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: micro-registry
subjects:
- kind: ServiceAccount
  name: micro-services
  namespace: default
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;服务指定service-account&#34;&gt;服务指定Service Account&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  namespace: default
  name: micro-api
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: micro-api
    spec:
+     serviceAccountName: micro-services
      containers:
      - name: api
        command: [
          &amp;quot;/micro&amp;quot;,
          &amp;quot;--registry=kubernetes&amp;quot;,
          &amp;quot;--server=rpc&amp;quot;,
          &amp;quot;--broker=http&amp;quot;,
          &amp;quot;--transport=http&amp;quot;,
          &amp;quot;--register_ttl=60&amp;quot;,
          &amp;quot;--register_interval=30&amp;quot;,
          &amp;quot;--selector=cache&amp;quot;,
          &amp;quot;--enable_stats&amp;quot;,
          &amp;quot;api&amp;quot;
        ]
        image: hbchen/micro:k8s
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          name: api-port
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【go-micro】服务间通信插件Benchmark</title>
      <link>http://hbchen.com/post/microservice/2019-05-31-go-micro-benchmark/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/microservice/2019-05-31-go-micro-benchmark/</guid>
      
        <description>&lt;p&gt;测试影响&lt;code&gt;go-micro&lt;/code&gt;服务间通信效率的三个组件：&lt;code&gt;transport&lt;/code&gt;、&lt;code&gt;server&lt;/code&gt;以及&lt;code&gt;codec&lt;/code&gt;，主要做不同插件间的横向对比。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;源码&lt;a href=&#34;https://github.com/hb-go/micro/tree/master/benchmark&#34;&gt;github.com/hb-go/micro/benchmark&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;测试环境&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MBP&lt;/li&gt;
&lt;li&gt;go &lt;strong&gt;1.12.5&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;go-micro &lt;strong&gt;v1.2.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;go-plugins &lt;strong&gt;v1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;transport-server对比&#34;&gt;Transport + Server对比&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;transport&lt;/code&gt;和&lt;code&gt;server&lt;/code&gt;的对比使用&lt;code&gt;100&lt;/code&gt;并发，完成&lt;code&gt;10W&lt;/code&gt;请求进行测试&lt;/p&gt;

&lt;h3 id=&#34;结果对比&#34;&gt;结果对比&lt;/h3&gt;

&lt;p&gt;从结果看&lt;code&gt;tcp&lt;/code&gt;+&lt;code&gt;rpc&lt;/code&gt;吞吐量最高，分别比较：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transport&lt;/code&gt;比较结果&lt;code&gt;tcp&lt;/code&gt;&amp;gt;&lt;code&gt;grpc&lt;/code&gt;&amp;gt;&lt;code&gt;utp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;server&lt;/code&gt;比较结果大致为&lt;code&gt;rpc&lt;/code&gt;&amp;gt;&lt;code&gt;grpc&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;T+S&lt;/th&gt;
&lt;th&gt;平均&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;中位&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最大&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最小&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P90&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P99&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;TPS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tcp+rpc&lt;/td&gt;
&lt;td&gt;7.236&lt;/td&gt;
&lt;td&gt;5.629&lt;/td&gt;
&lt;td&gt;101.506&lt;/td&gt;
&lt;td&gt;0.177&lt;/td&gt;
&lt;td&gt;13.338&lt;/td&gt;
&lt;td&gt;35.880&lt;/td&gt;
&lt;td&gt;13192&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;grpc+rpc&lt;/td&gt;
&lt;td&gt;8.668&lt;/td&gt;
&lt;td&gt;7.964&lt;/td&gt;
&lt;td&gt;101.280&lt;/td&gt;
&lt;td&gt;0.251&lt;/td&gt;
&lt;td&gt;12.744&lt;/td&gt;
&lt;td&gt;21.672&lt;/td&gt;
&lt;td&gt;11166&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;utp+rpc&lt;/td&gt;
&lt;td&gt;11.824&lt;/td&gt;
&lt;td&gt;11.600&lt;/td&gt;
&lt;td&gt;53.183&lt;/td&gt;
&lt;td&gt;0.204&lt;/td&gt;
&lt;td&gt;15.575&lt;/td&gt;
&lt;td&gt;21.334&lt;/td&gt;
&lt;td&gt;8252&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;grpc+grpc&lt;/td&gt;
&lt;td&gt;8.924&lt;/td&gt;
&lt;td&gt;8.181&lt;/td&gt;
&lt;td&gt;134.434&lt;/td&gt;
&lt;td&gt;0.286&lt;/td&gt;
&lt;td&gt;13.211&lt;/td&gt;
&lt;td&gt;22.973&lt;/td&gt;
&lt;td&gt;10845&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;在开始的测试中有个误区，&lt;code&gt;grpc&lt;/code&gt;服务并不使用&lt;code&gt;transport&lt;/code&gt;，包括&lt;code&gt;http&lt;/code&gt;服务，&lt;code&gt;transport&lt;/code&gt;仅在使用&lt;code&gt;go-micro&lt;/code&gt;的&lt;code&gt;rpc&lt;/code&gt;服务时有效&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;codec对比&#34;&gt;Codec对比&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;transport&lt;/code&gt;和&lt;code&gt;server&lt;/code&gt;分别使用&lt;code&gt;tcp&lt;/code&gt;和&lt;code&gt;rpc&lt;/code&gt;对比不同&lt;code&gt;codec&lt;/code&gt;性能，因为并发&lt;code&gt;100&lt;/code&gt;时不同&lt;code&gt;codec&lt;/code&gt;的失败率差别比较大，所以使用&lt;code&gt;50&lt;/code&gt;并发，完成&lt;code&gt;10W&lt;/code&gt;请求进行测试&lt;/p&gt;

&lt;h3 id=&#34;结果对比-1&#34;&gt;结果对比&lt;/h3&gt;

&lt;p&gt;对比结果：&lt;code&gt;protobuf&lt;/code&gt;&amp;gt;&lt;code&gt;proto-rpc&lt;/code&gt;&amp;gt;&lt;code&gt;grpc&lt;/code&gt;&amp;gt;&lt;code&gt;json&lt;/code&gt;&amp;gt;&lt;code&gt;grpc+json&lt;/code&gt;&amp;gt;&lt;code&gt;json-rpc&lt;/code&gt;&amp;gt;&lt;code&gt;bsonrpc&lt;/code&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CODEC&lt;/th&gt;
&lt;th&gt;平均&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;中位&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最大&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;最小&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P90&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;P99&lt;br/&gt;(ms)&lt;/th&gt;
&lt;th&gt;TPS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;grpc&lt;/td&gt;
&lt;td&gt;3.937&lt;/td&gt;
&lt;td&gt;2.979&lt;/td&gt;
&lt;td&gt;90.004&lt;/td&gt;
&lt;td&gt;0.180&lt;/td&gt;
&lt;td&gt;7.184&lt;/td&gt;
&lt;td&gt;19.355&lt;/td&gt;
&lt;td&gt;12310&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;grpc+json&lt;/td&gt;
&lt;td&gt;6.085&lt;/td&gt;
&lt;td&gt;4.694&lt;/td&gt;
&lt;td&gt;149.861&lt;/td&gt;
&lt;td&gt;0.342&lt;/td&gt;
&lt;td&gt;10.365&lt;/td&gt;
&lt;td&gt;31.837&lt;/td&gt;
&lt;td&gt;8000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;protobuf&lt;/td&gt;
&lt;td&gt;3.661&lt;/td&gt;
&lt;td&gt;2.707&lt;/td&gt;
&lt;td&gt;96.636&lt;/td&gt;
&lt;td&gt;0.156&lt;/td&gt;
&lt;td&gt;6.542&lt;/td&gt;
&lt;td&gt;20.261&lt;/td&gt;
&lt;td&gt;13150&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;json&lt;/td&gt;
&lt;td&gt;5.402&lt;/td&gt;
&lt;td&gt;4.122&lt;/td&gt;
&lt;td&gt;122.360&lt;/td&gt;
&lt;td&gt;0.225&lt;/td&gt;
&lt;td&gt;9.186&lt;/td&gt;
&lt;td&gt;30.474&lt;/td&gt;
&lt;td&gt;8896&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;json-rpc&lt;/td&gt;
&lt;td&gt;6.380&lt;/td&gt;
&lt;td&gt;4.878&lt;/td&gt;
&lt;td&gt;115.141&lt;/td&gt;
&lt;td&gt;0.288&lt;/td&gt;
&lt;td&gt;11.150&lt;/td&gt;
&lt;td&gt;33.395&lt;/td&gt;
&lt;td&gt;7631&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;proto-rpc&lt;/td&gt;
&lt;td&gt;3.692&lt;/td&gt;
&lt;td&gt;2.729&lt;/td&gt;
&lt;td&gt;101.010&lt;/td&gt;
&lt;td&gt;0.180&lt;/td&gt;
&lt;td&gt;6.701&lt;/td&gt;
&lt;td&gt;19.454&lt;/td&gt;
&lt;td&gt;13041&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bsonrpc&lt;/td&gt;
&lt;td&gt;7.912&lt;/td&gt;
&lt;td&gt;5.979&lt;/td&gt;
&lt;td&gt;132.041&lt;/td&gt;
&lt;td&gt;0.354&lt;/td&gt;
&lt;td&gt;14.789&lt;/td&gt;
&lt;td&gt;40.414&lt;/td&gt;
&lt;td&gt;6145&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;默认&lt;code&gt;chdec&lt;/code&gt;如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;DefaultCodecs = map[string]codec.NewCodec{
    &amp;quot;application/grpc&amp;quot;:         grpc.NewCodec,
    &amp;quot;application/grpc+json&amp;quot;:    grpc.NewCodec,
    &amp;quot;application/grpc+proto&amp;quot;:   grpc.NewCodec,
    &amp;quot;application/json&amp;quot;:         json.NewCodec,
    &amp;quot;application/json-rpc&amp;quot;:     jsonrpc.NewCodec,
    &amp;quot;application/protobuf&amp;quot;:     proto.NewCodec,
    &amp;quot;application/proto-rpc&amp;quot;:    protorpc.NewCodec,
    &amp;quot;application/octet-stream&amp;quot;: raw.NewCodec,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外&lt;code&gt;go-plugins&lt;/code&gt;提供三个&lt;code&gt;codec&lt;/code&gt;插件，在&lt;code&gt;server&lt;/code&gt;和&lt;code&gt;client&lt;/code&gt;初始化时自定义添加&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;server.Codec(&amp;quot;application/msgpackrpc&amp;quot;, msgpackrpc.NewCodec),
server.Codec(&amp;quot;application/bsonrpc&amp;quot;, bsonrpc.NewCodec),
server.Codec(&amp;quot;application/jsonrpc2&amp;quot;, jsonrpc2.NewCodec),

client.Codec(&amp;quot;application/msgpackrpc&amp;quot;, msgpackrpc.NewCodec),
client.Codec(&amp;quot;application/bsonrpc&amp;quot;, bsonrpc.NewCodec),
client.Codec(&amp;quot;application/jsonrpc2&amp;quot;, jsonrpc2.NewCodec),
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际测试时由于不同原因&lt;code&gt;raw&lt;/code&gt; 、&lt;code&gt;msgpackrpc&lt;/code&gt;和&lt;code&gt;jsonrpc2&lt;/code&gt;运行失败未测试，&lt;code&gt;grpc+proto&lt;/code&gt;与&lt;code&gt;grpc&lt;/code&gt;实现一致未测试&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;raw.NewCodec&lt;br/&gt;error:{&amp;ldquo;id&amp;rdquo;:&amp;ldquo;go.micro.client.codec&amp;rdquo;,&amp;ldquo;code&amp;rdquo;:500,&amp;ldquo;detail&amp;rdquo;:&amp;ldquo;failed to write: field1:……&lt;br/&gt;
 msgpackrpc.NewCodec，需要实现EncodeMsg(*Writer)&lt;br/&gt;error:{&amp;ldquo;id&amp;rdquo;:&amp;ldquo;go.micro.client.codec&amp;rdquo;,&amp;ldquo;code&amp;rdquo;:500,&amp;ldquo;detail&amp;rdquo;:&amp;ldquo;Not encodable&amp;rdquo;,&amp;ldquo;status&amp;rdquo;:&amp;ldquo;Internal Server Error&amp;rdquo;}&lt;br/&gt;
 jsonrpc2.NewCodec&lt;br/&gt;error:{&amp;ldquo;id&amp;rdquo;:&amp;ldquo;go.micro.client.transport&amp;rdquo;,&amp;ldquo;code&amp;rdquo;:500,&amp;ldquo;detail&amp;rdquo;:&amp;ldquo;EOF&amp;rdquo;,&amp;ldquo;status&amp;rdquo;:&amp;ldquo;Internal Server Error&amp;rdquo;}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;详细数据&#34;&gt;详细数据&lt;/h2&gt;

&lt;h3 id=&#34;transport-server&#34;&gt;Transport + Server&lt;/h3&gt;

&lt;h4 id=&#34;测试命令&#34;&gt;测试命令&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go run server.go
$ go run client.go -c 100 -n 100000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;tcp + rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 7580
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99999
throughput (TPS)       : 13192

concurrency mean      median    max         min       p90        p99        TPS
100         7235584ns 5629000ns 101506000ns 177000ns  13338000ns 35880000ns 13192
100         7.236ms   5.629ms   101.506ms   0.177ms   13.338ms   35.880ms   13192

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc + rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 8955
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99999
throughput (TPS)       : 11166

concurrency mean      median    max         min       p90        p99        TPS
100         8668191ns 7964000ns 101280000ns 251000ns  12744000ns 21672000ns 11166
100         8.668ms   7.964ms   101.280ms   0.251ms   12.744ms   21.672ms   11166
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;utp + rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 12117
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 100000
throughput (TPS)       : 8252

concurrency mean       median     max        min       p90        p99        TPS
100         11823520ns 11600000ns 53183000ns 204000ns  15575000ns 21334000ns 8252
100         11.824ms   11.600ms   53.183ms   0.204ms   15.575ms   21.334ms   8252
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc + gRPC&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 9220
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99995
throughput (TPS)       : 10845

concurrency mean      median    max         min       p90        p99        TPS
100         8924043ns 8181000ns 134434000ns 286000ns  13211000ns 22973000ns 10845
100         8.924ms   8.181ms   134.434ms   0.286ms   13.211ms   22.973ms   10845
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;codec&#34;&gt;Codec&lt;/h3&gt;

&lt;h4 id=&#34;测试命令-1&#34;&gt;测试命令&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd benchmark/tcp_rpc
$ go run server.go
$ go run client.go -c 50 -n 100000 -ct grpc
$ go run client.go -c 50 -n 100000 -ct grpc+json
$ go run client.go -c 50 -n 100000 -ct protobuf
$ go run client.go -c 50 -n 100000 -ct json
$ go run client.go -c 50 -n 100000 -ct json-rpc
$ go run client.go -c 50 -n 100000 -ct proto-rpc
$ go run client.go -c 50 -n 100000 -ct bsonrpc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 8123
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 100000
throughput (TPS)       : 12310

concurrency mean      median    max        min       p90       p99        TPS
50          3936652ns 2979000ns 90004000ns 180000ns  7184000ns 19355000ns 12310
50          3.937ms   2.979ms   90.004ms   0.180ms   7.184ms   19.355ms   12310
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;grpc+json&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 12500
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99961
throughput (TPS)       : 8000

concurrency mean      median    max         min       p90        p99        TPS
50          6084709ns 4694000ns 149861000ns 342000ns  10365000ns 31837000ns 8000
50          6.085ms   4.694ms   149.861ms   0.342ms   10.365ms   31.837ms   8000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;protobuf&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 7604
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 100000
throughput (TPS)       : 13150

concurrency mean      median    max        min       p90       p99        TPS
50          3660854ns 2707000ns 96636000ns 156000ns  6542000ns 20261000ns 13150
50          3.661ms   2.707ms   96.636ms   0.156ms   6.542ms   20.261ms   13150
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;json&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 11241
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99922
throughput (TPS)       : 8896

concurrency mean      median    max         min       p90       p99        TPS
50          5401532ns 4121500ns 122360000ns 225000ns  9186000ns 30474000ns 8896
50          5.402ms   4.122ms   122.360ms   0.225ms   9.186ms   30.474ms   8896
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;json-rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 13103
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99971
throughput (TPS)       : 7631

concurrency mean      median    max         min       p90        p99        TPS
50          6380308ns 4878000ns 115141000ns 288000ns  11150000ns 33395000ns 7631
50          6.380ms   4.878ms   115.141ms   0.288ms   11.150ms   33.395ms   7631
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;proto-rpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 7668
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99998
throughput (TPS)       : 13041

concurrency mean      median    max         min       p90       p99        TPS
50          3692281ns 2729000ns 101010000ns 180000ns  6701000ns 19454000ns 13041
50          3.692ms   2.729ms   101.010ms   0.180ms   6.701ms   19.454ms   13041
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;bsonrpc&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;took       (ms)        : 16272
sent       requests    : 100000
received   requests    : 100000
received   requests_OK : 99933
throughput (TPS)       : 6145

concurrency mean      median    max         min       p90        p99        TPS
50          7911887ns 5979000ns 132041000ns 354000ns  14789000ns 40414000ns 6145
50          7.912ms   5.979ms   132.041ms   0.354ms   14.789ms   40.414ms   6145
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio安全】网格边缘-Ingress</title>
      <link>http://hbchen.com/post/servicemesh/2019-05-11-istio-security-ingress/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-05-11-istio-security-ingress/</guid>
      
        <description>&lt;p&gt;接&lt;a href=&#34;(/post/servicemesh/2019-04-11-istio-security-egress/)&#34;&gt;【Istio安全】网格边缘-Egress&lt;/a&gt;继续网格边缘的实践&lt;code&gt;ingress-gateway&lt;/code&gt;，
分为&lt;strong&gt;HTTP&lt;/strong&gt;、&lt;strong&gt;HTTPS-不终止TLS&lt;/strong&gt;和&lt;strong&gt;HTTPS-种子TLS&lt;/strong&gt;三种场景。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;有了&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-04-11-istio-security-egress/&#34;&gt;Egress&lt;/a&gt;的实践，这里不使用&lt;code&gt;httpbin&lt;/code&gt;做内部服务，而是用&lt;code&gt;egress-gateway&lt;/code&gt;的成果，
&lt;code&gt;www.aliyun.com&lt;/code&gt;和&lt;code&gt;hbchen.com&lt;/code&gt;的两个外部服务进行测试。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http
    protocol: HTTP
  resolution: NONE
EOF

$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: originate-tls-for-aliyun
spec:
  host: www.aliyun.com
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - name: originate-tls
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
        portLevelSettings:
        - port:
            number: 443
          tls:
            mode: SIMPLE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;环境变量&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;http2&amp;quot;)].nodePort}&#39;)
export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#39;{.spec.ports[?(@.name==&amp;quot;https&amp;quot;)].nodePort}&#39;)

export INGRESS_HOST=$(minikube ip)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;接下来进入正文&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;都只需要定义两个&lt;code&gt;.yaml&lt;/code&gt;配置:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gateway&lt;/strong&gt;:&lt;code&gt;ingress-example-gateway&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VirtualService&lt;/strong&gt;:&lt;code&gt;ingress-example-svc&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;http-gateway&#34;&gt;Http Gateway&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/ingress-http.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方文档&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/ingress/&#34;&gt;控制 Ingress 流量&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ingress-example-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - &amp;quot;hbchen.com&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ingress-example-svc
spec:
  hosts:
  - &amp;quot;hbchen.com&amp;quot;
  gateways:
  - ingress-example-gateway
  http:
  - match:
    - port: 80
    route:
    - destination:
        host: hbchen.com
        port:
          number: 80
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -I -v -HHost:hbchen.com http://$INGRESS_HOST:$INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;https-gateway-不终止-tls&#34;&gt;Https Gateway-不终止&lt;code&gt;TLS&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/ingress-https-passthrough.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方文档&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/ingress-sni-passthrough/&#34;&gt;没有 TLS 的 Ingress gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不终止&lt;code&gt;TLS&lt;/code&gt;即透传&lt;code&gt;https&lt;/code&gt;请求到网格内服务，这里我们使用一个外部服务来模拟一个支持&lt;code&gt;https&lt;/code&gt;的服务&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ingress-example-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: http
    hosts:
    - &amp;quot;www.aliyun.com&amp;quot;
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: PASSTHROUGH
    hosts:
    - &amp;quot;www.aliyun.com&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ingress-example-svc
spec:
  hosts:
  - &amp;quot;www.aliyun.com&amp;quot;
  gateways:
  - ingress-example-gateway
  http:
  - match:
    - port: 80
    route:
    - destination:
        host: www.aliyun.com
        subset: originate-tls
        port:
          number: 443
  tls:
  - match:
    - port: 443
      sni_hosts:
      - www.aliyun.com
    route:
    - destination:
        host: www.aliyun.com
        port:
          number: 443
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -I -v -HHost:www.aliyun.com http://$INGRESS_HOST:$INGRESS_PORT
curl -I -v --resolve www.aliyun.com:$SECURE_INGRESS_PORT:$INGRESS_HOST https://www.aliyun.com:$SECURE_INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;https-gateway-终止-tls&#34;&gt;Https Gateway-终止&lt;code&gt;TLS&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/ingress-https.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方文档&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/secure-ingress/sds/&#34;&gt;使用 SDS 为 Gateway 提供 HTTPS 加密支持&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;终止&lt;code&gt;TLS&lt;/code&gt;即由&lt;code&gt;ingress-gateway&lt;/code&gt;提供&lt;code&gt;https&lt;/code&gt;服务，更符合&lt;code&gt;ingress-gateway&lt;/code&gt;作为网格统一入口的需求&lt;/p&gt;

&lt;h3 id=&#34;启用sds&#34;&gt;启用SDS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;SDS&lt;/code&gt;默认是关闭的，所以首先需要开启&lt;code&gt;ingress-gateway&lt;/code&gt;的&lt;code&gt;SDS&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd istio/path 

# 生成.yaml
$ helm template install/kubernetes/helm/istio/ --name istio \
--namespace istio-system -x charts/gateways/templates/deployment.yaml \
--set gateways.istio-egressgateway.enabled=false \
--set gateways.istio-ingressgateway.sds.enabled=true &amp;gt; \
$HOME/istio-ingressgateway.yaml

# 重新部署
$ kubectl apply -f $HOME/istio-ingressgateway.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;生成证书&#34;&gt;生成证书&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/nicholasjackson/mtls-go-example

$ cd mtls-go-example
$ ./generate.sh hbchen.com 123456

$ mkdir ./../hbchen.com &amp;amp;&amp;amp; mv 1_root 2_intermediate 3_application 4_client ./../hbchen.com
$ cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建-secret&#34;&gt;创建&lt;code&gt;Secret&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl create -n istio-system secret generic hbchen-credential \
--from-file=key=hbchen.com/3_application/private/hbchen.com.key.pem \
--from-file=cert=hbchen.com/3_application/certs/hbchen.com.cert.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: ingress-example-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: &amp;quot;hbchen-credential&amp;quot; # NOTE: 和 Secret 名称一致
    hosts:
    - &amp;quot;hbchen.com&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ingress-example-svc
spec:
  hosts:
  - &amp;quot;hbchen.com&amp;quot;
  gateways:
  - ingress-example-gateway
  http:
  - match:
    - port: 443
    route:
    - destination:
        host: hbchen.com
        port:
          number: 80
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -I -v -HHost:hbchen.com \
--resolve hbchen.com:$SECURE_INGRESS_PORT:$INGRESS_HOST \
--cacert hbchen.com/2_intermediate/certs/ca-chain.cert.pem \
https://hbchen.com:$SECURE_INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;todo&#34;&gt;TODO&lt;/h2&gt;

&lt;h3 id=&#34;jwt&#34;&gt;JWT&lt;/h3&gt;

&lt;h3 id=&#34;authn&#34;&gt;Authn&lt;/h3&gt;</description>
      
    </item>
    
    <item>
      <title>分布式系统限流服务-Golang&amp;Redis</title>
      <link>http://hbchen.com/post/distributed/2019-05-05-rate-limit/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/distributed/2019-05-05-rate-limit/</guid>
      
        <description>&lt;p&gt;本文参考两个使用Redis做限流的项目，分析分布式系统限流服务的实现，包括固定窗口以及滚动窗口的限流。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考项目&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Istio项目&lt;code&gt;mixer&lt;/code&gt;模块的&lt;a href=&#34;https://github.com/istio/istio/tree/master/mixer/adapter/redisquota&#34;&gt;adapter/redisquota&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/go-redis/redis_rate&#34;&gt;go-redis/redis_rate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;固定窗口&#34;&gt;固定窗口&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/distributed/rate-window-fixed.png&#34; alt=&#34;fixed-window&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;go-redis-redis-rate&#34;&gt;go-redis/redis_rate&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;redis_rate&lt;/code&gt;使用&lt;strong&gt;窗口标识&lt;/strong&gt;做&lt;code&gt;key&lt;/code&gt;的字符串，用&lt;code&gt;INCRBY&lt;/code&gt;统计窗口已使用流量&lt;code&gt;n&lt;/code&gt;，且&lt;code&gt;key&lt;/code&gt;在此窗口结束后自动过期。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;窗口标识&lt;/strong&gt;的生成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;slot&lt;/code&gt; = &lt;code&gt;utime&lt;/code&gt;(&lt;em&gt;时间戳&lt;code&gt;s&lt;/code&gt;&lt;/em&gt;)➗&lt;code&gt;udur&lt;/code&gt;(&lt;em&gt;窗口大小&lt;code&gt;s&lt;/code&gt;，&lt;code&gt;dur ≥ 1s&lt;/code&gt;&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;key&lt;/code&gt; = &lt;code&gt;name&lt;/code&gt; + &lt;code&gt;slot&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;utime&lt;/code&gt;与系统时钟相关，考虑一种较为极端的情况，窗口大小&lt;code&gt;1s&lt;/code&gt;，&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;两个系统时钟差&lt;code&gt;2s&lt;/code&gt;，而&lt;code&gt;key&lt;/code&gt;的过期时间与窗口大小相同&lt;code&gt;1s&lt;/code&gt;，
假设&lt;code&gt;key&lt;/code&gt;在窗口最后有更新则&lt;code&gt;key&lt;/code&gt;的生存周期是&lt;code&gt;2s&lt;/code&gt;，而恰好时钟相差&lt;code&gt;2s&lt;/code&gt;，这样&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;系统的分布式限流就变成了单机限流。&lt;br/&gt;
虽然比较极端，但在使用时还是需要注意，根据需要可以适当加大&lt;code&gt;key&lt;/code&gt;的过期时间，同时存活多个窗口，使存活窗口范围覆盖系统间的时钟误差。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (l *Limiter) AllowN(
	name string, maxn int64, dur time.Duration, n int64,
) (count int64, delay time.Duration, allow bool) {
	udur := int64(dur / time.Second)
	utime := time.Now().Unix()
	slot := utime / udur
	delay = time.Duration((slot+1)*udur-utime) * time.Second

	if l.Fallback != nil {
		allow = l.Fallback.Allow()
	}

	name = allowName(name, slot)
	count, err := l.incr(name, dur, n)
	if err == nil {
		allow = count &amp;lt;= maxn
	}

	return count, delay, allow
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;adapter-redisquota-fixed-window&#34;&gt;adapter/redisquota/fixed_window&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;redisquota&lt;/strong&gt;使用&lt;code&gt;lua&lt;/code&gt;脚本实现，设计上使用一个带有&lt;code&gt;token&lt;/code&gt;和&lt;code&gt;expire&lt;/code&gt;的哈希表，&lt;code&gt;key&lt;/code&gt;过期时间为&lt;code&gt;windowLength&lt;/code&gt;，窗口在&lt;code&gt;key&lt;/code&gt;过期或&lt;code&gt;timestamp&lt;/code&gt;≥&lt;code&gt;expire&lt;/code&gt;时重置。
另外&lt;code&gt;redisquota&lt;/code&gt;根据场景做了&lt;strong&gt;幂等&lt;/strong&gt;设计，同一&lt;code&gt;deduplicationid&lt;/code&gt;在窗口有效期内不会重新分配&lt;code&gt;token&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;因为&lt;code&gt;timestamp&lt;/code&gt;与系统时钟相关，同样假设&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;两个系统时钟差&lt;code&gt;2s&lt;/code&gt;(&lt;code&gt;A&lt;/code&gt;&amp;gt;&lt;code&gt;B&lt;/code&gt;)，窗口大小&lt;code&gt;10s&lt;/code&gt;，如果窗口①由&lt;code&gt;A&lt;/code&gt;系统时间戳触发，而窗口②由&lt;code&gt;B&lt;/code&gt;系统时间戳触发(&lt;code&gt;A&lt;/code&gt;在后&lt;code&gt;2s&lt;/code&gt;没有流量)，
这样①实际窗口大小就是&lt;code&gt;12s&lt;/code&gt;，这样继续到窗口③由&lt;code&gt;A&lt;/code&gt;系统时间戳触发，②的实际窗口代销就是&lt;code&gt;8s&lt;/code&gt;，所以在分布式环境下限流效果同样受系统时钟误差的影响。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;local key_meta = KEYS[1]
-- local key_data = KEYS[2]

local credit = tonumber(ARGV[1])
local windowLength = tonumber(ARGV[2])
-- local bucketLength = tonumber(ARGV[3])
local bestEffort = tonumber(ARGV[4])
local token = tonumber(ARGV[5])
local timestamp = tonumber(ARGV[6])
local deduplicationid = ARGV[7]

-- lookup previous response for the deduplicationid and returns if it is still valid
--------------------------------------------------------------------------------
if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
    local previous_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;))
    local previous_expire = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;expire&amp;quot;))

    if previous_token and previous_expire then
        if timestamp &amp;lt; previous_expire then
            return {previous_token, previous_expire - timestamp}
        end
    end
end

-- read or initialize meta information
--------------------------------------------------------------------------------
local info_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;token&amp;quot;))
local info_expire = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;expire&amp;quot;))

if (not info_token or not info_expire) or (timestamp &amp;gt;= info_expire) then
    info_token = 0
    info_expire = windowLength + timestamp

    redis.call(&amp;quot;HMSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, info_token, &amp;quot;expire&amp;quot;, windowLength + timestamp)
    -- set the expiration time for automatic cleanup
    redis.call(&amp;quot;PEXPIRE&amp;quot;, key_meta, windowLength / 1000000)
end

if info_token + token &amp;gt; credit then
    if bestEffort == 1 then
        local exceeded = info_token + token - credit

        if exceeded &amp;lt; token then
            -- return maximum available allocated token
            redis.call(&amp;quot;HMSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, credit)

            -- save current request and set expiration time for auto cleanup
            if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
                redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, token - exceeded, &amp;quot;expire&amp;quot;, info_expire)
                redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, math.floor((info_expire - timestamp) / 1000000))
            end

            return {token - exceeded, info_expire - timestamp}
        else
            -- not enough available credit
            return {0, 0}
        end
    else
        -- not enough available credit
        return {0, 0}
    end
else
    -- allocated token
    redis.call(&amp;quot;HMSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, info_token + token)

    -- save current request and set expiration time for auto cleanup
    if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
        redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, token, &amp;quot;expire&amp;quot;, info_expire)
        redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, math.floor((info_expire - timestamp) / 1000000))
    end

    return {token, info_expire - timestamp}
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;lua脚本获取时间戳&#34;&gt;Lua脚本获取时间戳&lt;/h3&gt;

&lt;p&gt;既然在分布式环境系统时钟有可能存在误差，那自然考虑将时间戳转到Redis中获取，消除时钟误差对窗口的影响，这里有一个限制条件是需要Lua脚本支持&lt;strong&gt;随机写入&lt;/strong&gt;，
有关Redis Lua脚本&lt;strong&gt;随机写入&lt;/strong&gt;请参考此文《&lt;a href=&#34;https://yq.aliyun.com/articles/195914&#34;&gt;redis4.0之Lua脚本新姿势&lt;/a&gt;》，结合这个特性可以将两个方案的时间戳由外部传入改为在Lua脚本中获取Redis系统时间，
我在&lt;a href=&#34;https://github.com/hb-go/pkg/tree/master/rate&#34;&gt;hb-go/pkg/rate&lt;/a&gt;包分别使用&lt;code&gt;SET&lt;/code&gt;、&lt;code&gt;HSET&lt;/code&gt;做了实现可以参考。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;-- Redis version ≥ 3.2
redis.replicate_commands()
local now = redis.call(&#39;TIME&#39;)
timestamp = (tonumber(now[1]) * 1e6 + tonumber(now[2])) * 1e3
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;滚动窗口&#34;&gt;滚动窗口&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/distributed/rate-window-rolling.png&#34; alt=&#34;rolling-window&#34; /&gt;&lt;/p&gt;

&lt;p&gt;滚动窗口在固定窗口基础上，将一个&lt;code&gt;window&lt;/code&gt;拆成多个&lt;code&gt;bucket&lt;/code&gt;，这样窗口根据&lt;code&gt;bucket&lt;/code&gt;的大小向前移动。Redis的结构为哈希表：&lt;code&gt;token&lt;/code&gt;、&lt;code&gt;bucket.token&lt;/code&gt;、&lt;code&gt;bucket.timestamp&lt;/code&gt;和&lt;code&gt;key&lt;/code&gt;，
以及一个存储&lt;code&gt;bucket&lt;/code&gt;历史数据的有序集合(&lt;em&gt;以&lt;code&gt;bucket&lt;/code&gt;的时间戳排序&lt;/em&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;token&lt;/code&gt;:窗口内已使用&lt;code&gt;token&lt;/code&gt;数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bucket.token&lt;/code&gt;:当前桶内已使用&lt;code&gt;token&lt;/code&gt;数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bucket.timestamp&lt;/code&gt;:当前桶的时间戳&lt;/li&gt;
&lt;li&gt;&lt;code&gt;key&lt;/code&gt;:累计&lt;code&gt;bucket&lt;/code&gt;数量&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;local key_meta = KEYS[1]
local key_data = KEYS[2]

local credit = tonumber(ARGV[1])
local windowLength = tonumber(ARGV[2])
local bucketLength = tonumber(ARGV[3])
local bestEffort = tonumber(ARGV[4])
local token = tonumber(ARGV[5])
local timestamp = tonumber(ARGV[6])
local deduplicationid = ARGV[7]

-- lookup previous response for the deduplicationid and returns if it is still valid
--------------------------------------------------------------------------------
if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
    local previous_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;))
    local previous_expire = tonumber(redis.call(&amp;quot;HGET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;expire&amp;quot;))

    if previous_token and previous_expire then
        if timestamp &amp;lt; previous_expire then
            return {previous_token, previous_expire - timestamp}
        end
    end
end

-- read meta information
--------------------------------------------------------------------------------
local info_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;token&amp;quot;))
local info_bucket_token = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;bucket.token&amp;quot;))
local info_bucket_timestamp = tonumber(redis.call(&amp;quot;HGET&amp;quot;, key_meta, &amp;quot;bucket.timestamp&amp;quot;))

-- initialize meta
--------------------------------------------------------------------------------
if not info_token or not info_bucket_token or not info_bucket_timestamp then
    info_token = 0
    info_bucket_token = 0
    info_bucket_timestamp = timestamp

    redis.call(&amp;quot;HMSET&amp;quot;, key_meta,
        &amp;quot;token&amp;quot;, info_token,
        &amp;quot;bucket.token&amp;quot;, info_bucket_token,
        &amp;quot;bucket.timestamp&amp;quot;, info_bucket_timestamp,
        &amp;quot;key&amp;quot;, 0)
end


-- move buffer to bucket list if bucket timer is older than bucket window
--------------------------------------------------------------------------------
if (timestamp - info_bucket_timestamp + 1) &amp;gt; bucketLength then
    if tonumber(info_bucket_token) &amp;gt; 0 then
        local nextKey = redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;key&amp;quot;, 1)
        local value = tostring(nextKey) .. &amp;quot;.&amp;quot; .. tostring(info_bucket_token)
        redis.call(&amp;quot;ZADD&amp;quot;, key_data, info_bucket_timestamp, value);
    end
    redis.call(&amp;quot;HMSET&amp;quot;, key_meta,
        &amp;quot;bucket.token&amp;quot;, 0,
        &amp;quot;bucket.timestamp&amp;quot;, timestamp)
end

local time_to_expire = timestamp - windowLength

-- reclaim tokens from expired records
--------------------------------------------------------------------------------
local reclaimed = 0
local expired = redis.call(&amp;quot;ZRANGEBYSCORE&amp;quot;, key_data, 0, time_to_expire)

for idx, value in ipairs(expired) do
    reclaimed = reclaimed + tonumber(string.sub(value, string.find(value, &amp;quot;%.&amp;quot;)+1))
end

-- remove expired records
--------------------------------------------------------------------------------
redis.call(&amp;quot;ZREMRANGEBYSCORE&amp;quot;, key_data, 0, time_to_expire)

-- update consumed token
--------------------------------------------------------------------------------
if reclaimed &amp;gt; 0 then
    info_token = info_token - reclaimed;
    if info_token &amp;lt; 0 then
        info_token = 0
    end
    redis.call(&amp;quot;HSET&amp;quot;, key_meta, &amp;quot;token&amp;quot;, info_token)
end

-- update the expiration time for automatic cleanup
--------------------------------------------------------------------------------
redis.call(&amp;quot;PEXPIRE&amp;quot;, key_meta, windowLength / 1000000)
redis.call(&amp;quot;PEXPIRE&amp;quot;, key_meta, windowLength / 1000000)

-- calculate available token
--------------------------------------------------------------------------------
local available_token = credit - info_token

-- check available token and requested token
--------------------------------------------------------------------------------

if available_token &amp;lt;= 0 then
    -- credit exhausted
    return {0, 0}
elseif available_token &amp;gt;= token then
    -- increase token and bucket.token by token
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;token&amp;quot;, token)
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;bucket.token&amp;quot;, token)

    -- save current request and set expiration time for auto cleanup
    if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
        redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, token, &amp;quot;expire&amp;quot;, timestamp + windowLength)
        redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, windowLength / 1000000)
    end

    return {token,  windowLength}
else

    if bestEffort == 0 then
        -- not enough token
        return {0, 0}
    end

    -- allocate available token only
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;token&amp;quot;, available_token)
    redis.call(&amp;quot;HINCRBY&amp;quot;, key_meta, &amp;quot;bucket.token&amp;quot;, available_token)

    -- save current request and set expiration time for auto cleanup
    if (deduplicationid or &#39;&#39;) ~= &#39;&#39; then
        redis.call(&amp;quot;HMSET&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, &amp;quot;token&amp;quot;, available_token, &amp;quot;expire&amp;quot;, timestamp + windowLength)
        redis.call(&amp;quot;PEXPIRE&amp;quot;, deduplicationid .. &amp;quot;-&amp;quot; .. key_meta, windowLength / 1000000)
    end

    return {available_token, windowLength}
end
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;限流的窗口与Flink的&lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/stream/operators/windows.html#tumbling-windows&#34;&gt;Window&lt;/a&gt;类似，
对于固定窗口结合使用场景的需求，可以借鉴Flink的&lt;strong&gt;Tumbling Window&lt;/strong&gt;接口设计提供&lt;code&gt;offset&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;</description>
      
    </item>
    
    <item>
      <title>【Flink实践】实时消费阿里云SLS日志&#43;输出到ES</title>
      <link>http://hbchen.com/post/flink/2019-04-29-sls&#43;es/</link>
      <pubDate>Mon, 29 Apr 2019 18:42:22 +0800</pubDate>
      
      <guid>http://hbchen.com/post/flink/2019-04-29-sls&#43;es/</guid>
      
        <description>&lt;p&gt;本文介绍Flink在流计算场景的简单应用，实时消费SLS内的AccessLog，并将计算结果输出到Elasticsearch。&lt;/p&gt;

&lt;h2 id=&#34;环境&#34;&gt;环境&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Flink

&lt;ul&gt;
&lt;li&gt;1.8&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ES

&lt;ul&gt;
&lt;li&gt;6.3.2&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;假设场景&#34;&gt;假设场景&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;日志结构&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;request_time: 1556415329
uri: /analysis/path?id=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;系统AccessLog通过Logtai采集到阿里云SLS，指定&lt;code&gt;request_time&lt;/code&gt;为日志时间字段。示例场景需求统计指定&lt;code&gt;uri.path&lt;/code&gt;+&lt;code&gt;uri.query.id&lt;/code&gt;分组统计访问计数。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实时消费&lt;code&gt;SLS&lt;/code&gt;日志&lt;/li&gt;
&lt;li&gt;筛选&lt;code&gt;uri.path&lt;/code&gt;=&lt;code&gt;/analysis/path&lt;/code&gt;(&lt;em&gt;简化只统计单个&lt;code&gt;path&lt;/code&gt;，实际场景可能是多个&lt;code&gt;path&lt;/code&gt;的访问统计，相应的&lt;code&gt;key&lt;/code&gt;参数规则也会不同&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;解析&lt;code&gt;uri.query&lt;/code&gt;参数&lt;code&gt;id&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;创建ES索引&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PUT sls_analysis

PUT sls_analysis/_mapping/_doc
{
  &amp;quot;properties&amp;quot;: {
    &amp;quot;path&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;
    },
    &amp;quot;key&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;
    },
    &amp;quot;count&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;
    },
    &amp;quot;timestamp&amp;quot;: {
      &amp;quot;type&amp;quot;:&amp;quot;long&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;流程解析&#34;&gt;流程解析&lt;/h2&gt;

&lt;p&gt;接下来结合&lt;a href=&#34;https://github.com/hb-chen/flink-practice/tree/master/sls&#34;&gt;hb-chen/flink-practice&lt;/a&gt;源码对流程进行解析。&lt;/p&gt;

&lt;h3 id=&#34;gradle添加依赖&#34;&gt;Gradle添加依赖&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;    // ES
    flinkShadowJar &amp;quot;org.apache.flink:flink-connector-elasticsearch6_${scalaBinaryVersion}:${flinkVersion}&amp;quot;

    // SLS
    flinkShadowJar &amp;quot;com.aliyun.openservices:flink-log-connector:0.1.7&amp;quot;
    flinkShadowJar &amp;quot;com.aliyun.openservices:aliyun-log:0.6.19&amp;quot;
    flinkShadowJar &amp;quot;com.aliyun.openservices:log-loghub-producer:0.1.8&amp;quot;
    flinkShadowJar &amp;quot;com.google.protobuf:protobuf-java:2.5.0&amp;quot;
    
    // YAML解析
    flinkShadowJar &amp;quot;org.yaml:snakeyaml:1.24&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;参数-配置-可忽略&#34;&gt;参数&amp;amp;配置（可忽略）&lt;/h3&gt;

&lt;p&gt;虽然只是示例还是做了&lt;code&gt;args&lt;/code&gt;参数及&lt;code&gt;config.yml&lt;/code&gt;配置的获取，方便配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) throws Exception {
    final ParameterTool params = ParameterTool.fromArgs(args);
    String analysisPath = params.getRequired(&amp;quot;path&amp;quot;);
    String analysisQueryKey = params.get(&amp;quot;key&amp;quot;, &amp;quot;id&amp;quot;);
    LOG.info(&amp;quot;access log analysis path:&amp;quot; + analysisPath + &amp;quot; key:&amp;quot; + analysisQueryKey);

    Config config = getConfig();
    
    // ……
}

private static Config getConfig() {
    Constructor constructor = new Constructor(Config.class);
    org.yaml.snakeyaml.Yaml yaml = new org.yaml.snakeyaml.Yaml(constructor);

    Config config = yaml.loadAs(SlsAnalysis.class.getClassLoader().getResourceAsStream(&amp;quot;config.yml&amp;quot;), Config.class);
    return config;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;日志消费&#34;&gt;日志消费&lt;/h3&gt;

&lt;p&gt;首先参考&lt;a href=&#34;https://help.aliyun.com/document_detail/63594.html&#34;&gt;官方文档&lt;/a&gt;通过&lt;code&gt;SLS&lt;/code&gt;的各种配置创建一个&lt;code&gt;Consumer&lt;/code&gt;，获得&lt;code&gt;SLS&lt;/code&gt;日志流&lt;code&gt;DataStream&amp;lt;RawLogGroupList&amp;gt; logStream&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    // SLS消费
    // https://help.aliyun.com/document_detail/63594.html
    Properties configProps = new Properties();
    // 设置访问日志服务的域名
    configProps.put(ConfigConstants.LOG_ENDPOINT, config.getSls().getEndpoint());
    // 设置访问ak
    configProps.put(ConfigConstants.LOG_ACCESSSKEYID, config.getSls().getAk());
    configProps.put(ConfigConstants.LOG_ACCESSKEY, config.getSls().getSk());
    // 设置日志服务的project
    configProps.put(ConfigConstants.LOG_PROJECT, config.getSls().getProject());
    // 设置日志服务的Logstore
    configProps.put(ConfigConstants.LOG_LOGSTORE, config.getSls().getLogStore());
    // 设置消费日志服务起始位置
    configProps.put(ConfigConstants.LOG_CONSUMER_BEGIN_POSITION, &amp;quot;&amp;quot; + (System.currentTimeMillis() / 1000L));
    // 设置日志拉取时间间隔及每次调用拉取的日志数量
    configProps.put(ConfigConstants.LOG_FETCH_DATA_INTERVAL_MILLIS, &amp;quot;1000&amp;quot;);
    configProps.put(ConfigConstants.LOG_MAX_NUMBER_PER_FETCH, &amp;quot;100&amp;quot;);
    // 设置Shards发现周期
    configProps.put(ConfigConstants.LOG_SHARDS_DISCOVERY_INTERVAL_MILLIS, Consts.DEFAULT_SHARDS_DISCOVERY_INTERVAL_MILLIS);

    // 设置日志服务的消息反序列化方法
    RawLogGroupListDeserializer deserializer = new RawLogGroupListDeserializer();
    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
    DataStream&amp;lt;RawLogGroupList&amp;gt; logStream = env.addSource(new FlinkLogConsumer&amp;lt;RawLogGroupList&amp;gt;(deserializer, configProps));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过&lt;code&gt;RawLogGroupList&lt;/code&gt;结构知道&lt;code&gt;logStream&lt;/code&gt;获得的是批量的&lt;code&gt;SLS&lt;/code&gt;日志，单条日志是分组的&lt;code&gt;RawLog&lt;/code&gt;列表，这就需要首先对批量的数据进行展开(&lt;code&gt;flatMap()&lt;/code&gt;)来获得单条数据流&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class RawLogGroupList implements Serializable {
    public List&amp;lt;RawLogGroup&amp;gt; rawLogGroups = new ArrayList();
}

public class RawLogGroup implements Serializable {
    public String source;
    public String topic = &amp;quot;&amp;quot;;
    public Map&amp;lt;String, String&amp;gt; tags = new HashMap();
    public List&amp;lt;RawLog&amp;gt; logs = new ArrayList();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;批量日志展开&#34;&gt;批量日志展开&lt;/h3&gt;

&lt;p&gt;这是整个过流程最关键的一环，这里要定义展开后数据流的结构，不啰嗦直接看结构&lt;code&gt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;f0&lt;/code&gt;:&lt;code&gt;AccessLogAnalysis&lt;/code&gt;是解析&lt;code&gt;uri&lt;/code&gt;的&lt;code&gt;path&lt;/code&gt;+&lt;code&gt;key&lt;/code&gt;的对象，也就是要用做&lt;code&gt;keyBy&lt;/code&gt;的属性&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f1&lt;/code&gt;:&lt;code&gt;Integer&lt;/code&gt;统计数量，单条日志全计为1(&lt;em&gt;根据需求这里可以考些优化，比如Group内有序可以在range过程直接对相同&lt;code&gt;request_time&lt;/code&gt;做聚合&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f2&lt;/code&gt;:&lt;code&gt;Long&lt;/code&gt;日志时间戳，考虑后续作为&lt;code&gt;EventTime&lt;/code&gt;使用，所以将&lt;code&gt;request_time&lt;/code&gt;转为毫秒&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f3&lt;/code&gt;:&lt;code&gt;Long&lt;/code&gt;批量日志的最小时间戳，因为&lt;code&gt;SLS&lt;/code&gt;日志是时间有序的，且单个&lt;code&gt;RawLogGroup&lt;/code&gt;日志升序，所以自然的考虑使用最小时间戳作为&lt;code&gt;watermark&lt;/code&gt;，这样也避免了&lt;strong&gt;arrive late&lt;/strong&gt;的出现&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    // SLS批量日志展开
    DataStream&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt; flatStream = logStream.flatMap(new FlatMapFunction&amp;lt;RawLogGroupList, Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt;() {
        @Override
        public void flatMap(RawLogGroupList value, Collector&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt; out) throws Exception {
            // Log group内时间升序，记录所有分组最小时间戳，即为watermark位置
            long minTimestamp = Long.MAX_VALUE;
            for (RawLogGroup group : value.getRawLogGroups()) {
                if (group.getLogs().size() &amp;gt; 0) {
                    RawLog log = group.getLogs().get(0);
                    long rt = Optional.ofNullable(log.getContents().get(&amp;quot;request_time&amp;quot;)).map(Long::new).orElse(Long.MAX_VALUE);
                    minTimestamp = rt &amp;lt; minTimestamp ? rt : minTimestamp;
                }
            }
            // 取毫秒，排除MAX_VALUE
            minTimestamp = minTimestamp == Long.MAX_VALUE ? minTimestamp : minTimestamp * 1000;

            Integer count = 0;
            for (RawLogGroup group : value.getRawLogGroups()) {
                count += group.getLogs().size();
                for (RawLog log : group.getLogs()) {
                    // URI解析
                    QueryStringDecoder decoder = new QueryStringDecoder(log.getContents().get(&amp;quot;uri&amp;quot;));
                    String path = decoder.path();
                    List&amp;lt;String&amp;gt; keyList = decoder.parameters().get(analysisQueryKey);
                    if (path.equalsIgnoreCase(analysisPath) &amp;amp;&amp;amp; keyList != null &amp;amp;&amp;amp; keyList.size() &amp;gt; 0) {
                        Integer id = Optional.ofNullable(keyList.get(0)).map(Integer::new).orElse(0);
                        AccessLogAnalysis ala = new AccessLogAnalysis();
                        ala.setKey(id);
                        ala.setPath(path);

                        Long timestamp = Optional.ofNullable(log.getContents().get(&amp;quot;request_time&amp;quot;)).map(Long::new).orElse(0L);
                        timestamp *= 1000;

                        out.collect(new Tuple4&amp;lt;&amp;gt;(ala, 1, timestamp, minTimestamp));
                    }

                }
            }
            LOG.info(&amp;quot;raw log count:&amp;quot; + count + &amp;quot; timestamp:&amp;quot; + minTimestamp);
        }
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;eventtime-timewindow&#34;&gt;EventTime &amp;amp; timeWindow&lt;/h3&gt;

&lt;p&gt;有了&lt;code&gt;flatStream&lt;/code&gt;的结果，自定义&lt;code&gt;EventTime&lt;/code&gt;以及&lt;code&gt;Watermark&lt;/code&gt;就比较简单。&lt;br/&gt;&lt;code&gt;.keyBy(0).timeWindow(Time.seconds(60)).sum(1)&lt;/code&gt;流程以&lt;code&gt;f0&lt;/code&gt;为&lt;code&gt;key&lt;/code&gt;分隔，60s为时间窗口对&lt;code&gt;f1&lt;/code&gt;求和。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;DataStream result = flatStream.assignTimestampsAndWatermarks(new AssignerWithPunctuatedWatermarks&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt;() {
    @Nullable
    @Override
    public Watermark checkAndGetNextWatermark(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; lastElement, long extractedTimestamp) {
        return lastElement.f3 &amp;lt;= extractedTimestamp ? new Watermark(lastElement.f3) : null;
    }

    @Override
    public long extractTimestamp(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; element, long previousElementTimestamp) {
        if (element.f2 &amp;gt; 0L) {
            return element.f2;
        } else {
            return previousElementTimestamp;
        }
    }
})
.keyBy(0)
.timeWindow(Time.seconds(60))
.sum(1);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;输出到es&#34;&gt;输出到ES&lt;/h3&gt;

&lt;p&gt;大致参考&lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/connectors/elasticsearch.html&#34;&gt;官方文档&lt;/a&gt;即可，
只是没有认证(&lt;em&gt;生产环境必不可少，想到ES社区的分享，在&lt;a href=&#34;https://www.shodan.io&#34;&gt;shodan.io&lt;/a&gt;上找各种公开免费ES资源😏&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Sink:Elasticsearch
List&amp;lt;HttpHost&amp;gt; httpHosts = new ArrayList&amp;lt;&amp;gt;();
httpHosts.add(new HttpHost(config.getEs().getHostname(), 9200, &amp;quot;http&amp;quot;));

// use a ElasticsearchSink.Builder to create an ElasticsearchSink
ElasticsearchSink.Builder&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt; esSinkBuilder = new ElasticsearchSink.Builder&amp;lt;&amp;gt;(httpHosts, new ElasticsearchSinkFunction&amp;lt;Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt;&amp;gt;() {
    public IndexRequest createIndexRequest(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; element) {
        Map&amp;lt;String, String&amp;gt; json = new HashMap&amp;lt;&amp;gt;();
        json.put(&amp;quot;path&amp;quot;, element.f0.getPath());
        json.put(&amp;quot;key&amp;quot;, element.f0.getKey().toString());
        json.put(&amp;quot;count&amp;quot;, element.f1.toString());
        json.put(&amp;quot;timestamp&amp;quot;, element.f3.toString());

        return Requests.indexRequest().index(&amp;quot;sls_analysis&amp;quot;).type(&amp;quot;_doc&amp;quot;).source(json);
    }

    @Override
    public void process(Tuple4&amp;lt;AccessLogAnalysis, Integer, Long, Long&amp;gt; element, RuntimeContext runtimeContext, RequestIndexer requestIndexer) {
        requestIndexer.add(createIndexRequest(element));
    }
});

// configuration for the bulk requests; this instructs the sink to emit after every element, otherwise they would be buffered
esSinkBuilder.setBulkFlushMaxActions(1);

// provide a RestClientFactory for custom configuration on the internally created REST client
String esUsername = config.getEs().getUsername();
String esPassword = config.getEs().getPassword();
esSinkBuilder.setRestClientFactory(restClientBuilder -&amp;gt; {
    // restClientBuilder.setDefaultHeaders(headers);
    // restClientBuilder.setMaxRetryTimeoutMillis(...)
    // restClientBuilder.setPathPrefix(...)
    restClientBuilder.setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() {
        @Override
        public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpAsyncClientBuilder) {
            CredentialsProvider credentialsProvider = new BasicCredentialsProvider();
            credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(esUsername, esPassword));
            return httpAsyncClientBuilder.setDefaultCredentialsProvider(credentialsProvider);
        }
    });
});

// finally, build and add the sink to the job&#39;s pipeline
result.addSink(esSinkBuilder.build());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里还遇到个小坑（Java丢的太久了😂），在&lt;code&gt;UsernamePasswordCredentials()&lt;/code&gt;中直接使用&lt;code&gt;config.getEs().getUsername()&lt;/code&gt; &lt;code&gt;config.getEs().getPassword()&lt;/code&gt;，导致序列化错误，相关参考&lt;a href=&#34;https://yuzhouwan.com/posts/20644/&#34;&gt;Apache Flink#踩过的坑&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Exception in thread &amp;quot;main&amp;quot; org.apache.flink.api.common.InvalidProgramException: The implementation of the ElasticsearchSinkBase is not serializable. The object probably contains or references non serializable fields.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试-打包&#34;&gt;测试 &amp;amp; 打包&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 测试
$ ./gradlew sls:run --args=&amp;quot;--path /analysis/path&amp;quot;

# 打包
$ ./gradlew clean sls:shadowJar
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;提交job到flink运行&#34;&gt;提交Job到Flink运行&lt;/h3&gt;

&lt;p&gt;上传&lt;code&gt;.jar&lt;/code&gt;到Flink&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Program Arguments
--path /analysis/path
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/flink/sls+es-dashboard.png&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;到kibana看下结果&#34;&gt;到Kibana看下结果&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/flink/sls+es-kibana.png&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GET /sls_analysis/_search
{
  &amp;quot;aggs&amp;quot;: {
    &amp;quot;2&amp;quot;: {
      &amp;quot;terms&amp;quot;: {
        &amp;quot;field&amp;quot;: &amp;quot;key&amp;quot;,
        &amp;quot;size&amp;quot;: 20,
        &amp;quot;order&amp;quot;: {
          &amp;quot;1&amp;quot;: &amp;quot;desc&amp;quot;
        }
      },
      &amp;quot;aggs&amp;quot;: {
        &amp;quot;1&amp;quot;: {
          &amp;quot;sum&amp;quot;: {
            &amp;quot;field&amp;quot;: &amp;quot;count&amp;quot;
          }
        }
      }
    }
  },
  &amp;quot;size&amp;quot;: 0,
  &amp;quot;_source&amp;quot;: {
    &amp;quot;excludes&amp;quot;: []
  },
  &amp;quot;stored_fields&amp;quot;: [
    &amp;quot;*&amp;quot;
  ],
  &amp;quot;script_fields&amp;quot;: {},
  &amp;quot;docvalue_fields&amp;quot;: [],
  &amp;quot;query&amp;quot;: {
    &amp;quot;bool&amp;quot;: {
      &amp;quot;must&amp;quot;: [
        {
          &amp;quot;match_all&amp;quot;: {}
        },
        {
          &amp;quot;match_phrase&amp;quot;: {
            &amp;quot;path&amp;quot;: {
              &amp;quot;query&amp;quot;: &amp;quot;/analysis/path&amp;quot;
            }
          }
        }
      ],
      &amp;quot;filter&amp;quot;: [],
      &amp;quot;should&amp;quot;: [],
      &amp;quot;must_not&amp;quot;: []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;todo&#34;&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Checkpoint&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio安全】网格边缘-Egress</title>
      <link>http://hbchen.com/post/servicemesh/2019-04-11-istio-security-egress/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-04-11-istio-security-egress/</guid>
      
        <description>&lt;p&gt;接上一篇《&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/&#34;&gt;【Istio安全】服务间访问控制-RBAC&lt;/a&gt;》，本文主要介绍网格边缘Egress相关的配置，&lt;code&gt;HTTP&lt;/code&gt;、&lt;code&gt;HTTPS&lt;/code&gt;以及&lt;code&gt;HTTP&lt;/code&gt;转&lt;code&gt;TLS&lt;/code&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Istio版本 &lt;strong&gt;1.1.1&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;开始前的准备&#34;&gt;开始前的准备&lt;/h2&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  # Set the default behavior of the sidecar for handling outbound traffic from the application:
  # ALLOW_ANY - outbound traffic to unknown destinations will be allowed, in case there are no
  #   services or ServiceEntries for the destination port
  # REGISTRY_ONLY - restrict outbound traffic to services defined in the service registry as well
  #   as those defined through ServiceEntries
  # ALLOW_ANY is the default in 1.1.  This means each pod will be able to make outbound requests 
  # to services outside of the mesh without any ServiceEntry.
  # REGISTRY_ONLY was the default in 1.0.  If this behavior is desired, set the value below to REGISTRY_ONLY.
  outboundTrafficPolicy:
    mode: ALLOW_ANY
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;Istio部署配置的&lt;code&gt;global.outboundTrafficPolicy&lt;/code&gt;参数，在1.1开始默认&lt;code&gt;ALLOW_ANY&lt;/code&gt;，这种情况下如果不配置&lt;code&gt;ServiceEntry&lt;/code&gt;，访问外包HTTP流量返回&lt;code&gt;404&lt;/code&gt;，而HTTPS流量可以正常访问，为了测试&lt;code&gt;ServiceEntry&lt;/code&gt;配置效果，将配置改为&lt;code&gt;REGISTRY_ONLY&lt;/code&gt;，方便观察&lt;code&gt;ServiceEntry&lt;/code&gt;配置的效果&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文示例Istio使用helm的values-istio-demo.yaml配置安装&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;部署测试用例&lt;code&gt;sleep&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.1/samples/sleep/sleep.yaml

$ export SOURCE_POD=$(kubectl get pod -l app=sleep -o jsonpath={.items..metadata.name})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;code&gt;outboundTrafficPolicy=ALLOW_ANY&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://hbchen.com
HTTP/1.1 404 Not Found

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 404 Not Found

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
HTTP/2 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改&lt;code&gt;values-istio-demo.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  outboundTrafficPolicy:
    mode: REGISTRY_ONLY
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新部署Istio&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system --values install/kubernetes/helm/istio/values-istio-demo.yaml | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新部署测试用例&lt;code&gt;sleep&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl delete -f https://raw.githubusercontent.com/istio/istio/release-1.1/samples/sleep/sleep.yaml
$ kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.1/samples/sleep/sleep.yaml

$ export SOURCE_POD=$(kubectl get pod -l app=sleep -o jsonpath={.items..metadata.name})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sidecar方式&#34;&gt;Sidecar方式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/egress-sidecar.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;http&#34;&gt;HTTP&lt;/h3&gt;

&lt;p&gt;先定义一个&lt;code&gt;ServiceEntry&lt;/code&gt;，开启&lt;code&gt;www.aliyun.com&lt;/code&gt;、&lt;code&gt;hbchen.com&lt;/code&gt;的外部访问&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http
    protocol: HTTP
  resolution: NONE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://hbchen.com
HTTP/1.1 200 OK

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 301 Moved Permanently
...
command terminated with exit code 35

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
command terminated with exit code 35
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http-https&#34;&gt;HTTP &amp;amp; HTTPS&lt;/h3&gt;

&lt;p&gt;只开&lt;code&gt;80&lt;/code&gt;端口，&lt;code&gt;HTTP&lt;/code&gt;正常，而对于&lt;code&gt;HTTPS&lt;/code&gt;以及有&lt;code&gt;HTTP&lt;/code&gt;重定向&lt;code&gt;HTTPS&lt;/code&gt;的请求仍会失败&lt;code&gt;command terminated with exit code 35&lt;/code&gt;，所以实践中外部服务一般同时开启&lt;code&gt;80&lt;/code&gt;、&lt;code&gt;443&lt;/code&gt;端口&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;$ kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http-port
    protocol: HTTP
  - number: 443
    name: https-port
    protocol: HTTPS
  resolution: NONE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 301 Moved Permanently
...
HTTP/2 200

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
HTTP/2 200
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http转tls&#34;&gt;HTTP转TLS&lt;/h3&gt;

&lt;p&gt;这时我们看到另一个问题，需要升级&lt;code&gt;HTTPS&lt;/code&gt;的&lt;code&gt;HTTP&lt;/code&gt;请求每次都要&lt;code&gt;301&lt;/code&gt;重定向一次，在不修改代码的情况下可以在&lt;code&gt;proxy&lt;/code&gt;将&lt;code&gt;HTTP&lt;/code&gt;请求升级为&lt;code&gt;TLS&lt;/code&gt;，避免二次跳转，需要加&lt;code&gt;VirtualService&lt;/code&gt; + &lt;code&gt;DestinationRule&lt;/code&gt;来实现。&lt;/p&gt;

&lt;p&gt;在官方示例&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/egress-tls-origination/#%E5%87%BA%E5%8F%A3%E6%B5%81%E9%87%8F%E7%9A%84-tls&#34;&gt;出口流量的-tls&lt;/a&gt;中，仅将&lt;code&gt;HTTP&lt;/code&gt;升级到&lt;code&gt;TLS&lt;/code&gt;，而对正常的&lt;code&gt;HTTPS&lt;/code&gt;没有支持，这里稍作改动，在&lt;code&gt;VirtualService&lt;/code&gt;中为&lt;code&gt;80&lt;/code&gt;端口的&lt;code&gt;destination&lt;/code&gt;定义&lt;code&gt;subset&lt;/code&gt;，这样在&lt;code&gt;DestinationRule&lt;/code&gt;中默认&lt;code&gt;trafficPolicy&lt;/code&gt;不做处理，仅对指定的&lt;code&gt;subset&lt;/code&gt;做&lt;code&gt;HTTPS&lt;/code&gt;转发，使网格内无论发起&lt;code&gt;HTTP&lt;/code&gt;还是&lt;code&gt;HTTPS&lt;/code&gt;的外网请求都可以正常访问。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  - hbchen.com
  ports:
  - number: 80
    name: http-port
    protocol: HTTP
  - number: 443
    name: https-port
    protocol: HTTPS
  resolution: DNS
  location: MESH_EXTERNAL
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: rewrite-port-for-entry
spec:
  hosts:
  - www.aliyun.com
  http:
  - match:
      - port: 80
    route:
    - destination:
        # NOTE: 为HTTP升级流量指定subset
        subset: originate-tls
        host: www.aliyun.com
        port:
          number: 443
  tls:
  - match:
      - port: 443
        sniHosts:
        - www.aliyun.com
    route:
    - destination:
        host: www.aliyun.com
        port:
          number: 443
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: originate-tls-for-entry
spec:
  host: www.aliyun.com
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - name: originate-tls
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
        portLevelSettings:
        - port:
            number: 443
          tls:
            mode: SIMPLE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://hbchen.com
HTTP/1.1 200 OK

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 200 OK

$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - https://www.aliyun.com
HTTP/2 200
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gateway方式&#34;&gt;Gateway方式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/egress-gateway.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;官方示例&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/egress-gateway/&#34;&gt;配置 Egress gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gateway与Sidecar的区别是将出口流量都转到&lt;code&gt;egressgateway&lt;/code&gt;，再由Gateway进行转发处理，无论Gateway还是Sidecar&lt;code&gt;ServiceEntry&lt;/code&gt;的配置规则都是需要的，这里我们直接开启&lt;code&gt;80&lt;/code&gt;、&lt;code&gt;433&lt;/code&gt;，注意&lt;code&gt;resolution&lt;/code&gt;=&lt;code&gt;DNS&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: entry-x
spec:
  hosts:
  - www.aliyun.com
  ports:
  - number: 80
    name: http-port
    protocol: HTTP
  - number: 443
    name: https-port
    protocol: HTTPS
  resolution: DNS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;访问测试（略）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;http-1&#34;&gt;HTTP&lt;/h3&gt;

&lt;p&gt;流程如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR;
   S[Siedcar]--&amp;gt;|&amp;quot;①HTTP&amp;quot;|VS[VirtualService&amp;lt;br/&amp;gt;www.aliyun.com]
   VS--&amp;gt;|&amp;quot;②gateway=mesh&amp;quot;|EG[EgressGateway]
   EG--&amp;gt;|&amp;quot;③HTTP&amp;quot;|VS
   VS--&amp;gt;|&amp;quot;④gateway=istio-egressgateway&amp;quot;|E[External]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-egressgateway
spec:
  selector:
    istio: egressgateway
  servers:
  - port:
      number: 80
      name: http-port
      protocol: HTTP
    hosts:
    - www.aliyun.com
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: egressgateway-for-aliyun
spec:
  host: istio-egressgateway.istio-system.svc.cluster.local
  subsets:
  - name: aliyun
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: aliyun-through-egress-gateway
spec:
  hosts:
  - www.aliyun.com
  gateways:
  - istio-egressgateway
  - mesh
  http:
  - match:
    - gateways:
      - mesh
      port: 80
    route:
    - destination:
        host: istio-egressgateway.istio-system.svc.cluster.local
        subset: aliyun
        port:
          number: 80
      weight: 100
  - match:
    - gateways:
      - istio-egressgateway
      port: 80
    route:
    - destination:
        host: www.aliyun.com
        port:
          number: 80
      weight: 100
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;(&lt;em&gt;这里只有HTTP&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 301 Moved Permanently
...
HTTP/2 200
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http转tls-1&#34;&gt;HTTP转TLS&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR;
   S[Siedcar]--&amp;gt;|&amp;quot;①HTTP&amp;quot;|VS[VirtualService&amp;lt;br/&amp;gt;www.aliyun.com]
   VS--&amp;gt;|&amp;quot;②gateway=mesh&amp;quot;|EG[EgressGateway]
   EG--&amp;gt;|&amp;quot;③HTTP&amp;quot;|VS
   VS--&amp;gt;|&amp;quot;④gateway=istio-egressgateway&amp;lt;br/&amp;gt;DestinationRule为Subset升级TLS&amp;quot;|E[External]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;与Sidecar方式类似，对于有&lt;code&gt;HTTP&lt;/code&gt;重定向到&lt;code&gt;HTTPS&lt;/code&gt;的流量可以在Gateway代理直接升级为&lt;code&gt;TLS&lt;/code&gt;，减少跳转，实现方式与Sidecar方式类似，为&lt;code&gt;HOST&lt;/code&gt;增加&lt;code&gt;DestinationRule&lt;/code&gt;规则为&lt;code&gt;HTTP&lt;/code&gt;流量发起&lt;code&gt;TLS&lt;/code&gt;请求。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;kubectl apply -f - &amp;lt;&amp;lt;EOF
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-egressgateway
spec:
  selector:
    istio: egressgateway
  servers:
  - port:
      number: 80
      name: http-port
      protocol: HTTP
    hosts:
    - www.aliyun.com
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: egressgateway-for-aliyun
spec:
  host: istio-egressgateway.istio-system.svc.cluster.local
  subsets:
  - name: aliyun
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: aliyun-through-egress-gateway
spec:
  hosts:
  - www.aliyun.com
  gateways:
  - istio-egressgateway
  - mesh
  http:
  - match:
    - gateways:
      - mesh
      port: 80
    route:
    - destination:
        host: istio-egressgateway.istio-system.svc.cluster.local
        subset: aliyun
        port:
          number: 80
      weight: 100
  - match:
    - gateways:
      - istio-egressgateway
      port: 80
    route:
    - destination:
        host: www.aliyun.com
        # NOTE: 为HTTP升级流量指定subset
        subset: originate-tls
        port:
          number: 443
      weight: 100
---
# NOTE: 注意这里与Sidecar方式类似，需要对HTTP流量单独配置subset，否则影响正常HTTPS流量
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: originate-tls-for-aliyun
spec:
  host: www.aliyun.com
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - name: originate-tls
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
        portLevelSettings:
        - port:
            number: 443
          tls:
            mode: SIMPLE
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -it $SOURCE_POD -c sleep -- curl -sL -o /dev/null -D - http://www.aliyun.com
HTTP/1.1 200 OK
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;双向&lt;code&gt;TLS&lt;/code&gt;、&lt;code&gt;HTTTPS&lt;/code&gt;透传等这里没有再做测试，有兴趣可以参考官方示例&lt;a href=&#34;https://istio.io/zh/docs/examples/advanced-gateways/egress-gateway/&#34;&gt;配置 Egress gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;直接调用外部服务&#34;&gt;直接调用外部服务&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio/egress-sidecar-ip.png&#34; alt=&#34;ServiceEntry&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Istio文档&lt;a href=&#34;https://istio.io/zh/docs/tasks/traffic-management/egress/#%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1&#34;&gt;直接调用外部服务&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;需要修改helm的values配置更新部署。并且要让新的&lt;code&gt;istio-sidecar-injector&lt;/code&gt;生效，重新部署&lt;code&gt;sleep&lt;/code&gt;用例。这种方式在Sidecar的Proxy中跳过了外部IP，虽然也有&lt;code&gt;excludeIPRanges&lt;/code&gt;方式，但修改麻烦需要更新sidecar，并且这样也失去了Istio的其它能力，所以不怎么实用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  proxy:
    # Minikube
    includeIPRanges: &amp;quot;10.0.0.1/24&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ServiceEntry&lt;/code&gt;配合&lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt;可以使外部流量做比较灵活的管控，并且可以对外部服务使用流量管理的相关功能，Gateway相对Sidecar配置还是略显复杂，而在性能方面官方Blog&lt;a href=&#34;https://istio.io/zh/blog/2019/egress-performance/&#34;&gt;Egress gateway 性能测试&lt;/a&gt;给出的比较结果两者相差不大，至于直接调用方式相对就不怎么实用了。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio源码】Pilot Agent</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-31-istio-code-pilot-agent/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-31-istio-code-pilot-agent/</guid>
      
        <description>&lt;p&gt;接上一篇&lt;a href=&#34;http://hbchen.com/post/servicemesh/2019-03-17-istio-code-pilot-discovery/&#34;&gt;《【Istio源码】Pilot Discovery》&lt;/a&gt;，这篇继续分析&lt;strong&gt;Pilot&lt;/strong&gt;的&lt;code&gt;pilot-agent&lt;/code&gt;模块。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pilot-agent&lt;/code&gt;相对&lt;code&gt;pilot-discovery&lt;/code&gt;在控制平面比较简单，&lt;strong&gt;agent&lt;/strong&gt;更多的能力是在数据平面的&lt;code&gt;envoy&lt;/code&gt;，&lt;code&gt;envoy&lt;/code&gt;通过&lt;code&gt;xDS&lt;/code&gt;协议与&lt;code&gt;pilot-discovery&lt;/code&gt;服务进行通信。agent主要负责监控&lt;code&gt;ingress&lt;/code&gt;、&lt;code&gt;mTLS&lt;/code&gt;的证书，发生变更后重启&lt;code&gt;envoy&lt;/code&gt;，以及提供&lt;strong&gt;agent&lt;/strong&gt;状态的HTTP服务(&lt;em&gt;可选服务&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant a as agent
    participant pa as proxy/agent
    participant ew as envoy/watcher
    participant ep as envoy/proxy
    participant s as status
    participant fw as fsnotify.Watcher 
    
    Note over a,fw: agent状态服务
    a -&amp;gt;&amp;gt; s: NewServer()
    s --&amp;gt;&amp;gt; a: statusServer *Server
    a -&amp;gt;&amp;gt; s: statusServer.Run()

    a -&amp;gt;&amp;gt; ep: NewProxy(proxyConfig)
    ep --&amp;gt;&amp;gt; a: envoyProxy proxy.Proxy
    a -&amp;gt;&amp;gt; pa: NewAgent(envoyProxy)
    pa --&amp;gt; a: agent Agent
    a -&amp;gt;&amp;gt; ew: NewWatcher(agent.ConfigCh)，updates = agent.ConfigCh
    ew --&amp;gt;&amp;gt; a: watcher Watcher
    
    Note over a,fw: watcher监控配置变更，通知agent重启envoy
    loop: go
        a -&amp;gt;&amp;gt; ew: watcher.Run()
        ew -&amp;gt;&amp;gt; fw: fw.Watch(certs)，AuthCertsPath、IngressCertsPath
        fw --&amp;gt;&amp;gt; ew: w.watchFileEvents()
        ew -&amp;gt;&amp;gt; ew: &amp;lt;-timeChan，10s延迟
        ew -&amp;gt;&amp;gt; ew: SendConfig()
        ew -&amp;gt;&amp;gt; pa: updates&amp;lt;-
        Note over pa: &amp;lt;-configCh
    end    
    
    Note over a,fw: agent做envoy重启操作，包括频率控制、失败重试等
    loop : go
        a -&amp;gt;&amp;gt; pa: agent.Run()
        Note over pa: rateLimiter.Wait()&amp;lt;br/&amp;gt;控制频率
        alt &amp;lt;-configCh
            Note over pa: 配置更新Envoy热重启&amp;lt;br/&amp;gt;reconcile()
        else &amp;lt;-statusCh  
            Note over pa: Envoy重启后通知处理&amp;lt;br/&amp;gt;失败重试逻辑
        else &amp;lt;-reconcileTimer.C
            Note over pa: 失败重试计时重启&amp;lt;br/&amp;gt;reconcile()
        end
    end
    
    loop: envoy重启
        pa -&amp;gt;&amp;gt; pa: reconcile()
        Note over ep: 默认服务发现地址:&amp;lt;br/&amp;gt;istio-pilot:15010&amp;lt;br/&amp;gt;对应pilot-discovery的地址:&amp;lt;br/&amp;gt;gRPC port:15010
        pa -&amp;gt;&amp;gt; ep: proxy.Run(&amp;lt;-abort)
        ep --&amp;gt;&amp;gt; pa: err error
        pa -&amp;gt;&amp;gt; pa: statusCh&amp;lt;-
    end
    
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio源码】Pilot Discovery</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-17-istio-code-pilot-discovery/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-17-istio-code-pilot-discovery/</guid>
      
        <description>&lt;p&gt;流量管理是网格的基础，Pilot负责三个主要功能：服务治理&lt;code&gt;istio-pilot&lt;/code&gt;、Sidecar注入&lt;code&gt;istio-sidecar-injector&lt;/code&gt;、以及Sidecar&lt;code&gt;istio-proxy&lt;/code&gt;，
分别由三个模块负责：&lt;code&gt;pilot-discovery&lt;/code&gt;、&lt;code&gt;sidecar-injector&lt;/code&gt;、&lt;code&gt;pilot-agent&lt;/code&gt;，这里从&lt;code&gt;pilot-discovery&lt;/code&gt;开始。&lt;/p&gt;

&lt;h2 id=&#34;discovery运行序列&#34;&gt;Discovery运行序列&lt;/h2&gt;

&lt;h3 id=&#34;kube环境简化序列&#34;&gt;kube环境简化序列&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant s as server
    participant f as fileWatcher
    participant i as k8s.io/client-go&amp;lt;br/&amp;gt;informer
    participant h as handler
    
    Note over s: mesh
    s -&amp;gt;&amp;gt; f: addFieWatcher()
    Note over s: meshNetworks
    s -&amp;gt;&amp;gt; f: addFileWatcher()
    Note over s: config
        loop IstioConfigTypes
        s -&amp;gt;&amp;gt; i: cache.NewSharedIndexInformer()
        end
    Note over s: service
        activate i
        s -&amp;gt;&amp;gt; i: Services().Informer()
        s -&amp;gt;&amp;gt; i: Endpoints().Informer()
        s -&amp;gt;&amp;gt; i: Nodes().Informer()
        s -&amp;gt;&amp;gt; i: Pods().Informer()
        deactivate i
    Note over s: discovery
        activate h
        s -&amp;gt;&amp;gt; h: service.AppendServiceHandler()
        s -&amp;gt;&amp;gt; h: service.AppendInstanceHandler()
        s -&amp;gt;&amp;gt; h: config.RegisterEventHandler()
        deactivate h
    alt fsnotify
        f -&amp;gt;&amp;gt; s: fsnotify.Event()
        s -&amp;gt;&amp;gt; s: ds.ConfigUpdate()
    end
        
    alt K8S
        i -&amp;gt;&amp;gt; h: handler.Apply()
        loop handler.funcs
            h -&amp;gt;&amp;gt; s: Event Handler
            s -&amp;gt;&amp;gt; s: ds.ConfigUpdate()
        end
    end
    activate s
    s -&amp;gt;&amp;gt; s: pushChannel &amp;lt;- XdsEvent
    s -&amp;gt;&amp;gt; s: ds.StreamAggregatedResources()Push到xDS
    deactivate s

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;详细序列&#34;&gt;详细序列&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
    participant b as bootstrap
    participant kc as k8s.io/client-go
    participant cmd as cmd
    participant c as config/&amp;lt;br/&amp;gt;aggregate&amp;lt;br/&amp;gt;kube&amp;lt;br/&amp;gt;……
    
    participant k as kube
    participant m as model
    participant pe as proxy/envoy
    participant sr as serviceregistry
    
    
    b -&amp;gt;&amp;gt; b: NewServer()
    Note left of b: initKubeClient()
    b -&amp;gt;&amp;gt; k: kube.CreateClientset()
    k --&amp;gt;&amp;gt; b: kubeClient *kubernetes.Clientset
    
    Note left of b: 网格配置&amp;lt;br/&amp;gt;initMesh()
        Note over kc,cmd: 默认ConfigFile&amp;lt;br/&amp;gt;/etc/istio/config/mesh
        alt args.Mesh.ConfigFile != &amp;quot;&amp;quot;
        b -&amp;gt;&amp;gt; cmd: cmd.ReadMeshConfig(args.Mesh.ConfigFile)
        cmd --&amp;gt;&amp;gt; b: mesh *meshconfig.MeshConfig
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;️addFileWatcher(args.Mesh.ConfigFile)&amp;lt;br/&amp;gt;mesh reload&amp;lt;br/&amp;gt;✅s.EnvoyXdsServer.ConfigUpdate()
        else K8s ConfigMap 获取配置
        b -&amp;gt;&amp;gt; b: GetMeshConfig(s.kubeClient, kube.IstioNamespace, kube.IstioConfigMap)
        b -&amp;gt;&amp;gt; m: model.DefaultMeshConfig()/model.ApplyMeshConfigDefaults(cfgYaml)
        m --&amp;gt;&amp;gt; b: mesh meshconfig.MeshConfig
        end
    
    Note left of b: Mesh网络配置&amp;lt;br/&amp;gt;initMeshNetworks()
        Note over kc,cmd: 默认NetworksConfigFile&amp;lt;br/&amp;gt;/etc/istio/config/meshNetworks
        alt args.NetworksConfigFile != &amp;quot;&amp;quot;
        b -&amp;gt;&amp;gt; cmd: cmd.ReadMeshNetworksConfig()
        cmd --&amp;gt;&amp;gt; b: meshNetworks *meshconfig.MeshNetworks
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;addFileWatcher(args.NetworksConfigFile)&amp;lt;br/&amp;gt;meshNetworks reload&amp;lt;br/&amp;gt;✅s.EnvoyXdsServer.ConfigUpdate()
        end
    
    Note left of b: Mixer&amp;lt;br/&amp;gt;initMixerSan()
        alt s.mesh.DefaultConfig.ControlPlaneAuthPolicy == meshconfig.AuthenticationPolicy_MUTUAL_TLS
        b -&amp;gt;&amp;gt; pe: envoy.GetMixerSAN(args.Namespace)
        pe -&amp;gt;&amp;gt; b: SpiffeURI string
        Note over kc,cmd: s.mixerSAN[SpiffeURI]&amp;lt;br/&amp;gt;NewDiscoveryService的Env
        end
    
    Note left of b: 配置管理&amp;lt;br/&amp;gt;initConfigController()
        alt len(args.MCPServerAddrs) &amp;gt; 0 || len(s.mesh.ConfigSources) &amp;gt; 0
        Note over kc,cmd: s.initMCPConfigController()
            Note over kc,cmd: var clients []*client.Client&amp;lt;br/&amp;gt;var clients2 []*sink.Client&amp;lt;br/&amp;gt;var conns []*grpc.ClientConn&amp;lt;br/&amp;gt;var configStores []model.ConfigStoreCache
            loop s.mesh.ConfigSources
                alt url.Scheme == fsScheme
                b -&amp;gt;&amp;gt; c: memory.NewController(store)
                c --&amp;gt;&amp;gt; b: configController model.ConfigStoreCache
                Note over kc,cmd: configStores = append(configStores, configController)
                else
                b -&amp;gt;&amp;gt; c: coredatamodel.NewController()
                c --&amp;gt;&amp;gt; b: mcpController CoreDataModel
                Note over kc,cmd: clients = append(clients, mcpClient)&amp;lt;br/&amp;gt;clients2 = append(clients2, mcpClient2)&amp;lt;br/&amp;gt;mcpController是MCP Client的Updater&amp;lt;br/&amp;gt;当Client端收到Response时&amp;lt;br/&amp;gt;通过Updater.Apply()接口通知更新
                Note over kc,cmd: conns = append(conns, conn)&amp;lt;br/&amp;gt;configStores = append(configStores, mcpController)
                end
            end
            
            alt len(configStores) == 0
            Note over kc,cmd: ConfigSources未加载配置&amp;lt;br/&amp;gt;从MCPServerAddrs加载
            loop args.MCPServerAddrs
            b -&amp;gt;&amp;gt; c: coredatamodel.NewController()
            c --&amp;gt;&amp;gt; b: mcpController CoreDataModel
            Note over kc,cmd: conns = append(conns, conn)&amp;lt;br/&amp;gt;configStores = append(configStores, mcpController)
            end
            end
            
            
            Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc(go func() {client.Run(ctx)}())&amp;lt;br/&amp;gt;MCP Clients启动&amp;lt;br/&amp;gt;接收到Response通知mcpController&amp;lt;br/&amp;gt;Apply(*Change)&amp;lt;br/&amp;gt;model.ServiceEntry.Type的修改通知到serviceEntryEvents()&amp;lt;br/&amp;gt;❗在external.NewServiceDiscovery()有model.ServiceEntry.Type的handler
            Note over kc,cmd: 配置汇总
            b -&amp;gt;&amp;gt; c: configaggregate.MakeCache(configStores)
            c --&amp;gt;&amp;gt; b: aggregateMcpController model.ConfigStoreCache
            
        else args.Config.Controller != nil
        Note over kc,cmd: s.configController = args.Config.Controller
        else args.Config.FileDir != &amp;quot;&amp;quot;
        Note over kc,cmd: configController := memory.NewController(store)
        else 默认KubeConfig
        Note over kc,cmd: controller, err := s.makeKubeConfigController(args)
        end
        
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc ( go s.configController.Run(stop) )&amp;lt;br/&amp;gt;配置Controller启动&amp;lt;br/&amp;gt;处理配置变更的EventHandler&amp;lt;br/&amp;gt;memory、kube.crd的Controller有Run()实现
        Note over kc,cmd: memory通过makeFileMonitor()监控文件&amp;lt;br/&amp;gt;接收资源变更时更新configStore&amp;lt;br/&amp;gt;并通过monitor.ScheduleProcessEvent()分发事件&amp;lt;br/&amp;gt;❗RegisterEventHandler将handler Append到monitor的handlers
        Note over kc,cmd: kube.crd.cacheHandler运行informer&amp;lt;br/&amp;gt;informer监控不同ConfigType&amp;lt;br/&amp;gt;informer将资源Add、Update、Delete事件统一压入Queue&amp;lt;br/&amp;gt;Queue Run()逐个事件处理，即cacheHandler的hander.funcs&amp;lt;br/&amp;gt;❗RegisterEventHandler将handler Append到hander.funcs
        Note over b,c: 💚💚💚💚💚&amp;lt;br/&amp;gt;RegisterEventHandler()&amp;lt;br/&amp;gt;&amp;lt;br/&amp;gt;❗在Discovery和ServiceRegistry有handler注册
        
        alt hasKubeRegistry(args) &amp;amp;&amp;amp; s.mesh.IngressControllerMode != meshconfig.MeshConfig_OFF
        Note over kc,cmd: K8s ingress的ConfigController
        b -&amp;gt;&amp;gt; c: ingress.NewController()
        c --&amp;gt;&amp;gt; b: ingress model.ConfigStoreCache
        b -&amp;gt;&amp;gt; c: configaggregate.MakeCache(s.configController, ingress)
        c --&amp;gt;&amp;gt; b: configController model.ConfigStoreCache
        b -&amp;gt;&amp;gt; c: ingress.NewStatusSyncer()
        c --&amp;gt;&amp;gt; b: ingressSyncer *StatusSyncer
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc ( go ingressSyncer.Run(stop) )&amp;lt;br/&amp;gt;Ingress Syncer启动
        end
        b -&amp;gt;&amp;gt; m: model.MakeIstioStore(s.configController)
        m --&amp;gt;&amp;gt; b: istioConfigStore IstioConfigStore
        Note over b,c: 💚💚💚💚💚&amp;lt;br/&amp;gt;istioConfigStore提供Istio配置获取&amp;lt;br/&amp;gt;主要为ConfigStore的List()接口
    
    Note left of b: 服务注册&amp;lt;br/&amp;gt;initServiceControllers()
        b -&amp;gt;&amp;gt; sr: aggregate.NewController()
        sr --&amp;gt;&amp;gt; b: serviceControllers *Controller
        loop args.Service.Registries
        Note over b,c: 💚💚💚💚💚&amp;lt;br/&amp;gt;多注册中心&amp;lt;br/&amp;gt;Controller通过AppendServiceHandler()、AppendInstanceHandler()接收外部Handler&amp;lt;br/&amp;gt;在有变更时轮询Handler&amp;lt;br/&amp;gt;❗Discovery会AppendHandler
        alt serviceregistry.MockRegistry
        b -&amp;gt;&amp;gt; b: s.initMemoryRegistry()
        b -&amp;gt;&amp;gt; sr: srmemory.NewDiscovery() aggregate.Registry{}
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        else serviceregistry.KubernetesRegistry
        b -&amp;gt;&amp;gt; b: s.createK8sServiceControllers()
        b -&amp;gt;&amp;gt; sr: kube.NewController()
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        else serviceregistry.ConsulRegistry
        b -&amp;gt;&amp;gt; b: s.initConsulRegistry()
        b -&amp;gt;&amp;gt; sr: consul.NewController()
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        else serviceregistry.MCPRegistry
        Note over kc,cmd: no-op: get service info from MCP ServiceEntries.
        end
        end
        b -&amp;gt;&amp;gt; sr: external.NewServiceDiscovery()
        sr --&amp;gt;&amp;gt; b: serviceEntryStore *ServiceEntryStore
        b --&amp;gt;&amp;gt; b: serviceControllers.AddRegistry()
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc()&amp;lt;br/&amp;gt;服务注册Controllers启动
    
    Note left of b: 服务发现&amp;lt;br/&amp;gt;initDiscoveryService()&amp;lt;br/&amp;gt;gRPC和HTTP服务
        b -&amp;gt;&amp;gt; pe: envoy.NewDiscoveryService()
        Note over b,c: 💚💚💚💚💚ds.clearCache()封装为Handler&amp;lt;br/&amp;gt;接收s.ServiceController、s.configController的变更通知&amp;lt;br/&amp;gt;✅s.ServiceController.AppendServiceHandler()&amp;lt;br/&amp;gt;✅s.ServiceController.AppendInstanceHandler()&amp;lt;br/&amp;gt;✅s.configController.RegisterEventHandler()
        pe --&amp;gt;&amp;gt; b: discovery *DiscoveryService
        Note over kc,cmd: HTTP&amp;lt;br/&amp;gt;envoy.DiscoveryService提供/v1/registration以及/debug/pprof/* REST接口
        b --&amp;gt; b: s.mux = discovery.RestContainer.ServeMux
        b -&amp;gt;&amp;gt; pe: envoyv2.NewDiscoveryServer()
        pe --&amp;gt;&amp;gt; b: s.EnvoyXdsServer *DiscoveryServer
        Note over kc,cmd: gRPC&amp;lt;br/&amp;gt;envoyv2.DiscoveryServer&amp;lt;br/&amp;gt;只提供StreamAggregatedResources()服务&amp;lt;br/&amp;gt;xDS管理
        Note over kc,cmd: s.initGrpcServer()&amp;lt;br/&amp;gt;s.httpServer&amp;lt;br/&amp;gt;http.Server{Handler: s.mux}        
        Note over kc,cmd: http listener&amp;lt;br/&amp;gt;grpc listener
        Note over b,c: ❤️❤️❤️️❤️❤️️s.addStartFunc()&amp;lt;br/&amp;gt;s.httpServer.Serve()&amp;lt;br/&amp;gt;s.grpcServer.Serve()
        alt args.DiscoveryOptions.SecureGrpcAddr != &amp;quot;&amp;quot;
        b -&amp;gt;&amp;gt; b: initSecureGrpcServer()
            Note over kc,cmd: s.secureGRPCServer&amp;lt;br/&amp;gt;s.secureHTTPServer
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc()&amp;lt;br/&amp;gt;s.secureHTTPServer.ServeTLS()
        end
        
        Note right of b: 
    
    Note left of b: 监控&amp;lt;br/&amp;gt;initMonitor()
        Note over b,c: ❤️❤️❤️️❤️️❤️&amp;lt;br/&amp;gt;s.addStartFunc()&amp;lt;br/&amp;gt;startMonitor()
    
    Note left of b: 集群&amp;lt;br/&amp;gt;initClusterRegistries()
        b -&amp;gt;&amp;gt; c: clusterregistry.NewMulticluster()
        c --&amp;gt;&amp;gt; b: multicluster *Multicluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;discovery-server流程&#34;&gt;Discovery Server流程&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
    
    
    s(ads.StreamAggregatedResources)
    style s fill:#f9f
    s --&amp;gt; rc(reqChannel)
    s --&amp;gt; pc(pushChannel)
    style rc fill:#f9f
    style pc fill:#f9f
    
    subgraph reqChannel
        rc --&amp;gt; dt{discReq.TypeUrl}
        dt --&amp;gt;|ClusterType| pushCds[&amp;quot;pushCds()&amp;quot;]
        dt --&amp;gt;|ListenerType| pushLds[&amp;quot;pushLds()&amp;quot;]
        dt --&amp;gt;|RouteType| pushRoute[&amp;quot;pushRoute()&amp;quot;]
        dt --&amp;gt;|EndpointType| pushEds[&amp;quot;pushEds()&amp;quot;]
    end
    
    subgraph pushChannel
        nd(&amp;quot;DiscoveryServer&amp;quot;) --&amp;gt; pr(&amp;quot;periodicRefresh&amp;quot;)
        nd --&amp;gt; ash(&amp;quot;s.ServiceController.AppendServiceHandler()&amp;quot;)
        nd --&amp;gt; aih(&amp;quot;s.ServiceController.AppendInstanceHandler()&amp;quot;)
        nd --&amp;gt; reh(&amp;quot;s.configController.RegisterEventHandler()&amp;quot;)
        ash --&amp;gt; clearCache(&amp;quot;clearCache()&amp;quot;)
        aih --&amp;gt; clearCache
        reh --&amp;gt; clearCache
        clearCache --&amp;gt;|full=true| ds(&amp;quot;ds.ConfigUpdate()&amp;quot;)
        pr --&amp;gt; pa(&amp;quot;ads.AdsPushAll()&amp;quot;)         
        
        sp(&amp;quot;ads.startPush()&amp;quot;) --&amp;gt; pc
        
        c(config) --MeshConfig/MeshNetworks/MCPConfig--&amp;gt; ds
        ds --&amp;gt; dp(&amp;quot;doPush()&amp;quot;)
        dp --&amp;gt; push(&amp;quot;Push()&amp;quot;)
        
        push --&amp;gt; pa
        pa --&amp;gt; updateCluster[&amp;quot;eds.updateCluster()&amp;quot;]
        push --&amp;gt; updateServiceShards[&amp;quot;eds.updateServiceShards()&amp;quot;]
        pa --&amp;gt; ei(&amp;quot;eds.edsIncremental()&amp;quot;)
        ei --&amp;gt; updateClusterInc(&amp;quot;eds.updateClusterInc()&amp;quot;)
        pa --&amp;gt; sp
        ei --&amp;gt; sp
        updateClusterInc --&amp;gt; updateCluster
        
        
        pc --&amp;gt; pushConn(pushConnection)
        pushConn -.-&amp;gt; C/E/L/Rds
    end
    
    nd --&amp;gt;|Serve gRPC| s
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>【Istio安全】服务间访问控制-RBAC</title>
      <link>http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hbchen.com/post/servicemesh/2019-03-09-istio-rbac-quick-start/</guid>
      
        <description>&lt;p&gt;Istio提供了非常易用的安全解决方案，包括服务间身份验证&lt;code&gt;mTLS&lt;/code&gt;，服务间访问控制&lt;code&gt;RBAC&lt;/code&gt;，以及终端用户身份验证&lt;code&gt;JWT&lt;/code&gt;等，本文主要介绍如何使用服务间访问控制，同时涉及&lt;code&gt;双向TLS&lt;/code&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Istio版本 &lt;strong&gt;1.1.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;在的&lt;a href=&#34;https://github.com/hb-go/micro-mesh&#34;&gt;github.com/hb-go/micro-mesh&lt;/a&gt;中有结合示例的&lt;a href=&#34;https://github.com/hb-go/micro-mesh/tree/master/deploy/k8s/istio/rbac&#34;&gt;RBAC配置实践&lt;/a&gt;可以参考&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;要实现&lt;code&gt;RBAC&lt;/code&gt;主要理解以下几个类型的&lt;code&gt;yaml&lt;/code&gt;配置，以及之间的关系：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#双向tls&#34;&gt;双向TLS&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Policy&lt;/code&gt;或&lt;code&gt;MeshPolicy&lt;/code&gt;，上游&lt;code&gt;server&lt;/code&gt;开启TLS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DestinationRule&lt;/code&gt;，下游&lt;code&gt;client&lt;/code&gt;开启TLS&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rbac&#34;&gt;RBAC&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ClusterRbacConfig&lt;/code&gt;/&lt;code&gt;RbacConfig&lt;/code&gt;，启用授权及范围&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ServiceRole&lt;/code&gt;，角色权限规则&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ServiceRoleBinding&lt;/code&gt;，角色绑定规则&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optional&#34;&gt;Optional&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ServiceAccount&lt;/code&gt;，&lt;code&gt;ServiceRoleBinding&lt;/code&gt;.&lt;code&gt;subjects&lt;/code&gt;的&lt;code&gt;user&lt;/code&gt;条件
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;假设场景&#34;&gt;假设场景&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;网格内&lt;code&gt;service-1&lt;/code&gt;、&lt;code&gt;service-2&lt;/code&gt;开启RBAC访问控制&lt;/li&gt;
&lt;li&gt;仅&lt;code&gt;service-1&lt;/code&gt;授权给&lt;code&gt;ingressgateway&lt;/code&gt;访问，&lt;code&gt;service-2&lt;/code&gt;则不能被&lt;code&gt;ingressgateway&lt;/code&gt;访问&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://hbchen.com/img/istio-tls-rbac.png&#34; alt=&#34;auth-adapter&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;双向tls&#34;&gt;双向TLS&lt;/h2&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E8%AE%A4%E8%AF%81&#34;&gt;Istio文档-认证策略&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E8%AE%A4%E8%AF%81%E7%AD%96%E7%95%A5&#34;&gt;认证策略&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/authn-policy/&#34;&gt;Istio文档-基础认证策略&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/authn-policy/#%E4%B8%BA%E7%BD%91%E6%A0%BC%E4%B8%AD%E7%9A%84%E6%89%80%E6%9C%89%E6%9C%8D%E5%8A%A1%E5%90%AF%E7%94%A8%E5%8F%8C%E5%90%91-tls-%E8%AE%A4%E8%AF%81&#34;&gt;为网格中的所有服务启用双向 TLS 认证&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;1-上游-server-开启tls&#34;&gt;1.上游&lt;code&gt;server&lt;/code&gt;开启TLS&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;a href=&#34;##&#34;&gt;策略范围说明&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网格范围策略&lt;/strong&gt;：在网格范围存储中定义的策略，没有目标选择器部分。网格中最多只能有&lt;strong&gt;一个网格范围&lt;/strong&gt;的策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;命名空间范围的策略&lt;/strong&gt;：在命名空间范围存储中定义的策略，名称为 default 且没有目标选择器部分。每个命名空间最多只能有&lt;strong&gt;一个命名空间范围&lt;/strong&gt;的策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特定于服务的策略&lt;/strong&gt;：在命名空间范围存储中定义的策略，具有非空目标选择器部分。命名空间可以具有&lt;strong&gt;零个，一个或多个特定于服务&lt;/strong&gt;的策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;策略范围可以分别由&lt;code&gt;Policy&lt;/code&gt;、&lt;code&gt;MeshPolicy&lt;/code&gt;设置，&lt;code&gt;Policy&lt;/code&gt;可以选择对&lt;strong&gt;命名空间&lt;/strong&gt;所有服务生效，也可以指定&lt;code&gt;targets&lt;/code&gt;对&lt;strong&gt;特定服务&lt;/strong&gt;生效，&lt;code&gt;MeshPolicy&lt;/code&gt;则是整个网格内生效，对于&lt;strong&gt;命名空间范围&lt;/strong&gt;和&lt;strong&gt;网格范围&lt;/strong&gt;名称都只能为&lt;code&gt;default&lt;/code&gt;。&lt;/br&gt;
同时配置多个策略时使用最窄匹配策略，&lt;strong&gt;特定服务&amp;gt;命名空间范围&amp;gt;网格范围&lt;/strong&gt;，如果多个&lt;strong&gt;特定于服务的策略&lt;/strong&gt;与服务匹配，则随机选择一个。下面是不同策略范围的具体配置参考：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;Policy&lt;/code&gt;特定于服务的策略&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;targets&lt;/code&gt;支持&lt;code&gt;name&lt;/code&gt;以及&lt;code&gt;ports&lt;/code&gt;列表&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;authentication.istio.io/v1alpha1&amp;quot;
kind: &amp;quot;Policy&amp;quot;
metadata:
  name: &amp;quot;policy-name&amp;quot;
spec:
  targets:
  - name: service-name-1
  - name: service-name-2
    ports:
    - number: 8080
  peers:
  - mtls: {}
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;Policy&lt;/code&gt;命名空间范围的策略&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;authentication.istio.io/v1alpha1&amp;quot;
kind: &amp;quot;Policy&amp;quot;
metadata:
  name: &amp;quot;default&amp;quot;
  namespace: &amp;quot;namespace-1&amp;quot;
spec:
  peers:
  - mtls: {}
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;MeshPolicy&lt;/code&gt;网格范围策略&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;authentication.istio.io/v1alpha1&amp;quot;
kind: &amp;quot;MeshPolicy&amp;quot;
metadata:
  name: &amp;quot;default&amp;quot;
spec:
  peers:
  - mtls: {}
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-下游-client-开启tls&#34;&gt;2.下游&lt;code&gt;client&lt;/code&gt;开启TLS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;client&lt;/code&gt;端TLS由目标规则&lt;code&gt;DestinationRule&lt;/code&gt;配置，在流量策略&lt;code&gt;trafficPolicy&lt;/code&gt;中开启&lt;code&gt;tls&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/reference/config/istio.networking.v1alpha3/#destinationrule&#34;&gt;Istio参考配置-通信路由#DestinationRule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/reference/config/istio.networking.v1alpha3/#trafficpolicy&#34;&gt;Istio参考配置-通信路由#TrafficPolicy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: service-name-1
spec:
  host: service-host-1
  # NOTE: 开启TLS
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
  subsets:
  - name: v1
    labels:
      version: v1
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;TLS&lt;code&gt;mode&lt;/code&gt;说明&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;mode值&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;DISABLE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;不要为上游端点使用 TLS。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SIMPLE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;向上游端点发起 TLS 连接。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;MUTUAL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;发送客户端证书进行验证，用双向 TLS 连接上游端点。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ISTIO_MUTUAL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;发送客户端证书进行验证，用双向 TLS 连接上游端点。和 MUTUAL 相比，这种方式使用的双向 TLS 证书系统是由 Istio 生成的。如果使用这种模式，TLSSettings 中的其他字段应该留空。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;rbac&#34;&gt;RBAC&lt;/h2&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E6%8E%88%E6%9D%83&#34;&gt;Istio文档-授权&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E5%90%AF%E7%94%A8%E6%8E%88%E6%9D%83&#34;&gt;启用授权&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/concepts/security/#%E6%8E%88%E6%9D%83%E7%AD%96%E7%95%A5&#34;&gt;授权策略&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/role-based-access-control/&#34;&gt;Istio文档-基于角色的访问控制&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/role-based-access-control/#%E6%9C%8D%E5%8A%A1%E7%BA%A7%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6&#34;&gt;服务级的访问控制&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/setup/kubernetes/upgrade/#%E8%BF%81%E7%A7%BB-rbacconfig-%E5%88%B0-clusterrbacconfig&#34;&gt;Istio文档-迁移 RbacConfig 到 ClusterRbacConfig&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;这里使用的&lt;code&gt;ClusterRbacConfig&lt;/code&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/&#34;&gt;Istio参考配置-授权&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;有关&lt;code&gt;RbacConfig&lt;/code&gt;、&lt;code&gt;ServiceRole&lt;/code&gt;、&lt;code&gt;ServiceRoleBinding&lt;/code&gt;的属性结构Istio文档有详细的配置可以参考:&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/istio.rbac.v1alpha1/&#34;&gt;Istio参考配置-授权-RBAC&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-开启授权-clusterrbacconfig&#34;&gt;1.开启授权&lt;code&gt;ClusterRbacConfig&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;rbac.istio.io/v1alpha1&amp;quot;
kind: ClusterRbacConfig
metadata:
  name: default
  namespace: istio-system
spec:
  mode: &#39;ON_WITH_INCLUSION&#39;
  inclusion:
    #namespaces: [&amp;quot;namespace-1&amp;quot;]
    services: [&amp;quot;service-name-1.namespace-1.svc.cluster.local&amp;quot;, &amp;quot;service-name-2.namespace-1.svc.cluster.local&amp;quot;]
  # NOTE: ENFORCED/PERMISSIVE，严格或宽容模式
  enforcement_mode: ENFORCED
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;enforcement_mode&lt;/code&gt;可以选择&lt;code&gt;ENFORCED&lt;/code&gt;严格模式，或&lt;code&gt;PERMISSIVE&lt;/code&gt;宽容模式，宽容模式便于授权策略需要&lt;strong&gt;变更时进行验证测试&lt;/strong&gt;，&lt;a href=&#34;https://istio.io/zh/docs/tasks/security/role-based-access-control/#%E6%8E%88%E6%9D%83%E8%AE%B8%E5%8F%AF%E6%A8%A1%E5%BC%8F&#34;&gt;Istio任务-授权许可模式&lt;/a&gt;任务中有更具体的场景介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模式&lt;code&gt;mode&lt;/code&gt;说明&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;mode值&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;OFF&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;关闭 Istio RBAC，RbacConfig 的所有配置将会失效，且 Istio RBAC Policies 不会执行。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ON&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;为所有 services 和 namespaces 启用 Istio RBAC。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ON_WITH_INCLUSION&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;仅针对 inclusion 字段中指定的 services 和 namespaces 启用 Istio RBAC。其它不在 inclusion 字段中的 services 和 namespaces 将不会被 Istio RBAC Policies 强制执行。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ON_WITH_EXCLUSION&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;针对除了 exclusion 字段中指定的 services 和 namespaces，启用 Istio RBAC。其它不在 exclusion 字段中的 services 和 namespaces 将按照 Istio RBAC Policies 执行。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;2-角色权限规则-servicerole&#34;&gt;2.角色权限规则&lt;code&gt;ServiceRole&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;namespace&lt;/code&gt; + &lt;code&gt;services&lt;/code&gt; + &lt;code&gt;paths&lt;/code&gt; + &lt;code&gt;methods&lt;/code&gt; 一起定义了如何访问服务，其中&lt;code&gt;services&lt;/code&gt;必选，另外有&lt;code&gt;constraints&lt;/code&gt;可以指定其它约束，支持的约束参考&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/constraints-and-properties/#%E6%94%AF%E6%8C%81%E7%9A%84%E7%BA%A6%E6%9D%9F&#34;&gt;Istio参考配置-授权-约束和属性#支持的约束&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;rbac.istio.io/v1alpha1&amp;quot;
kind: ServiceRole
metadata:
  name: service-role-1
  namespace: default
spec:
  rules:
  - services: [&amp;quot;service-name-1.namespace-1.svc.cluster.local&amp;quot;]
    methods: [&amp;quot;*&amp;quot;]
    # NOTE: 根据约束需要修改
    constraints:
    - key: request.headers[version]
      values: [&amp;quot;v1&amp;quot;, &amp;quot;v2&amp;quot;]
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-角色绑定规则-servicerolebinding&#34;&gt;3.角色绑定规则&lt;code&gt;ServiceRoleBinding&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;user&lt;/code&gt; + &lt;code&gt;properties&lt;/code&gt; 一起定义授权给谁，支持的属性参考&lt;a href=&#34;https://istio.io/zh/docs/reference/config/authorization/constraints-and-properties/#%E6%94%AF%E6%8C%81%E7%9A%84%E5%B1%9E%E6%80%A7&#34;&gt;Istio参考配置-授权-约束和属性#支持的属性&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: &amp;quot;rbac.istio.io/v1alpha1&amp;quot;
kind: ServiceRoleBinding
metadata:
  name: service-rb-1
  namespace: default
spec:
  subjects:
  # NOTE: 需要添加 ServiceAccount
  - user: &amp;quot;cluster.local/ns/namespace-1/sa/service-account-2&amp;quot;
    # NOTE: 根据属性需要修改
    properties:
      source.namespace: &amp;quot;default&amp;quot;
  # NOTE: ingressgateway授权
  - user: &amp;quot;cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account&amp;quot;
  roleRef:
    kind: ServiceRole
    name: &amp;quot;service-role-1&amp;quot;
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;optional&#34;&gt;Optional&lt;/h2&gt;

&lt;h3 id=&#34;部署实例添加-serviceaccount&#34;&gt;部署实例添加&lt;code&gt;ServiceAccount&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;对于需要要在&lt;code&gt;ServiceRoleBinding&lt;/code&gt;的&lt;code&gt;subjects&lt;/code&gt;条件中授权的&lt;code&gt;user&lt;/code&gt;，需要在部署实例时指定&lt;code&gt;serviceAccountName&lt;/code&gt;，如前面&lt;code&gt;ServiceRoleBinding&lt;/code&gt;配置要允许&lt;code&gt;service-2&lt;/code&gt;访问&lt;code&gt;service-1&lt;/code&gt;，则部署&lt;code&gt;service-2&lt;/code&gt;时需要配置&lt;code&gt;serviceAccountName: service-account-2&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# NOTE: 创建ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: service-account-2
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: service-name-2-v1
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: service-name-2
        version: v1
    spec:
      # NOTE: 为部署实例指定serviceAccountName
      serviceAccountName: service-account-2
      containers:
      - name: service-name-2-v1
        command: [
          &amp;quot;/main&amp;quot;
        ]
        image: hbchen/service-2:v0.0.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 9080
---
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;Istio服务网格可以很方便的实现&lt;strong&gt;服务间访问控制&lt;/strong&gt;，通过服务级的授权开关，再结合&lt;code&gt;ServiceRole&lt;/code&gt;、&lt;code&gt;ServiceRoleBinding&lt;/code&gt;的约束和属性条件，可以实现细粒度的访问控制。本文未涉及Istio的终端用户身份验证，后面会结合&lt;code&gt;Ingress&lt;/code&gt;、&lt;code&gt;Egress&lt;/code&gt;的&lt;code&gt;TLS&lt;/code&gt;和&lt;code&gt;JWT&lt;/code&gt;一起分析边缘流量相关的安全问题。&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>